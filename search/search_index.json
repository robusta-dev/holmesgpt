{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"HolmesGPT","text":"<p>AI Agent for Troubleshooting Cloud-Native Environments.</p> <p></p>"},{"location":"#quick-start","title":"Quick Start","text":"<ul> <li> <p> Install CLI</p> <p>Run HolmesGPT from your terminal</p> <p> Install</p> </li> <li> <p> Install UI/TUI</p> <p>Use through a web interface or K9s plugin</p> <p> Install</p> </li> <li> <p> View Benchmarks</p> <p>Compare LLM performance across 150+ test scenarios</p> <p> Benchmarks</p> </li> </ul>"},{"location":"#need-help","title":"Need Help?","text":"<ul> <li>Join our Slack - Get help from the community</li> <li>Request features on GitHub - Suggest improvements or report bugs</li> </ul>"},{"location":"cncf-self-assesment/","title":"General Technical Review - HolmesGPT / Sandbox","text":"<ul> <li>Project: HolmesGPT</li> <li>Project Version: 0.11.5</li> <li>Website: https://github.com/robusta-dev/holmesgpt</li> <li>Date Updated: 2025-07-16</li> <li>Template Version: v1.0</li> <li>Description: HolmesGPT is an AI agent that automates cloud-native troubleshooting, bridging knowledge gaps by investigating alerts, executing runbooks, and correlating observability data in cloud-native platforms.</li> </ul>"},{"location":"cncf-self-assesment/#day-0-planning-phase","title":"Day 0 - Planning Phase","text":""},{"location":"cncf-self-assesment/#scope","title":"Scope","text":"<p>Describe the roadmap process, how scope is determined for mid to long term features, as well as how the roadmap maps back to current contributions and maintainer ladder?</p> <p>HolmesGPT follows an open and community-driven roadmap process. The roadmap is maintained publicly (via GitHub Projects and issues) and is shaped by a combination of the following inputs:</p> <ul> <li>Community feedback from users and contributors, gathered through GitHub issues, Slack, and regular discussions</li> <li>Strategic alignment with the project\u2019s long-term mission: enabling AI-powered root cause analysis in cloud-native environments</li> <li>Technical priorities based on gaps surfaced during usage or contributor pain points</li> <li>Upstream integration plans with core CNCF projects like Prometheus, Kubernetes, and OpenTelemetry</li> </ul> <p>Mid to long-term scope is defined quarterly and iterated collaboratively among maintainers</p> <p>Describe the target persona or user(s) for the project? DevOps, SREs, and platform engineers</p> <p>Explain the primary use case for the project. What additional use cases are supported by the project?</p> <p>Two primary use cases: 1. Root-cause analysis of alerts (i.e. Prometheus alerts) 2. Troubleshooting problems (via free-text questions) in cloud-native environments</p> <p>In both cases, the analysis can be 100% autonomous, or driven by predefined runbooks.</p> <p>Explain which use cases have been identified as unsupported by the project. General purpose AI agent use cases (outside of troubleshooting and RCA), coding agents, and security use cases.</p> <p>Describe the intended types of organizations who would benefit from adopting this project. (i.e. financial services, any software manufacturer, organizations providing platform engineering services)?</p> <p>End users running cloud-native services at scale, especially in larger environments with many microservices and potential for complex cascading failures.</p> <p>Please describe any completed end user research and link to any reports. N/A</p>"},{"location":"cncf-self-assesment/#usability","title":"Usability","text":"<p>How should the target personas interact with your project? The most common entry point is via a cli tool that is run on-demand to troubleshoot a problem or an alert.</p> <p>Describe the user experience (UX) and user interface (UI) of the project. The open source includes a CLI tool with an interactive console and /slash commands. Several vendors have built graphical user interfaces on top of that.</p> <p>Describe how this project integrates with other projects in a production environment. The project exposes an HTTP API and a Helm chart for running the HTTP server in Kubernetes clusters.</p>"},{"location":"cncf-self-assesment/#design","title":"Design","text":"<p>Explain the design principles and best practices the project is following. * Human-in-the-loop: users are able to interact with and guide HolmesGPT investigations * Safety-first - The agent is restricted by default and only allowed to run safe commands. * Interoperable \u2013 works seamlessly with existing observability stacks * Kubernetes-native: Works with Prometheus, Loki, and other CNCF stack components. * Extensible: Modular plugin system for adding new data sources, including external MCP servers</p> <p>Outline or link to the project\u2019s architecture requirements? Describe how they differ for Proof of Concept, Development, Test and Production environments, as applicable. Lightweight, can run as a standalone local CLI or in-cluster as an HTTP server. Typical during POC users start with the local CLI and when rolling into production use a more advanced setup.</p> <p>Define any specific service dependencies the project relies on in the cluster. No relevant.</p> <p>Describe how the project implements Identity and Access Management. HolmesGPT runs with user-provided credentials (e.g. service account) and respects whichever permissions were given to it.</p> <p>Describe how the project has addressed sovereignty. HolmesGPT runs fully within the user\u2019s infrastructure. All data\u2014logs, metrics, traces, and AI-generated insights\u2014remains under user control. There\u2019s no dependency on external SaaS or third-party APIs unless explicitly configured. This ensures data privacy, compliance, and operational sovereignty.</p> <p>Regarding data sent to the LLM, here too users have the choice of providing their own LLM or using a trusted cloud provider of their choice.</p> <p>Describe any compliance requirements addressed by the project. N/A</p> <p>Describe the project\u2019s High Availability requirements. Each request to HolmesGPT is stateless, so it's possible to run multiple instances.</p> <p>Describe the project\u2019s resource requirements, including CPU, Network and Memory. Minimal, similar to any standard Python application running in a Kubernetes cluster. We recommend some defaults in the Helm chart, but this can be customized by the user.</p> <p>Describe the project\u2019s storage requirements, including its use of ephemeral and/or persistent storage. N/A</p> <p>Please outline the project\u2019s API Design The project itself exposes a REST API, following standard conventions. We strive to maintain backwards compatibility, and to add new endpoints when changing something instead of breaking an existing endpoint.</p> <p>It will perform HTTP calls to collect data when investigating problems - the exact calls depend on which data sources the user enabled.</p> <p>We bump the major release number only on breaking changes. Minor releases are done about monthly, when there are substantial new features. Bug fixes are done as needed with a patch release.</p> <p>Describe how the project is installed and initialized, e.g. a minimal install with a few lines of code or does it require more complex integration and configuration? Please refer to https://holmesgpt.dev/installation/cli-installation/</p> <p>How does an adopter test and validate the installation? Please refer to https://holmesgpt.dev/walkthrough/</p>"},{"location":"cncf-self-assesment/#security","title":"Security","text":"<p>Please provide a link to the project\u2019s cloud native security self assessment.</p> <p>Please review the Cloud Native Security Tenets from TAG Security. How are you satisfying the tenets of cloud native security projects? This is extremely relevant for us, given the risk that AI models can hallucinate and thereby that HolmesGPT could run malicious commands. To mitigate this, default access is read-only and non-mutating and limited to a pre-approved list of safe commands and integrations.</p> <p>Describe how each of the cloud native principles apply to your project. * Make security a design requirement - see above. * Applying secure configuration has the best user experience - also covered above * Selecting insecure configuration is a conscious decision -  Users must make a conscious and concerted effort to add insecure toolsets (data sources) to HolmesGPT - it cannot be done accidentally. * Transition from insecure to secure state is possible - users are free to reduce the permissions with which Holmes runs at any point in time and Holmes will identify it and adapt * Secure defaults are inherited - by default Holmes inherits service roles and permissions from its environment * Exception lists have first class support - users can add their own toolsets to give Holmes access to additional commands * Secure defaults protect against pervasive vulnerability exploits - in the case of Holmes, this is equivalent to providing security even when used with malicious/hallucinating LLM which is done as described above * Security limitations of a system are explainable - Holmes reports permission issues when encountered</p> <p>How do you recommend users alter security defaults in order to \"loosen\" the security of the project? Please link to any documentation the project has written concerning these use cases. https://holmesgpt.dev/data-sources/permissions/</p> <p>Security Hygiene We discuss security implications of features at the design phase, when working on new features. Where warranted there are dedicated discussions around security related aspects. Code reviews function as the final review, but very few issues reach that stage due to thinking about security earlier in the process.</p> <p>Explain the least minimal privileges required by the project and reasons for additional privileges. Read-only access to the data sources that are relevant to the requested RCA.</p> <p>Describe how the project is handling certificate rotation and mitigates any issues with certificates. Not relevant.</p> <p>Describe how the project is following and implementing secure software supply chain best practices Link is broken, but we strictly review all changes to CI/CD and anything that impacts building the project and distributing it to end users.</p>"},{"location":"community/","title":"Community","text":"<p>Join our community to collaborate on the future of AI-powered troubleshooting.</p>"},{"location":"community/#community-meetup-recording","title":"Community Meetup Recording","text":"<p>\ud83d\udcf9 Watch our first HolmesGPT Community Meetup</p> <p>We held our inaugural community meetup on August 21, 2025. Watch the recording to learn about:</p> <ul> <li>HolmesGPT roadmap and upcoming features</li> <li>Community Q&amp;A and feedback</li> <li>Ways to get involved with the project</li> </ul> <p>\u25b6\ufe0f Watch Recording on YouTube</p>"},{"location":"community/#resources","title":"Resources","text":"<ul> <li>\ud83d\udcdd Meeting Notes</li> <li>\ud83d\udccb HolmesGPT Roadmap</li> </ul>"},{"location":"community/#get-involved","title":"Get Involved","text":"<p>\ud83d\udcac Join the Discussion:</p> <ul> <li>Slack - #holmesgpt channel</li> <li>GitHub Issues - Report bugs and request features</li> </ul> <p>\ud83e\udd1d Contribute:</p> <ul> <li>Share your HolmesGPT use cases</li> <li>Help improve documentation</li> <li>Submit code contributions</li> </ul>"},{"location":"ai-providers/","title":"AI Providers","text":"<p>HolmesGPT supports multiple AI providers, giving you flexibility in choosing the best model for your needs and budget.</p> <ul> <li> Anthropic</li> <li> AWS Bedrock</li> <li> Azure OpenAI</li> <li> Gemini</li> <li> Google Vertex AI</li> <li> Ollama</li> <li> OpenAI</li> <li> OpenAI-Compatible</li> <li> Robusta AI</li> <li> Using Multiple Providers</li> </ul>"},{"location":"ai-providers/#quick-start","title":"Quick Start","text":"<p>Recommended for New Users</p> <p>OpenAI models provide a good balance of accuracy and speed.</p> <p>Anthropic models often give better results at the expense of speed.</p> <p>To get started with an OpenAI model:</p> <ol> <li>Get an OpenAI API key</li> <li>Set <code>export OPENAI_API_KEY=\"your-api-key\"</code></li> <li>Run <code>holmes ask \"what pods are failing?\"</code> (OpenAI is the default provider)</li> </ol> <p>Choose your provider above to see detailed configuration instructions.</p>"},{"location":"ai-providers/#configuration","title":"Configuration","text":"<p>Each AI provider requires specific environment variables for authentication. See the Environment Variables Reference for a complete list of all configuration options beyond just API keys.</p>"},{"location":"ai-providers/anthropic/","title":"Anthropic","text":"<p>Configure HolmesGPT to use Anthropic's Claude models.</p>"},{"location":"ai-providers/anthropic/#setup","title":"Setup","text":"<p>Get an Anthropic API key.</p>"},{"location":"ai-providers/anthropic/#configuration","title":"Configuration","text":"Holmes CLIHolmes Helm ChartRobusta Helm Chart <pre><code>export ANTHROPIC_API_KEY=\"your-anthropic-api-key\"\nholmes ask \"what pods are failing?\" --model=\"anthropic/&lt;your-claude-model&gt;\"\n</code></pre> <p>Create Kubernetes Secret: <pre><code>kubectl create secret generic holmes-secrets \\\n  --from-literal=anthropic-api-key=\"sk-ant-...\" \\\n  -n &lt;namespace&gt;\n</code></pre></p> <p>Configure Helm Values: <pre><code># values.yaml\nadditionalEnvVars:\n  - name: ANTHROPIC_API_KEY\n    valueFrom:\n      secretKeyRef:\n        name: holmes-secrets\n        key: anthropic-api-key\n\n# Configure at least one model using modelList\nmodelList:\n  claude-sonnet-4:\n    api_key: \"{{ env.ANTHROPIC_API_KEY }}\"\n    model: claude-sonnet-4-20250514\n    temperature: 1\n    thinking:\n      budget_tokens: 10000\n      type: enabled\n\n  claude-opus-4:\n    api_key: \"{{ env.ANTHROPIC_API_KEY }}\"\n    model: anthropic/claude-opus-4-1-20250805\n    temperature: 1\n\n# Optional: Set default model (use modelList key name)\nconfig:\n  model: \"claude-sonnet-4\"  # This refers to the key name in modelList above\n</code></pre></p> <p>Create Kubernetes Secret: <pre><code>kubectl create secret generic robusta-holmes-secret \\\n  --from-literal=anthropic-api-key=\"sk-ant-...\" \\\n  -n &lt;namespace&gt;\n</code></pre></p> <p>Configure Helm Values: <pre><code># values.yaml\nholmes:\n  additionalEnvVars:\n    - name: ANTHROPIC_API_KEY\n      valueFrom:\n        secretKeyRef:\n          name: robusta-holmes-secret\n          key: anthropic-api-key\n\n  # Configure at least one model using modelList\n  modelList:\n    claude-sonnet-4:\n      api_key: \"{{ env.ANTHROPIC_API_KEY }}\"\n      model: claude-sonnet-4-20250514\n      temperature: 1\n      thinking:\n        budget_tokens: 10000\n        type: enabled\n\n    claude-opus-4:\n      api_key: \"{{ env.ANTHROPIC_API_KEY }}\"\n      model: anthropic/claude-opus-4-1-20250805\n      temperature: 1\n\n  # Optional: Set default model (use modelList key name)\n  config:\n    model: \"claude-sonnet-4\"  # This refers to the key name in modelList above\n</code></pre></p>"},{"location":"ai-providers/anthropic/#using-cli-parameters","title":"Using CLI Parameters","text":"<p>You can also pass the API key directly as a command-line parameter:</p> <pre><code>holmes ask \"what pods are failing?\" --model=\"anthropic/&lt;your-claude-model&gt;\" --api-key=\"your-api-key\"\n</code></pre>"},{"location":"ai-providers/anthropic/#prompt-caching","title":"Prompt Caching","text":"<p>HolmesGPT adds Anthropic's prompt caching feature, which can significantly reduce costs and latency for repeated API calls with similar prompts.</p> <p>HolmesGPT automatically adds cache control to the last message in each API call. This caches everything from the beginning of the conversation up to that point, making subsequent calls with the same prefix much faster and cheaper.</p>"},{"location":"ai-providers/anthropic/#how-it-works","title":"How It Works","text":"<ul> <li>Anthropic uses prefix-based caching - it caches the exact sequence of messages up to the cache control point</li> <li>The cache has a 5-minute lifetime by default</li> <li>Cached content must be at least 1024 tokens to be effective</li> <li>You're charged for cache writes on the first call, but subsequent cache hits are much cheaper</li> </ul>"},{"location":"ai-providers/anthropic/#benefits-in-holmesgpt","title":"Benefits in HolmesGPT","text":"<p>Prompt caching is particularly effective for HolmesGPT because:</p> <ul> <li>System prompts with tool definitions are large and static - perfect for caching</li> <li>Tool investigation loops reuse the same context multiple times</li> <li>Multi-step investigations benefit from cached conversation history</li> </ul>"},{"location":"ai-providers/anthropic/#additional-resources","title":"Additional Resources","text":"<p>HolmesGPT uses the LiteLLM API to support Anthropic provider. Refer to LiteLLM Anthropic docs for more details.</p>"},{"location":"ai-providers/aws-bedrock/","title":"AWS Bedrock","text":"<p>Configure HolmesGPT to use AWS Bedrock foundation models.</p> <p>Which Model to Use</p> <p>We highly recommend using Sonnet 4.0 or Sonnet 4.5 as they give the best results by far. See examples below for configuration.</p>"},{"location":"ai-providers/aws-bedrock/#setup","title":"Setup","text":""},{"location":"ai-providers/aws-bedrock/#prerequisites","title":"Prerequisites","text":"<ol> <li> <p>Install boto3: AWS Bedrock requires boto3 version 1.28.57 or higher:    <pre><code>pip install \"boto3&gt;=1.28.57\"\n</code></pre></p> </li> <li> <p>AWS credentials: Ensure you have AWS credentials configured with access to Bedrock models. See AWS Docs.</p> </li> </ol>"},{"location":"ai-providers/aws-bedrock/#configuration","title":"Configuration","text":"Holmes CLIHolmes Helm ChartRobusta Helm Chart <pre><code>export AWS_REGION_NAME=\"us-east-1\"  # Replace with your region\nexport AWS_ACCESS_KEY_ID=\"your-access-key\"\nexport AWS_SECRET_ACCESS_KEY=\"your-secret-key\"\nexport EXTRA_HEADERS=\"{\\\"anthropic-beta\\\": \\\"context-1m-2025-08-07\\\"}\" # Optional, beta 1M context window support, for Claude Sonnet 4 model.\n\nholmes ask \"what pods are failing?\" --model=\"bedrock/&lt;your-bedrock-model&gt;\"\n</code></pre> <p>Create Kubernetes Secret: <pre><code>kubectl create secret generic holmes-secrets \\\n  --from-literal=aws-access-key-id=\"AKIA...\" \\\n  --from-literal=aws-secret-access-key=\"your-secret-key\" \\\n  -n &lt;namespace&gt;\n</code></pre></p> <p>Configure Helm Values: <pre><code># values.yaml\nadditionalEnvVars:\n  - name: AWS_ACCESS_KEY_ID\n    valueFrom:\n      secretKeyRef:\n        name: holmes-secrets\n        key: aws-access-key-id\n  - name: AWS_SECRET_ACCESS_KEY\n    valueFrom:\n      secretKeyRef:\n        name: holmes-secrets\n        key: aws-secret-access-key\n\n# Configure at least one model using modelList\nmodelList:\n  bedrock-claude-35-sonnet:\n    aws_access_key_id: \"{{ env.AWS_ACCESS_KEY_ID }}\"\n    aws_secret_access_key: \"{{ env.AWS_SECRET_ACCESS_KEY }}\"\n    aws_region_name: us-east-1\n    model: bedrock/anthropic.claude-3-5-sonnet-20240620-v1:0\n    temperature: 1\n\n  bedrock-claude-sonnet-4:\n    aws_access_key_id: \"{{ env.AWS_ACCESS_KEY_ID }}\"\n    aws_secret_access_key: \"{{ env.AWS_SECRET_ACCESS_KEY }}\"\n    aws_region_name: eu-south-2\n    model: bedrock/eu.anthropic.claude-sonnet-4-20250514-v1:0\n    temperature: 1\n    thinking:\n      budget_tokens: 10000\n      type: enabled\n\n  bedrock-claude-sonnet-4-1M-context:\n    aws_access_key_id: \"{{ env.AWS_ACCESS_KEY_ID }}\"\n    aws_secret_access_key: \"{{ env.AWS_SECRET_ACCESS_KEY }}\"\n    aws_region_name: eu-south-2\n    model: bedrock/eu.anthropic.claude-sonnet-4-20250514-v1:0\n    temperature: 1\n    thinking:\n      budget_tokens: 10000\n      type: enabled\n    extra_headers:\n      anthropic-beta: context-1m-2025-08-07\n\n# Optional: Set default model (use modelList key name)\nconfig:\n  model: \"bedrock-claude-35-sonnet\"  # This refers to the key name in modelList above\n</code></pre></p> <p>Create Kubernetes Secret: <pre><code>kubectl create secret generic robusta-holmes-secret \\\n  --from-literal=aws-access-key-id=\"AKIA...\" \\\n  --from-literal=aws-secret-access-key=\"your-secret-key\" \\\n  -n &lt;namespace&gt;\n</code></pre></p> <p>Configure Helm Values: <pre><code># values.yaml\nholmes:\n  additionalEnvVars:\n    - name: AWS_ACCESS_KEY_ID\n      valueFrom:\n        secretKeyRef:\n          name: robusta-holmes-secret\n          key: aws-access-key-id\n    - name: AWS_SECRET_ACCESS_KEY\n      valueFrom:\n        secretKeyRef:\n          name: robusta-holmes-secret\n          key: aws-secret-access-key\n\n  # Configure at least one model using modelList\n  modelList:\n    bedrock-claude-35-sonnet:\n      aws_access_key_id: \"{{ env.AWS_ACCESS_KEY_ID }}\"\n      aws_secret_access_key: \"{{ env.AWS_SECRET_ACCESS_KEY }}\"\n      aws_region_name: us-east-1\n      model: bedrock/anthropic.claude-3-5-sonnet-20240620-v1:0\n      temperature: 1\n\n    bedrock-claude-sonnet-4:\n      aws_access_key_id: \"{{ env.AWS_ACCESS_KEY_ID }}\"\n      aws_secret_access_key: \"{{ env.AWS_SECRET_ACCESS_KEY }}\"\n      aws_region_name: eu-south-2\n      model: bedrock/eu.anthropic.claude-sonnet-4-20250514-v1:0\n      temperature: 1\n      thinking:\n        budget_tokens: 10000\n        type: enabled\n\n    bedrock-claude-sonnet-4-1M-context:\n      aws_access_key_id: \"{{ env.AWS_ACCESS_KEY_ID }}\"\n      aws_secret_access_key: \"{{ env.AWS_SECRET_ACCESS_KEY }}\"\n      aws_region_name: eu-south-2\n      model: bedrock/eu.anthropic.claude-sonnet-4-20250514-v1:0\n      temperature: 1\n      thinking:\n        budget_tokens: 10000\n        type: enabled\n      extra_headers:\n        anthropic-beta: context-1m-2025-08-07\n\n  # Optional: Set default model (use modelList key name)\n  config:\n    model: \"bedrock-claude-35-sonnet\"  # This refers to the key name in modelList above\n</code></pre></p>"},{"location":"ai-providers/aws-bedrock/#finding-your-aws-credentials","title":"Finding Your AWS Credentials","text":"<p>If the AWS CLI is already configured on your machine, you may be able to find the above values with:</p> <pre><code>cat ~/.aws/credentials ~/.aws/config\n</code></pre>"},{"location":"ai-providers/aws-bedrock/#finding-available-models","title":"Finding Available Models","text":"<p>To list models your account can access (replacing <code>us-east-1</code> with the relevant region):</p> <pre><code>aws bedrock list-foundation-models --region=us-east-1 | grep modelId\n</code></pre> <p>Important: Different models are available in different regions. For example, Claude Opus is only available in us-west-2.</p>"},{"location":"ai-providers/aws-bedrock/#model-name-examples","title":"Model Name Examples","text":"<p>Be sure to replace <code>&lt;your-bedrock-model&gt;</code> with a model you have access to, such as <code>anthropic.claude-opus-4-1-20250805-v1:0</code> or <code>anthropic.claude-sonnet-4-20250514-v1:0</code></p>"},{"location":"ai-providers/aws-bedrock/#additional-resources","title":"Additional Resources","text":"<p>HolmesGPT uses the LiteLLM API to support AWS Bedrock provider. Refer to LiteLLM Bedrock docs for more details.</p>"},{"location":"ai-providers/azure-openai/","title":"Azure OpenAI","text":"<p>Configure HolmesGPT to use Azure OpenAI Service.</p>"},{"location":"ai-providers/azure-openai/#setup","title":"Setup","text":"<p>Create an Azure OpenAI resource.</p>"},{"location":"ai-providers/azure-openai/#configuration","title":"Configuration","text":"Holmes CLIHolmes Helm ChartRobusta Helm Chart <pre><code>export AZURE_API_VERSION=\"2024-02-15-preview\"\nexport AZURE_API_BASE=\"https://your-resource.openai.azure.com\"\nexport AZURE_API_KEY=\"your-azure-api-key\"\n\nholmes ask \"what pods are failing?\" --model=\"azure/&lt;your-deployment-name&gt;\"\n</code></pre> <p>Create Kubernetes Secret: <pre><code>kubectl create secret generic holmes-secrets \\\n  --from-literal=azure-api-key=\"your-azure-api-key\" \\\n  -n &lt;namespace&gt;\n</code></pre></p> <p>Configure Helm Values: <pre><code># values.yaml\nadditionalEnvVars:\n  - name: AZURE_API_KEY\n    valueFrom:\n      secretKeyRef:\n        name: holmes-secrets\n        key: azure-api-key\n\n# Configure at least one model using modelList\nmodelList:\n  azure-gpt-41:\n    api_key: \"{{ env.AZURE_API_KEY }}\"\n    model: azure/gpt-4.1\n    api_base: https://your-resource.openai.azure.com/\n    api_version: \"2025-01-01-preview\"\n    temperature: 0\n\n  azure-gpt-5:\n    api_key: \"{{ env.AZURE_API_KEY }}\"\n    model: azure/gpt-5\n    api_base: https://your-resource.openai.azure.com/\n    api_version: \"2025-01-01-preview\"\n    temperature: 1\n\n# Optional: Set default model (use modelList key name)\nconfig:\n  model: \"azure-gpt-41\"  # This refers to the key name in modelList above\n</code></pre></p> <p>Create Kubernetes Secret: <pre><code>kubectl create secret generic robusta-holmes-secret \\\n  --from-literal=azure-api-key=\"your-azure-api-key\" \\\n  -n &lt;namespace&gt;\n</code></pre></p> <p>Configure Helm Values: <pre><code># values.yaml\nholmes:\n  additionalEnvVars:\n    - name: AZURE_API_KEY\n      valueFrom:\n        secretKeyRef:\n          name: robusta-holmes-secret\n          key: azure-api-key\n\n  # Configure at least one model using modelList\n  modelList:\n    azure-gpt-41:\n      api_key: \"{{ env.AZURE_API_KEY }}\"\n      model: azure/gpt-4.1\n      api_base: https://your-resource.openai.azure.com/\n      api_version: \"2025-01-01-preview\"\n      temperature: 0\n\n    azure-gpt-5:\n      api_key: \"{{ env.AZURE_API_KEY }}\"\n      model: azure/gpt-5\n      api_base: https://your-resource.openai.azure.com/\n      api_version: \"2025-01-01-preview\"\n      temperature: 1\n\n  # Optional: Set default model (use modelList key name)\n  config:\n    model: \"azure-gpt-41\"  # This refers to the key name in modelList above\n</code></pre></p>"},{"location":"ai-providers/azure-openai/#using-cli-parameters","title":"Using CLI Parameters","text":"<p>You can also pass the API key directly as a command-line parameter:</p> <pre><code>holmes ask \"what pods are failing?\" --model=\"azure/&lt;your-deployment-name&gt;\" --api-key=\"your-api-key\"\n</code></pre>"},{"location":"ai-providers/azure-openai/#additional-resources","title":"Additional Resources","text":"<p>HolmesGPT uses the LiteLLM API to support Azure OpenAI provider. Refer to LiteLLM Azure docs for more details.</p>"},{"location":"ai-providers/gemini/","title":"Gemini","text":"<p>Configure HolmesGPT to use Google's Gemini models via Google AI Studio.</p>"},{"location":"ai-providers/gemini/#setup","title":"Setup","text":"<p>Get your API key from Google AI Studio.</p>"},{"location":"ai-providers/gemini/#configuration","title":"Configuration","text":"Holmes CLIHolmes Helm ChartRobusta Helm Chart <pre><code>export GEMINI_API_KEY=\"your-gemini-api-key\"\nexport TOOL_SCHEMA_NO_PARAM_OBJECT_IF_NO_PARAMS=true\nholmes ask \"what pods are failing?\" --model=\"gemini/&lt;your-gemini-model&gt;\"\n</code></pre> <p>Create Kubernetes Secret: <pre><code>kubectl create secret generic holmes-secrets \\\n  --from-literal=gemini-api-key=\"your-gemini-api-key\" \\\n  -n &lt;namespace&gt;\n</code></pre></p> <p>Configure Helm Values: <pre><code># values.yaml\nadditionalEnvVars:\n  - name: GEMINI_API_KEY\n    valueFrom:\n      secretKeyRef:\n        name: holmes-secrets\n        key: gemini-api-key\n  - name: TOOL_SCHEMA_NO_PARAM_OBJECT_IF_NO_PARAMS\n    value: \"true\"  # Required for Gemini - see Environment Variables Reference\n\n# Configure at least one model using modelList\nmodelList:\n  gemini-pro:\n    api_key: \"{{ env.GEMINI_API_KEY }}\"\n    model: gemini/gemini-pro\n    temperature: 1\n\n  gemini-flash:\n    api_key: \"{{ env.GEMINI_API_KEY }}\"\n    model: gemini/gemini-1.5-flash\n    temperature: 1\n\n  gemini-pro-exp:\n    api_key: \"{{ env.GEMINI_API_KEY }}\"\n    model: gemini/gemini-exp-1206\n    temperature: 1\n\n# Optional: Set default model (use modelList key name)\nconfig:\n  model: \"gemini-pro\"  # This refers to the key name in modelList above\n</code></pre></p> <p>Create Kubernetes Secret: <pre><code>kubectl create secret generic robusta-holmes-secret \\\n  --from-literal=gemini-api-key=\"your-gemini-api-key\" \\\n  -n &lt;namespace&gt;\n</code></pre></p> <p>Configure Helm Values: <pre><code># values.yaml\nholmes:\n  additionalEnvVars:\n    - name: GEMINI_API_KEY\n      valueFrom:\n        secretKeyRef:\n          name: robusta-holmes-secret\n          key: gemini-api-key\n    - name: TOOL_SCHEMA_NO_PARAM_OBJECT_IF_NO_PARAMS\n      value: \"true\"  # Required for Gemini - see Environment Variables Reference\n\n  # Configure at least one model using modelList\n  modelList:\n    gemini-pro:\n      api_key: \"{{ env.GEMINI_API_KEY }}\"\n      model: gemini/gemini-pro\n      temperature: 1\n\n    gemini-flash:\n      api_key: \"{{ env.GEMINI_API_KEY }}\"\n      model: gemini/gemini-1.5-flash\n      temperature: 1\n\n    gemini-pro-exp:\n      api_key: \"{{ env.GEMINI_API_KEY }}\"\n      model: gemini/gemini-exp-1206\n      temperature: 1\n\n  # Optional: Set default model (use modelList key name)\n  config:\n    model: \"gemini-pro\"  # This refers to the key name in modelList above\n</code></pre></p>"},{"location":"ai-providers/gemini/#using-cli-parameters","title":"Using CLI Parameters","text":"<p>You can also pass the API key directly as a command-line parameter:</p> <pre><code>holmes ask \"what pods are failing?\" --model=\"gemini/&lt;your-gemini-model&gt;\" --api-key=\"your-api-key\"\n</code></pre>"},{"location":"ai-providers/gemini/#additional-resources","title":"Additional Resources","text":"<p>HolmesGPT uses the LiteLLM API to support Gemini provider. Refer to LiteLLM Gemini docs for more details.</p>"},{"location":"ai-providers/google-vertex-ai/","title":"Google Vertex AI","text":"<p>Configure HolmesGPT to use Google Vertex AI with Gemini models.</p>"},{"location":"ai-providers/google-vertex-ai/#setup","title":"Setup","text":"<ol> <li>Create a Google Cloud project with Vertex AI API enabled</li> <li>Create a service account with <code>Vertex AI User</code> role</li> <li>Download the JSON key file</li> </ol>"},{"location":"ai-providers/google-vertex-ai/#configuration","title":"Configuration","text":"Holmes CLIHolmes Helm ChartRobusta Helm Chart <pre><code>export VERTEXAI_PROJECT=\"your-project-id\"\nexport VERTEXAI_LOCATION=\"us-central1\"\nexport GOOGLE_APPLICATION_CREDENTIALS=\"path/to/service-account-key.json\"\n\nholmes ask \"what pods are failing?\" --model=\"vertex_ai/&lt;your-vertex-model&gt;\"\n</code></pre> <p>Create Kubernetes Secret: <pre><code># First, encode your service account JSON key\nkubectl create secret generic holmes-secrets \\\n  --from-file=google-credentials=path/to/service-account-key.json \\\n  --from-literal=vertexai-project=\"your-project-id\" \\\n  --from-literal=vertexai-location=\"us-central1\" \\\n  -n &lt;namespace&gt;\n</code></pre></p> <p>Configure Helm Values: <pre><code># values.yaml\nadditionalEnvVars:\n  - name: VERTEXAI_PROJECT\n    valueFrom:\n      secretKeyRef:\n        name: holmes-secrets\n        key: vertexai-project\n  - name: VERTEXAI_LOCATION\n    valueFrom:\n      secretKeyRef:\n        name: holmes-secrets\n        key: vertexai-location\n  - name: GOOGLE_APPLICATION_CREDENTIALS\n    value: \"/etc/google-credentials/google-credentials\"\n\n# Mount the credentials file (required for file-based authentication)\n# See: https://kubernetes.io/docs/concepts/storage/volumes/#secret\nadditionalVolumes:\n  - name: google-credentials\n    secret:\n      secretName: holmes-secrets\n      items:\n        - key: google-credentials\n          path: google-credentials\n\nadditionalVolumeMounts:\n  - name: google-credentials\n    mountPath: /etc/google-credentials\n    readOnly: true\n\n# Configure at least one model using modelList\nmodelList:\n  vertex-gemini-pro:\n    vertex_project: \"{{ env.VERTEXAI_PROJECT }}\"\n    vertex_location: \"{{ env.VERTEXAI_LOCATION }}\"\n    model: vertex_ai/gemini-pro\n    temperature: 1\n\n  vertex-gemini-flash:\n    vertex_project: \"{{ env.VERTEXAI_PROJECT }}\"\n    vertex_location: \"{{ env.VERTEXAI_LOCATION }}\"\n    model: vertex_ai/gemini-1.5-flash\n    temperature: 1\n\n# Optional: Set default model (use modelList key name)\nconfig:\n  model: \"vertex-gemini-pro\"  # This refers to the key name in modelList above\n</code></pre></p> <p>Create Kubernetes Secret: <pre><code># First, encode your service account JSON key\nkubectl create secret generic robusta-holmes-secret \\\n  --from-file=google-credentials=path/to/service-account-key.json \\\n  --from-literal=vertexai-project=\"your-project-id\" \\\n  --from-literal=vertexai-location=\"us-central1\" \\\n  -n &lt;namespace&gt;\n</code></pre></p> <p>Configure Helm Values: <pre><code># values.yaml\nholmes:\n  additionalEnvVars:\n    - name: VERTEXAI_PROJECT\n      valueFrom:\n        secretKeyRef:\n          name: robusta-holmes-secret\n          key: vertexai-project\n    - name: VERTEXAI_LOCATION\n      valueFrom:\n        secretKeyRef:\n          name: robusta-holmes-secret\n          key: vertexai-location\n    - name: GOOGLE_APPLICATION_CREDENTIALS\n      value: \"/etc/google-credentials/google-credentials\"\n\n  # Mount the credentials file (required for file-based authentication)\n  # See: https://kubernetes.io/docs/concepts/storage/volumes/#secret\n  additionalVolumes:\n    - name: google-credentials\n      secret:\n        secretName: robusta-holmes-secret\n        items:\n          - key: google-credentials\n            path: google-credentials\n\n  additionalVolumeMounts:\n    - name: google-credentials\n      mountPath: /etc/google-credentials\n      readOnly: true\n\n  # Configure at least one model using modelList\n  modelList:\n    vertex-gemini-pro:\n      vertex_project: \"{{ env.VERTEXAI_PROJECT }}\"\n      vertex_location: \"{{ env.VERTEXAI_LOCATION }}\"\n      model: vertex_ai/gemini-pro\n      temperature: 1\n\n    vertex-gemini-flash:\n      vertex_project: \"{{ env.VERTEXAI_PROJECT }}\"\n      vertex_location: \"{{ env.VERTEXAI_LOCATION }}\"\n      model: vertex_ai/gemini-1.5-flash\n      temperature: 1\n\n  # Optional: Set default model (use modelList key name)\n  config:\n    model: \"vertex-gemini-pro\"  # This refers to the key name in modelList above\n</code></pre></p>"},{"location":"ai-providers/google-vertex-ai/#using-cli-parameters","title":"Using CLI Parameters","text":"<p>You can also pass credentials directly as command-line parameters:</p> <pre><code>holmes ask \"what pods are failing?\" --model=\"vertex_ai/&lt;your-vertex-model&gt;\" --api-key=\"your-service-account-key\"\n</code></pre>"},{"location":"ai-providers/google-vertex-ai/#additional-resources","title":"Additional Resources","text":"<p>HolmesGPT uses the LiteLLM API to support Google Vertex AI provider. Refer to LiteLLM Google Vertex AI docs for more details.</p>"},{"location":"ai-providers/ollama/","title":"Ollama","text":"<p>Configure HolmesGPT to use local models with Ollama.</p> <p>Warning</p> <p>Ollama support is experimental and can be tricky to configure correctly. We recommend trying HolmesGPT with a hosted model first (like Claude or OpenAI) to ensure everything works before switching to Ollama. Tool-calling capabilities are limited and may produce inconsistent results. Only LiteLLM supported Ollama models work with HolmesGPT.</p>"},{"location":"ai-providers/ollama/#setup","title":"Setup","text":"<ol> <li>Download Ollama from ollama.com</li> <li>Start Ollama: <code>ollama serve</code></li> <li>Download models: <code>ollama pull &lt;model-name&gt;</code></li> </ol>"},{"location":"ai-providers/ollama/#configuration","title":"Configuration","text":"Holmes CLIHolmes Helm ChartRobusta Helm Chart <pre><code>export OLLAMA_API_BASE=\"http://localhost:11434\"\nholmes ask \"what pods are failing?\" --model=\"ollama_chat/&lt;your-ollama-model&gt;\"\n\n# Or use MODEL environment variable instead of --model flag\nexport MODEL=\"ollama_chat/&lt;your-ollama-model&gt;\"\nholmes ask \"what pods are failing?\"\n</code></pre> <p>Alternative (OpenAI-compatible gateway)</p> <p>If you hit compatibility issues with certain Ollama models via LiteLLM, you can use Ollama's OpenAI-compatible API endpoint:</p> <pre><code>export OPENAI_API_BASE=\"http://localhost:11434/v1\"\nexport OPENAI_API_KEY=\"dummy-key\"  # Required but can be any value\nholmes ask \"what pods are failing?\" --model=\"openai/&lt;your-ollama-model&gt;\"\n\n# Or use MODEL environment variable instead of --model flag\nexport MODEL=\"openai/&lt;your-ollama-model&gt;\"\nholmes ask \"what pods are failing?\"\n</code></pre> <p>Configure Helm Values: <pre><code># values.yaml\nadditionalEnvVars:\n  - name: OLLAMA_API_BASE\n    value: \"http://ollama-service:11434\"\n\n# Configure at least one model using modelList\nmodelList:\n  ollama-llama3:\n    api_base: \"{{ env.OLLAMA_API_BASE }}\"\n    model: ollama_chat/llama3\n    temperature: 1\n\n  ollama-codellama:\n    api_base: \"{{ env.OLLAMA_API_BASE }}\"\n    model: ollama_chat/codellama\n    temperature: 1\n\n# Optional: Set default model (use modelList key name)\nconfig:\n  model: \"ollama-llama3\"  # This refers to the key name in modelList above\n</code></pre></p> <p>Ollama Service</p> <p>You'll need to deploy Ollama as a service in your cluster. The <code>OLLAMA_API_BASE</code> should point to your Ollama service endpoint.</p> <p>Alternative (OpenAI-compatible gateway)</p> <p>If you hit compatibility issues with certain Ollama models via LiteLLM, you can configure an OpenAI-compatible gateway in your Helm values:</p> <pre><code># values.yaml\nadditionalEnvVars:\n  - name: OPENAI_API_BASE\n    value: \"http://ollama-service:11434/v1\"\n  - name: OPENAI_API_KEY\n    value: \"YOUR_BEARER_TOKEN_HERE\"\n\nmodelList:\n  ollama-alt:\n    api_base: \"{{ env.OPENAI_API_BASE }}\"\n    api_key: \"{{ env.OPENAI_API_KEY }}\"\n    model: openai/OLLAMA_MODEL_NAME\n\n# Optional\nconfig:\n  model: \"ollama-alt\"\n</code></pre> <p>Configure Helm Values: <pre><code># values.yaml\nholmes:\n  additionalEnvVars:\n    - name: OLLAMA_API_BASE\n      value: \"http://ollama-service:11434\"\n\n  # Configure at least one model using modelList\n  modelList:\n    ollama-llama3:\n      api_base: \"{{ env.OLLAMA_API_BASE }}\"\n      model: ollama_chat/llama3\n      temperature: 1\n\n    ollama-codellama:\n      api_base: \"{{ env.OLLAMA_API_BASE }}\"\n      model: ollama_chat/codellama\n      temperature: 1\n\n  # Optional: Set default model (use modelList key name)\n  config:\n    model: \"ollama-llama3\"  # This refers to the key name in modelList above\n</code></pre></p> <p>Ollama Service</p> <p>You'll need to deploy Ollama as a service in your cluster. The <code>OLLAMA_API_BASE</code> should point to your Ollama service endpoint.</p> <p>Alternative (OpenAI-compatible gateway)</p> <p>If you hit compatibility issues with certain Ollama models via LiteLLM, you can configure an OpenAI-compatible gateway in your Robusta chart values:</p> <pre><code># values.yaml\nholmes:\n  additionalEnvVars:\n    - name: OPENAI_API_BASE\n      value: \"http://ollama-service:11434/v1\"\n    - name: OPENAI_API_KEY\n      value: \"YOUR_BEARER_TOKEN_HERE\"\n\n  modelList:\n    ollama-alt:\n      api_base: \"{{ env.OPENAI_API_BASE }}\"\n      api_key: \"{{ env.OPENAI_API_KEY }}\"\n      model: openai/OLLAMA_MODEL_NAME\n\n  # Optional\n  config:\n    model: \"ollama-alt\"\n</code></pre>"},{"location":"ai-providers/ollama/#additional-resources","title":"Additional Resources","text":"<p>HolmesGPT uses the LiteLLM API to support Ollama provider. Refer to LiteLLM Ollama docs for more details.</p>"},{"location":"ai-providers/openai-compatible/","title":"OpenAI-Compatible Models","text":"<p>Configure HolmesGPT to use any OpenAI-compatible API.</p> <p>Function Calling Required</p> <p>Your model and inference server must support function calling (tool calling). Models that lack this capability may produce incorrect results.</p>"},{"location":"ai-providers/openai-compatible/#requirements","title":"Requirements","text":"<ul> <li>Function calling support - OpenAI-style tool calling</li> <li>OpenAI-compatible API - Standard endpoints and request/response format</li> </ul>"},{"location":"ai-providers/openai-compatible/#supported-inference-servers","title":"Supported Inference Servers","text":"<ul> <li>llama-cpp-python</li> <li>LocalAI</li> <li>Text Generation WebUI (with OpenAI extension)</li> </ul>"},{"location":"ai-providers/openai-compatible/#configuration","title":"Configuration","text":"Holmes CLIHolmes Helm ChartRobusta Helm Chart <pre><code>export OPENAI_API_BASE=\"http://localhost:8000/v1\"\nexport OPENAI_API_KEY=\"not-needed\"\nholmes ask \"what pods are failing?\" --model=\"openai/&lt;your-model&gt;\"\n</code></pre> <p>Create Kubernetes Secret (if authentication is required): <pre><code>kubectl create secret generic holmes-secrets \\\n  --from-literal=openai-api-key=\"your-api-key-if-needed\" \\\n  -n &lt;namespace&gt;\n</code></pre></p> <p>Configure Helm Values: <pre><code># values.yaml\nadditionalEnvVars:\n  - name: OPENAI_API_BASE\n    value: \"http://your-inference-server:8000/v1\"\n  - name: OPENAI_API_KEY\n    value: \"not-needed\"\n    # OR if authentication is required:\n    # valueFrom:\n    #   secretKeyRef:\n    #     name: holmes-secrets\n    #     key: openai-api-key\n\n# Configure at least one model using modelList\nmodelList:\n  local-llama:\n    api_key: \"not-needed\"\n    api_base: \"{{ env.OPENAI_API_BASE }}\"\n    model: openai/llama3\n    temperature: 1\n\n  custom-model:\n    api_key: \"{{ env.OPENAI_API_KEY }}\"\n    api_base: \"{{ env.OPENAI_API_BASE }}\"\n    model: openai/your-custom-model\n    temperature: 1\n\n# Optional: Set default model (use modelList key name)\nconfig:\n  model: \"local-llama\"  # This refers to the key name in modelList above\n</code></pre></p> <p>Create Kubernetes Secret (if authentication is required): <pre><code>kubectl create secret generic robusta-holmes-secret \\\n  --from-literal=openai-api-key=\"your-api-key-if-needed\" \\\n  -n &lt;namespace&gt;\n</code></pre></p> <p>Configure Helm Values: <pre><code># values.yaml\nholmes:\n  additionalEnvVars:\n    - name: OPENAI_API_BASE\n      value: \"http://your-inference-server:8000/v1\"\n    - name: OPENAI_API_KEY\n      value: \"not-needed\"\n      # OR if authentication is required:\n      # valueFrom:\n      #   secretKeyRef:\n      #     name: robusta-holmes-secret\n      #     key: openai-api-key\n\n  # Configure at least one model using modelList\n  modelList:\n    local-llama:\n      api_key: \"not-needed\"\n      api_base: \"{{ env.OPENAI_API_BASE }}\"\n      model: openai/llama3\n      temperature: 1\n\n    custom-model:\n      api_key: \"{{ env.OPENAI_API_KEY }}\"\n      api_base: \"{{ env.OPENAI_API_BASE }}\"\n      model: openai/your-custom-model\n      temperature: 1\n\n  # Optional: Set default model (use modelList key name)\n  config:\n    model: \"local-llama\"  # This refers to the key name in modelList above\n</code></pre></p>"},{"location":"ai-providers/openai-compatible/#using-cli-parameters","title":"Using CLI Parameters","text":"<p>You can also specify the model directly as a command-line parameter:</p> <pre><code>holmes ask \"what pods are failing?\" --model=\"openai/&lt;your-model&gt;\"\n</code></pre>"},{"location":"ai-providers/openai-compatible/#setup-examples","title":"Setup Examples","text":""},{"location":"ai-providers/openai-compatible/#localai","title":"LocalAI","text":"<pre><code>docker run -p 8080:8080 localai/localai:latest\nexport OPENAI_API_BASE=\"http://localhost:8080/v1\"\n</code></pre>"},{"location":"ai-providers/openai-compatible/#llama-cpp-python","title":"llama-cpp-python","text":"<pre><code>pip install 'llama-cpp-python[server]'\npython -m llama_cpp.server --model model.gguf --chat_format chatml\nexport OPENAI_API_BASE=\"http://localhost:8000/v1\"\nholmes ask \"analyze my deployment\" --model=openai/your-loaded-model\n</code></pre>"},{"location":"ai-providers/openai-compatible/#custom-ssl-certificates","title":"Custom SSL Certificates","text":"<p>If your LLM provider uses a custom Certificate Authority (CA):</p> <pre><code># Base64 encode your certificate and set it as an environment variable\nexport CERTIFICATE=\"base64-encoded-cert-here\"\n</code></pre>"},{"location":"ai-providers/openai-compatible/#known-limitations","title":"Known Limitations","text":"<ul> <li>vLLM: Does not yet support function calling</li> <li>Text Generation WebUI: Requires OpenAI extension enabled</li> <li>Some models: May hallucinate responses instead of reporting function calling limitations</li> </ul>"},{"location":"ai-providers/openai-compatible/#additional-resources","title":"Additional Resources","text":"<p>HolmesGPT uses the LiteLLM API to support OpenAI-compatible providers. Refer to LiteLLM OpenAI-compatible docs for more details.</p>"},{"location":"ai-providers/openai/","title":"OpenAI","text":"<p>Configure HolmesGPT to use OpenAI's GPT models.</p>"},{"location":"ai-providers/openai/#setup","title":"Setup","text":"<p>Get a paid OpenAI API key.</p> <p>Note</p> <p>Requires a paid OpenAI API key, not a ChatGPT Plus subscription.</p>"},{"location":"ai-providers/openai/#configuration","title":"Configuration","text":"Holmes CLIHolmes Helm ChartRobusta Helm Chart <p>Using Environment Variables: <pre><code>export OPENAI_API_KEY=\"your-openai-api-key\"\nholmes ask \"what pods are failing?\"\n</code></pre></p> <p>Using Command Line Parameters:</p> <p>You can also pass the API key directly as a command-line parameter: <pre><code>holmes ask \"what pods are failing?\" --api-key=\"your-api-key\"\n</code></pre></p> <p>Create Kubernetes Secret: <pre><code>kubectl create secret generic holmes-secrets \\\n  --from-literal=openai-api-key=\"sk-...\" \\\n  -n &lt;namespace&gt;\n</code></pre></p> <p>Configure Helm Values: <pre><code># values.yaml\nadditionalEnvVars:\n  - name: OPENAI_API_KEY\n    valueFrom:\n      secretKeyRef:\n        name: holmes-secrets\n        key: openai-api-key\n\n# Configure at least one model using modelList\nmodelList:\n  gpt-4.1:\n    api_key: \"{{ env.OPENAI_API_KEY }}\"\n    model: openai/gpt-4.1\n    temperature: 0\n\n  gpt-5:\n    api_key: \"{{ env.OPENAI_API_KEY }}\"\n    model: openai/gpt-5\n    temperature: 1\n    reasoning_effort: medium\n\n# Optional: Set default model (use modelList key name)\nconfig:\n  model: \"gpt-4.1\"  # This refers to the key name in modelList above\n</code></pre></p> <p>Create Kubernetes Secret:</p> <pre><code>kubectl create secret generic robusta-holmes-secret \\\n  --from-literal=openai-api-key=\"sk-...\" \\\n  -n &lt;namespace&gt;\n</code></pre> <p>Configure Helm Values:</p> <pre><code># values.yaml\nholmes:\n  additionalEnvVars:\n    - name: OPENAI_API_KEY\n      valueFrom:\n        secretKeyRef:\n          name: robusta-holmes-secret\n          key: openai-api-key\n\n  # Configure at least one model using modelList\n  modelList:\n    gpt-4.1:\n      api_key: \"{{ env.OPENAI_API_KEY }}\"\n      model: openai/gpt-4.1\n      temperature: 0\n\n    gpt-5:\n      api_key: \"{{ env.OPENAI_API_KEY }}\"\n      model: openai/gpt-5\n      temperature: 1\n      reasoning_effort: medium\n\n  # Optional: Set default model (use modelList key name)\n  config:\n    model: \"gpt-4.1\"  # This refers to the key name in modelList above\n</code></pre>"},{"location":"ai-providers/openai/#available-models","title":"Available Models","text":"<p>Most OpenAI models are supported. For example:</p> <pre><code># GPT-4.1 (default) - fast and decent responses\nholmes ask \"what pods are failing?\"\n\n# GPT-5 (more accurate but much slower)\nholmes ask \"what pods are failing?\" --model=\"gpt-5\"\n</code></pre> <p>Best Results</p> <p>For more accurate results, consider using Anthropic's Claude models.</p> <p>See benchmark results for a comparison.</p>"},{"location":"ai-providers/openai/#gpt-5-reasoning-effort","title":"GPT-5 Reasoning Effort","text":"<p>When using GPT-5 models, you can control the reasoning effort level. This allows you to balance between response quality and processing time/cost.</p> Holmes CLIHolmes Helm ChartRobusta Helm Chart <p>Using Environment Variables: <pre><code># Use minimal reasoning effort for faster responses\nexport REASONING_EFFORT=\"minimal\"\nholmes ask \"what pods are failing?\" --model=\"gpt-5\"\n\n# Use default reasoning effort\nexport REASONING_EFFORT=\"medium\"\nholmes ask \"what pods are failing?\" --model=\"gpt-5\"\n\n# Use high reasoning effort for complex investigations\nexport REASONING_EFFORT=\"high\"\nholmes ask \"what pods are failing?\" --model=\"gpt-5\"\n</code></pre></p> <p>Configure in modelList: <pre><code># values.yaml\nmodelList:\n  gpt-5-minimal:\n    api_key: \"{{ env.OPENAI_API_KEY }}\"\n    model: openai/gpt-5\n    temperature: 1\n    reasoning_effort: minimal  # Fast responses\n\n  gpt-5-medium:\n    api_key: \"{{ env.OPENAI_API_KEY }}\"\n    model: openai/gpt-5\n    temperature: 1\n    reasoning_effort: medium  # Balanced (default)\n\n  gpt-5-high:\n    api_key: \"{{ env.OPENAI_API_KEY }}\"\n    model: openai/gpt-5\n    temperature: 1\n    reasoning_effort: high  # Complex investigations\n\n# Use the appropriate model based on your needs\nconfig:\n  model: \"gpt-5-medium\"\n</code></pre></p> <p>Configure in modelList: <pre><code># values.yaml\nholmes:\n  modelList:\n    gpt-5-minimal:\n      api_key: \"{{ env.OPENAI_API_KEY }}\"\n      model: openai/gpt-5\n      temperature: 1\n      reasoning_effort: minimal  # Fast responses\n\n    gpt-5-medium:\n      api_key: \"{{ env.OPENAI_API_KEY }}\"\n      model: openai/gpt-5\n      temperature: 1\n      reasoning_effort: medium  # Balanced (default)\n\n    gpt-5-high:\n      api_key: \"{{ env.OPENAI_API_KEY }}\"\n      model: openai/gpt-5\n      temperature: 1\n      reasoning_effort: high  # Complex investigations\n\n  # Use the appropriate model based on your needs\n  config:\n    model: \"gpt-5-medium\"\n</code></pre></p> <p>Available reasoning effort levels:</p> <ul> <li><code>minimal</code> - Fastest responses, suitable for simple queries</li> <li><code>low</code> - Balance between speed and quality</li> <li><code>medium</code> - Standard reasoning depth (default)</li> <li><code>high</code> - Deeper reasoning for complex problems</li> </ul> <p>For more details on reasoning effort levels, refer to the OpenAI documentation.</p>"},{"location":"ai-providers/openai/#additional-resources","title":"Additional Resources","text":"<p>HolmesGPT uses the LiteLLM API to support OpenAI provider. Refer to LiteLLM OpenAI docs for more details.</p>"},{"location":"ai-providers/other/","title":"Other","text":"<p>HolmesGPT supports all AI providers available through LiteLLM, including 100+ different LLM providers. This guide shows how to configure any LiteLLM-supported provider using DeepSeek via Novita as an example.</p>"},{"location":"ai-providers/other/#example-deepseek-31-terminus-via-novita","title":"Example: DeepSeek 3.1 Terminus via Novita","text":"<p>Let's walk through setting up DeepSeek 3.1 Terminus using the Novita AI provider.</p>"},{"location":"ai-providers/other/#step-1-check-litellm-documentation","title":"Step 1: Check LiteLLM Documentation","text":"<p>First, visit the LiteLLM Novita documentation to understand the provider requirements:</p> <ul> <li>Model naming format: <code>novita/&lt;model-name&gt;</code></li> <li>Required environment variable: <code>NOVITA_API_KEY</code></li> </ul>"},{"location":"ai-providers/other/#step-2-get-your-api-key","title":"Step 2: Get Your API Key","text":"<p>Sign up at Novita AI to obtain your API key.</p>"},{"location":"ai-providers/other/#step-3-configure-holmesgpt","title":"Step 3: Configure HolmesGPT","text":"<p>Model Not in LiteLLM Registry</p> <p>Since DeepSeek 3.1 Terminus via Novita isn't in LiteLLM's model registry, you'll see warnings about using default token limits (200K input, 4k output). To fix this, set the correct values based on the model's actual capabilities when run via Novita:</p> <ul> <li>Context window: 98,304 tokens</li> <li>Max output: 32,768 tokens</li> </ul> Holmes CLIHolmes Helm ChartRobusta Helm Chart <p>Set the API key and token limits: <pre><code>export NOVITA_API_KEY=\"your-novita-api-key\"\n\n# Override the default token limits with correct values\nexport OVERRIDE_MAX_CONTENT_SIZE=98304  # 98k context window\nexport OVERRIDE_MAX_OUTPUT_TOKEN=32768   # 32k max output\n</code></pre></p> <p>Use the model: <pre><code>holmes ask \"what pods are failing?\" --model=\"novita/deepseek/deepseek-v3.1-terminus\"\n</code></pre></p> <p>Or pass the API key directly: <pre><code>OVERRIDE_MAX_CONTENT_SIZE=98304 OVERRIDE_MAX_OUTPUT_TOKEN=32768 \\\nholmes ask \"what pods are failing?\" \\\n  --model=\"novita/deepseek/deepseek-v3.1-terminus\" \\\n  --api-key=\"your-novita-api-key\"\n</code></pre></p> <p>Option 1: Using Kubernetes Secret (Recommended): <pre><code>kubectl create secret generic holmes-secrets \\\n  --from-literal=novita-api-key=\"your-novita-api-key\" \\\n  -n &lt;namespace&gt;\n</code></pre></p> <pre><code># values.yaml\nadditionalEnvVars:\n  - name: NOVITA_API_KEY\n    valueFrom:\n      secretKeyRef:\n        name: holmes-secrets\n        key: novita-api-key\n\nmodelList:\n  deepseek-terminus:\n    model: novita/deepseek/deepseek-v3.1-terminus\n    api_key: \"{{ env.NOVITA_API_KEY }}\"\n    custom_args:\n      max_context_size: 98304  # Override context window to 98k tokens\n</code></pre> <p>Option 2: Direct Value (Less Secure):</p> <p>Warning</p> <p>This method stores the API key in plain text in your values file. Use Kubernetes Secrets for production environments.</p> <pre><code># values.yaml\nadditionalEnvVars:\n  - name: NOVITA_API_KEY\n    value: \"your-novita-api-key\"  # API key directly in values file\n\nmodelList:\n  deepseek-terminus:\n    model: novita/deepseek/deepseek-v3.1-terminus\n    api_key: \"{{ env.NOVITA_API_KEY }}\"\n    custom_args:\n      max_context_size: 98304  # Override context window to 98k tokens\n</code></pre> <p>Option 1: Using Kubernetes Secret (Recommended): <pre><code>kubectl create secret generic robusta-holmes-secret \\\n  --from-literal=novita-api-key=\"your-novita-api-key\" \\\n  -n &lt;namespace&gt;\n</code></pre></p> <pre><code># values.yaml\nholmes:\n  additionalEnvVars:\n    - name: NOVITA_API_KEY\n      valueFrom:\n        secretKeyRef:\n          name: robusta-holmes-secret\n          key: novita-api-key\n\n  modelList:\n    deepseek-terminus:\n      model: novita/deepseek/deepseek-v3.1-terminus\n      api_key: \"{{ env.NOVITA_API_KEY }}\"\n      custom_args:\n        max_context_size: 98304  # Override context window to 98k tokens\n</code></pre> <p>Option 2: Direct Value (Less Secure):</p> <p>Warning</p> <p>This method stores the API key in plain text in your values file. Use Kubernetes Secrets for production environments.</p> <pre><code># values.yaml\nholmes:\n  additionalEnvVars:\n    - name: NOVITA_API_KEY\n      value: \"your-novita-api-key\"  # API key directly in values file\n\n  modelList:\n    deepseek-terminus:\n      model: novita/deepseek/deepseek-v3.1-terminus\n      api_key: \"{{ env.NOVITA_API_KEY }}\"\n      custom_args:\n        max_context_size: 98304  # Override context window to 98k tokens\n</code></pre>"},{"location":"ai-providers/other/#general-model-configuration-parameters","title":"General Model Configuration Parameters","text":"<p>When configuring models in <code>modelList</code>, you can use these parameters:</p> <p>Core Parameters: <pre><code>modelList:\n  my-model:\n    # Required: LiteLLM model identifier\n    model: \"provider/model-name\"\n\n    # Optional: Authentication\n    api_key: \"{{ env.API_KEY }}\"  # Supports environment variables\n\n    # Optional: Custom endpoints\n    api_base: \"https://custom-endpoint.example.com/v1\"  # Custom API URL\n    api_version: \"2024-01-01\"  # API version (e.g., for Azure)\n</code></pre></p> <p>Advanced Parameters: <pre><code>modelList:\n  advanced-model:\n    model: \"provider/model-name\"\n    api_key: \"{{ env.API_KEY }}\"\n\n    # GPT-5 specific\n    reasoning_effort: \"medium\"  # Options: minimal, low, medium, high\n\n    # Thinking mode (experimental, model-specific)\n    thinking: true  # Enable thinking mode if supported by the model\n\n    # Override context window size for any model\n    custom_args:\n      max_context_size: 1000000  # Override the model's context window\n</code></pre></p> <p>Context Window Override</p> <p>The <code>custom_args.max_context_size</code> parameter can be used with any model to override its default context window size. This is particularly useful when the model's actual context window is different from what LiteLLM reports.</p> <p>This parameter takes precedence over the <code>OVERRIDE_MAX_CONTENT_SIZE</code> environment variable, giving you per-model control when using modelList configuration.</p> <p>Example: If your model isn't recognized by LiteLLM and defaults to 200k tokens, but it actually supports 1M tokens: <pre><code>modelList:\n  my-model:\n    model: provider/model-name\n    api_key: \"{{ env.API_KEY }}\"\n    custom_args:\n      max_context_size: 1000000  # Override to 1M tokens\n</code></pre></p> <p>Parameter Passthrough</p> <p>Any additional parameters not listed here (like <code>temperature</code>, <code>max_tokens</code>, etc.) are passed directly to the LiteLLM completion API. Refer to your provider's documentation for supported parameters.</p>"},{"location":"ai-providers/other/#finding-other-providers","title":"Finding Other Providers","text":"<p>To use any other LiteLLM-supported provider, follow the same pattern:</p> <ol> <li>Check the provider's page in LiteLLM documentation</li> <li>Note the required environment variables and model naming format</li> <li>Configure using the same structure shown above</li> </ol>"},{"location":"ai-providers/other/#additional-resources","title":"Additional Resources","text":"<ul> <li>LiteLLM Providers: Full list at LiteLLM Providers</li> </ul>"},{"location":"ai-providers/robusta-ai/","title":"Robusta AI","text":"<p>Access multiple AI models from different providers through Robusta's unified API, without managing individual API keys.</p> <p>Robusta SaaS Feature</p> <p>Robusta AI is available exclusively for Robusta SaaS customers running HolmesGPT in Kubernetes. It provides access to various AI models through a single managed endpoint.</p>"},{"location":"ai-providers/robusta-ai/#overview","title":"Overview","text":"<p>Robusta AI simplifies AI model access by:</p> <ul> <li>Multi-provider access: Access a wide variety of models from different providers (OpenAI, Anthropic, and others) through a single interface</li> <li>No API key management: Use models from multiple providers without managing individual API keys</li> </ul>"},{"location":"ai-providers/robusta-ai/#prerequisites","title":"Prerequisites","text":"<ol> <li>Robusta SaaS account: You must have an active Robusta platform subscription</li> <li>Kubernetes deployment: Robusta AI is only available when running HolmesGPT as a server in Kubernetes (not available in CLI mode)</li> <li>Robusta platform integration: Your cluster must be connected to the Robusta platform with a valid <code>robusta_sink</code> token</li> <li>Robusta version: Requires Robusta version 0.22.0 or higher</li> <li>Robusta UI sink enabled: The Robusta UI sink must be configured and operational</li> </ol>"},{"location":"ai-providers/robusta-ai/#configuration","title":"Configuration","text":"<p>Robusta AI is automatically enabled when:</p> <ol> <li>HolmesGPT is deployed in Kubernetes via the Robusta Helm chart</li> <li>A valid Robusta sink is configured in the Robusta Helm Chart</li> <li>The <code>ROBUSTA_AI</code> environment variable is set to <code>true</code></li> </ol>"},{"location":"ai-providers/robusta-ai/#quick-setup","title":"Quick Setup","text":"<p>The simplest way to enable HolmesGPT with Robusta AI is to add this to your Robusta Helm values:</p> <pre><code># Add to generated_values.yaml\nenableHolmesGPT: true\n</code></pre> <p>This automatically:</p> <ol> <li>Deploys HolmesGPT as a server in Kubernetes</li> <li>Enables Robusta AI integration</li> <li>Sets up the necessary authentication</li> </ol>"},{"location":"ai-providers/robusta-ai/#manual-configuration","title":"Manual Configuration","text":"<p>For more granular control, you can manually configure Robusta AI:</p> <pre><code># Add to generated_values.yaml\nholmes:\n  additionalEnvVars:\n    - name: ROBUSTA_AI\n      value: \"true\"\n</code></pre>"},{"location":"ai-providers/robusta-ai/#using-existing-robusta-tokens-in-secrets","title":"Using Existing Robusta Tokens in Secrets","text":"<p>If your Robusta token is already stored in a Kubernetes secret (common in existing Robusta deployments), you can reference it in HolmesGPT configuration:</p> <pre><code># Add to generated_values.yaml\nholmes:\n  additionalEnvVars:\n    - name: ROBUSTA_TOKEN\n      valueFrom:\n        secretKeyRef:\n          name: robusta-token-secret\n          key: token\n    - name: ROBUSTA_AI\n      value: \"true\"\n</code></pre> <p>Common scenarios for existing secrets:</p> <ul> <li>Existing Robusta UI sink: If you already have a <code>robusta_sink</code> configured, the token is typically stored in a secret named <code>robusta-token</code> or similar</li> <li>Multi-environment deployments: Use the same secret across different namespaces or clusters</li> <li>GitOps workflows: Reference existing secrets managed by ArgoCD or Flux</li> </ul> <p>In most cases, no additional configuration is needed. If you have a valid Robusta deployment, HolmesGPT will automatically:</p> <ol> <li>Authenticate with the Robusta platform</li> <li>Fetch available models for your account</li> <li>Make them available for selection</li> </ol>"},{"location":"ai-providers/robusta-ai/#disabling-robusta-ai","title":"Disabling Robusta AI","text":"<p>To explicitly disable Robusta AI (for example, if you prefer using your own API keys):</p> <pre><code># Add to generated_values.yaml\nholmes:\n  additionalEnvVars:\n    - name: ROBUSTA_AI\n      value: \"false\"\n</code></pre>"},{"location":"ai-providers/robusta-ai/#how-it-works","title":"How It Works","text":"<ol> <li>Authentication: HolmesGPT reads your Robusta token from the cluster configuration</li> <li>Session creation: A session token is created with the Robusta platform</li> <li>Model discovery: Available models are fetched from <code>https://api.robusta.dev/api/llm/models/v2</code></li> <li>Proxy access: Models are accessed through Robusta's proxy endpoint at <code>https://api.robusta.dev/llm/{model_name}</code></li> <li>Automatic refresh: Authentication tokens are automatically refreshed when they expire</li> </ol>"},{"location":"ai-providers/robusta-ai/#available-models","title":"Available Models","text":"<p>The specific models available depend on your Robusta subscription plan. Typically includes:</p> <ul> <li>OpenAI models (GPT-4o, GPT-4.1, GPT-5, etc.)</li> <li>Anthropic models (Claude 4.0 Sonnet, etc.)</li> </ul>"},{"location":"ai-providers/robusta-ai/#usage","title":"Usage","text":"<p>When Robusta AI is enabled, models appear in the model selector dropdown in the Robusta UI. Users can select any available model for their investigations.</p> <p></p>"},{"location":"ai-providers/robusta-ai/#troubleshooting","title":"Troubleshooting","text":""},{"location":"ai-providers/robusta-ai/#models-not-appearing","title":"Models not appearing","text":"<p>Check that:</p> <ol> <li>Your Robusta token is valid and not expired</li> <li>HolmesGPT can reach <code>api.robusta.dev</code></li> <li><code>ROBUSTA_AI</code> is set to <code>true</code></li> <li>Check logs for authentication errors</li> </ol>"},{"location":"ai-providers/robusta-ai/#environment-variables","title":"Environment Variables","text":"Variable Description Default <code>ROBUSTA_AI</code> Enable/disable Robusta AI Auto-detected <code>ROBUSTA_API_ENDPOINT</code> Robusta API endpoint (different for on-premise users) <code>https://api.robusta.dev</code>"},{"location":"ai-providers/robusta-ai/#see-also","title":"See Also","text":"<ul> <li>Using Multiple Providers - Configure multiple AI providers</li> <li>Kubernetes Installation - Deploy HolmesGPT in Kubernetes</li> <li>Robusta Platform Documentation - Learn more about Robusta platform integration</li> </ul>"},{"location":"ai-providers/using-multiple-providers/","title":"Using Multiple Providers","text":"<p>Configure multiple AI providers to give users flexibility in choosing models for investigations.</p> <p>Robusta UI and HTTP API Feature</p> <p>Multiple provider configuration impacts investigations run from the Robusta UI and other HTTP API clients. When multiple providers are defined, users can select which model to use from a dropdown in the UI, or specify a <code>model</code> parameter when using the HTTP API directly. This feature does not affect CLI usage.</p>"},{"location":"ai-providers/using-multiple-providers/#configuration","title":"Configuration","text":"<p>Configure multiple models using the <code>modelList</code> parameter in your Helm values, along with the necessary environment variables.</p>"},{"location":"ai-providers/using-multiple-providers/#step-1-create-the-kubernetes-secret","title":"Step 1: Create the Kubernetes Secret","text":"<p>First, create a secret with your API keys (only include the ones you need):</p> <pre><code># Example with all providers - only include what you're using\nkubectl create secret generic holmes-secrets \\\n  --from-literal=openai-api-key=\"sk-...\" \\\n  --from-literal=anthropic-api-key=\"sk-ant-...\" \\\n  --from-literal=azure-api-key=\"...\" \\\n  --from-literal=aws-access-key-id=\"AKIA...\" \\\n  --from-literal=aws-secret-access-key=\"...\" \\\n  -n &lt;namespace&gt;\n\n# Example with just OpenAI and Anthropic\nkubectl create secret generic holmes-secrets \\\n  --from-literal=openai-api-key=\"sk-...\" \\\n  --from-literal=anthropic-api-key=\"sk-ant-...\" \\\n  -n &lt;namespace&gt;\n</code></pre>"},{"location":"ai-providers/using-multiple-providers/#step-2-configure-helm-values","title":"Step 2: Configure Helm Values","text":"<pre><code># values.yaml\n# Reference only the API keys you created in the secret\nadditionalEnvVars:\n  - name: AZURE_API_KEY\n    valueFrom:\n      secretKeyRef:\n        name: holmes-secrets\n        key: azure-api-key\n  - name: ANTHROPIC_API_KEY\n    valueFrom:\n      secretKeyRef:\n        name: holmes-secrets\n        key: anthropic-api-key\n  - name: AWS_ACCESS_KEY_ID\n    valueFrom:\n      secretKeyRef:\n        name: holmes-secrets\n        key: aws-access-key-id\n  - name: AWS_SECRET_ACCESS_KEY\n    valueFrom:\n      secretKeyRef:\n        name: holmes-secrets\n        key: aws-secret-access-key\n  - name: OPENAI_API_KEY\n    valueFrom:\n      secretKeyRef:\n        name: holmes-secrets\n        key: openai-api-key\n\n# Configure the model list using the environment variables\nmodelList:\n  # Standard OpenAI\n  openai-4.1:\n    api_key: \"{{ env.OPENAI_API_KEY }}\"\n    model: openai/gpt-4.1\n    temperature: 0\n\n  # Azure OpenAI Models\n  azure-41:\n    api_key: \"{{ env.AZURE_API_KEY }}\"\n    model: azure/gpt-4.1\n    api_base: https://your-resource.openai.azure.com/\n    api_version: \"2025-01-01-preview\"\n    temperature: 0\n\n  azure-gpt-5:\n    api_key: \"{{ env.AZURE_API_KEY }}\"\n    model: azure/gpt-5\n    api_base: https://your-resource.openai.azure.com/\n    api_version: \"2025-01-01-preview\"\n    temperature: 1 # only 1 is supported for gpt-5 models\n\n  # Anthropic Models\n  claude-sonnet-4:\n    api_key: \"{{ env.ANTHROPIC_API_KEY }}\"\n    model: claude-sonnet-4-20250514\n    temperature: 1\n    thinking:\n      budget_tokens: 10000\n      type: enabled\n\n  claude-opus-4-1:\n    api_key: \"{{ env.ANTHROPIC_API_KEY }}\"\n    model: claude-opus-4-1-20250805\n    temperature: 0\n\n  # AWS Bedrock\n  bedrock-claude:\n    aws_access_key_id: \"{{ env.AWS_ACCESS_KEY_ID }}\"\n    aws_region_name: us-east-1\n    aws_secret_access_key: \"{{ env.AWS_SECRET_ACCESS_KEY }}\"\n    model: bedrock/anthropic.claude-sonnet-4-20250514-v1:0\n    temperature: 1\n    thinking:\n      budget_tokens: 10000\n      type: enabled\n</code></pre>"},{"location":"ai-providers/using-multiple-providers/#model-parameters","title":"Model Parameters","text":"<p>Each model in <code>modelList</code> can accept any parameter supported by LiteLLM for that provider. The <code>model</code> parameter is required, while authentication requirements vary by provider. Any additional LiteLLM parameters will be passed directly through to the provider.</p>"},{"location":"ai-providers/using-multiple-providers/#required-parameter","title":"Required Parameter","text":"<ul> <li><code>model</code>: Model identifier (provider-specific format)</li> </ul>"},{"location":"ai-providers/using-multiple-providers/#common-parameters","title":"Common Parameters","text":"<ul> <li><code>api_key</code>: API key for authentication where required (can use <code>{{ env.VAR_NAME }}</code> syntax)</li> <li><code>temperature</code>: Creativity level (0-2, lower is more deterministic)</li> </ul>"},{"location":"ai-providers/using-multiple-providers/#additional-parameters","title":"Additional Parameters","text":"<p>You can pass any LiteLLM-supported parameter for your provider. Examples include:</p> <ul> <li>Azure: <code>api_base</code>, <code>api_version</code>, <code>deployment_id</code></li> <li>Anthropic: <code>thinking</code> (with <code>budget_tokens</code> and <code>type</code>)</li> <li>AWS Bedrock: <code>aws_access_key_id</code>, <code>aws_secret_access_key</code>, <code>aws_region_name</code>, <code>aws_session_token</code></li> <li>Google Vertex: <code>vertex_project</code>, <code>vertex_location</code></li> </ul> <p>Refer to LiteLLM documentation for the complete list of parameters supported by each provider.</p>"},{"location":"ai-providers/using-multiple-providers/#user-experience","title":"User Experience","text":"<p>When multiple models are configured:</p>"},{"location":"ai-providers/using-multiple-providers/#robusta-ui","title":"Robusta UI","text":"<ol> <li>Users see a model selector dropdown in the Robusta UI</li> <li>Each model appears with its configured name (e.g., \"azure-4o\", \"claude-sonnet-4\")</li> <li>Users can switch between models for different investigations</li> </ol>"},{"location":"ai-providers/using-multiple-providers/#http-api","title":"HTTP API","text":"<p>Clients can specify the model in their API requests: <pre><code>{\n  \"ask\": \"What pods are failing?\",\n  \"model\": \"claude-sonnet-4\"\n}\n</code></pre></p>"},{"location":"ai-providers/using-multiple-providers/#robusta-ai-integration","title":"Robusta AI Integration","text":"<p>If you're a Robusta SaaS customer, you can also use Robusta AI which provides access to multiple models without managing individual API keys.</p>"},{"location":"ai-providers/using-multiple-providers/#best-practices","title":"Best Practices","text":"<ol> <li>Secure API keys: Always use Kubernetes secrets for API keys</li> <li>Model recommendations: For best results, consider using Anthropic's Claude Opus 4.1 or Claude Sonnet 4 models. GPT-4.1 provides a good balance of speed and capability as an alternative. See benchmark results for detailed model performance comparisons.</li> </ol>"},{"location":"ai-providers/using-multiple-providers/#limitations","title":"Limitations","text":"<ul> <li>No automatic failover: If a selected model fails, clients must manually switch to another model</li> </ul>"},{"location":"ai-providers/using-multiple-providers/#see-also","title":"See Also","text":"<ul> <li>UI Installation</li> <li>Helm Configuration</li> <li>Individual provider documentation for specific configuration details</li> </ul>"},{"location":"data-sources/","title":"Data Sources","text":"<p>HolmesGPT connects to your monitoring and observability tools to provide comprehensive root cause analysis.</p>"},{"location":"data-sources/#available-options","title":"Available Options","text":"<ul> <li> <p>Built-in Toolsets</p> <p>Pre-configured integrations for popular tools like Prometheus, Grafana, DataDog, and more.</p> </li> <li> <p>Custom Toolsets</p> <p>Create your own integrations for proprietary or specialized tools.</p> </li> <li> <p>Remote MCP Servers</p> <p>Connect to Model Context Protocol servers for extended capabilities.</p> </li> </ul>"},{"location":"data-sources/custom-toolsets/","title":"Custom Toolsets","text":"<p>If the built-in toolsets don't meet your needs, you can extend HolmesGPT's investigation capabilities by creating custom toolsets. This is especially useful for unique use cases, proprietary tools, or specialized infrastructure setups. Examples include advanced log analysis tools, external monitoring integrations, or custom diagnostic scripts.</p> <p>By creating custom toolsets, you can ensure HolmesGPT has access to all the data sources and tools necessary for thorough investigations in your specific environment.</p>"},{"location":"data-sources/custom-toolsets/#examples","title":"Examples","text":"<p>Below are three examples of how to create custom toolsets for different scenarios.</p>"},{"location":"data-sources/custom-toolsets/#example-1-grafana-toolset","title":"Example 1: Grafana Toolset","text":"<p>This example creates a toolset that helps HolmesGPT view and suggest relevant Grafana dashboards.</p> Holmes CLIRobusta Helm Chart <p>Configuration File (<code>toolsets.yaml</code>):</p> <pre><code>toolsets:\n  grafana:\n    description: \"View and suggest Grafana dashboards\"\n    prerequisites: \"Grafana instance accessible from HolmesGPT\"\n    tags: [monitoring, observability]\n    installation: |\n      1. Ensure Grafana is accessible from HolmesGPT\n      2. Configure Grafana API credentials if authentication is required\n    tools:\n      - name: view_dashboard\n        description: \"View a specific Grafana dashboard by ID or name\"\n        command: |\n          curl -s \"${GRAFANA_URL}/api/dashboards/uid/{{ dashboard_uid }}\" \\\n            -H \"Authorization: Bearer ${GRAFANA_TOKEN}\"\n        additionalInstructions: |\n          Parse the JSON response to extract dashboard information.\n          If dashboard is not found, suggest similar dashboards.\n\n      - name: search_dashboards\n        description: \"Search for dashboards related to specific keywords\"\n        command: |\n          curl -s \"${GRAFANA_URL}/api/search?query={{ search_query }}\" \\\n            -H \"Authorization: Bearer ${GRAFANA_TOKEN}\"\n        additionalInstructions: |\n          Return the most relevant dashboards based on the search query.\n          Include dashboard URLs for easy access.\n</code></pre> <p>Environment Variables:</p> <pre><code>export GRAFANA_URL=\"http://grafana.monitoring.svc.cluster.local:3000\"\nexport GRAFANA_TOKEN=\"your-grafana-api-token\"\n</code></pre> <p>Run HolmesGPT:</p> <pre><code>holmes ask \"show me dashboards related to CPU usage\" --toolsets=toolsets.yaml\n</code></pre> <p>After making changes to your toolsets file, run: <pre><code>holmes toolset refresh\n</code></pre></p> <p>Helm Values:</p> <pre><code>holmes:\n  customToolsets:\n    grafana:\n      description: \"View and suggest Grafana dashboards\"\n      prerequisites: \"Grafana instance accessible from HolmesGPT\"\n      tags: [monitoring, observability]\n      installation: |\n        1. Ensure Grafana is accessible from HolmesGPT\n        2. Configure Grafana API credentials if authentication is required\n      tools:\n        - name: view_dashboard\n          description: \"View a specific Grafana dashboard by ID or name\"\n          command: |\n            curl -s \"{{ grafana_url }}/api/dashboards/uid/{{ dashboard_uid }}\" \\\n              -H \"Authorization: Bearer {{ grafana_token }}\"\n          additionalInstructions: |\n            Parse the JSON response to extract dashboard information.\n            If dashboard is not found, suggest similar dashboards.\n\n        - name: search_dashboards\n          description: \"Search for dashboards related to specific keywords\"\n          command: |\n            curl -s \"{{ grafana_url }}/api/search?query={{ search_query }}\" \\\n              -H \"Authorization: Bearer {{ grafana_token }}\"\n          additionalInstructions: |\n            Return the most relevant dashboards based on the search query.\n            Include dashboard URLs for easy access.\n</code></pre> <p>Environment Variables:</p> <pre><code>export GRAFANA_URL=\"http://grafana.monitoring.svc.cluster.local:3000\"\nexport GRAFANA_TOKEN=\"your-grafana-api-token\"\n</code></pre> <p>Helm Upgrade:</p> <pre><code>helm upgrade robusta robusta/robusta --values=generated_values.yaml --set clusterName=&lt;YOUR_CLUSTER_NAME&gt;\n</code></pre>"},{"location":"data-sources/custom-toolsets/#example-2-kubernetes-diagnostics-toolset","title":"Example 2: Kubernetes Diagnostics Toolset","text":"<p>This example creates a toolset with advanced diagnostic tools for Kubernetes clusters.</p> Holmes CLIRobusta Helm Chart <p>Configuration File (<code>toolsets.yaml</code>):</p> <pre><code>toolsets:\n  k8s-diagnostics:\n    description: \"Advanced Kubernetes diagnostic tools\"\n    prerequisites: \"kubectl access to the cluster\"\n    tags: [kubernetes, diagnostics]\n    installation: |\n      1. Ensure kubectl is configured with cluster access\n      2. Verify necessary RBAC permissions are in place\n    tools:\n      - name: check_node_pressure\n        description: \"Check for node pressure conditions and resource usage\"\n        command: |\n          kubectl get nodes -o json | jq -r '\n            .items[] |\n            select(.status.conditions[]? | select(.type == \"MemoryPressure\" or .type == \"DiskPressure\" or .type == \"PIDPressure\") | .status == \"True\") |\n            .metadata.name + \": \" + (.status.conditions[] | select(.type == \"MemoryPressure\" or .type == \"DiskPressure\" or .type == \"PIDPressure\") | .type + \" = \" + .status)\n          '\n        additionalInstructions: |\n          If any nodes show pressure conditions, investigate further and suggest remediation steps.\n\n      - name: analyze_pod_distribution\n        description: \"Analyze pod distribution across nodes in a namespace\"\n        command: |\n          kubectl get pods -n {{ namespace }} -o wide --no-headers |\n          awk '{print $7}' | sort | uniq -c | sort -nr\n        additionalInstructions: |\n          Check for uneven pod distribution that might indicate scheduling issues.\n          Suggest rebalancing if necessary.\n\n      - name: check_resource_quotas\n        description: \"Check resource quota usage in a namespace\"\n        command: |\n          kubectl describe resourcequota -n {{ namespace }}\n        additionalInstructions: |\n          Alert if resource quotas are close to limits. Suggest scaling or quota adjustments.\n</code></pre> <p>Run HolmesGPT:</p> <pre><code>holmes ask \"check for any resource pressure in the cluster\" --toolsets=toolsets.yaml\n</code></pre> <p>After making changes to your toolsets file, run: <pre><code>holmes toolset refresh\n</code></pre></p> <p>Helm Values:</p> <pre><code>holmes:\n  customToolsets:\n    k8s-diagnostics:\n      description: \"Advanced Kubernetes diagnostic tools\"\n      prerequisites: \"kubectl access to the cluster\"\n      tags: [kubernetes, diagnostics]\n      installation: |\n        1. Ensure kubectl is configured with cluster access\n        2. Verify necessary RBAC permissions are in place\n      tools:\n        - name: check_node_pressure\n          description: \"Check for node pressure conditions and resource usage\"\n          command: |\n            kubectl get nodes -o json | jq -r '\n              .items[] |\n              select(.status.conditions[]? | select(.type == \"MemoryPressure\" or .type == \"DiskPressure\" or .type == \"PIDPressure\") | .status == \"True\") |\n              .metadata.name + \": \" + (.status.conditions[] | select(.type == \"MemoryPressure\" or .type == \"DiskPressure\" or .type == \"PIDPressure\") | .type + \" = \" + .status)\n            '\n          additionalInstructions: |\n            If any nodes show pressure conditions, investigate further and suggest remediation steps.\n\n        - name: analyze_pod_distribution\n          description: \"Analyze pod distribution across nodes in a namespace\"\n          command: |\n            kubectl get pods -n {{ namespace }} -o wide --no-headers |\n            awk '{print $7}' | sort | uniq -c | sort -nr\n          additionalInstructions: |\n            Check for uneven pod distribution that might indicate scheduling issues.\n            Suggest rebalancing if necessary.\n\n        - name: check_resource_quotas\n          description: \"Check resource quota usage in a namespace\"\n          command: |\n            kubectl describe resourcequota -n {{ namespace }}\n          additionalInstructions: |\n            Alert if resource quotas are close to limits. Suggest scaling or quota adjustments.\n</code></pre> <p>Helm Upgrade:</p> <pre><code>helm upgrade robusta robusta/robusta --values=generated_values.yaml --set clusterName=&lt;YOUR_CLUSTER_NAME&gt;\n</code></pre>"},{"location":"data-sources/custom-toolsets/#example-3-github-toolset","title":"Example 3: GitHub Toolset","text":"<p>This example shows how to create a toolset for fetching information from GitHub repositories.</p> Holmes CLIRobusta Helm Chart <p>Configuration File (<code>toolsets.yaml</code>):</p> <pre><code>toolsets:\n  github:\n    description: \"Fetch information from GitHub repositories\"\n    prerequisites: \"GitHub API token with repository access\"\n    tags: [source-control, github]\n    installation: |\n      1. Create a GitHub personal access token\n      2. Set the token as an environment variable\n      3. Ensure network access to GitHub API\n    tools:\n      - name: get_repository_info\n        description: \"Get information about a GitHub repository\"\n        command: |\n          curl -s -H \"Authorization: token ${GITHUB_TOKEN}\" \\\n            \"https://api.github.com/repos/{{ owner }}/{{ repo }}\"\n        additionalInstructions: |\n          Extract relevant repository information like description, language, last update.\n          Check for any security alerts or issues.\n\n      - name: get_recent_commits\n        description: \"Get recent commits from a repository\"\n        command: |\n          curl -s -H \"Authorization: token ${GITHUB_TOKEN}\" \\\n            \"https://api.github.com/repos/{{ owner }}/{{ repo }}/commits?per_page={{ limit | default(10) }}\"\n        additionalInstructions: |\n          Show commit messages, authors, and timestamps.\n          Look for patterns that might relate to the current issue.\n\n      - name: search_issues\n        description: \"Search for issues in a repository\"\n        command: |\n          curl -s -H \"Authorization: token ${GITHUB_TOKEN}\" \\\n            \"https://api.github.com/search/issues?q=repo:{{ owner }}/{{ repo }}+{{ search_query }}\"\n        additionalInstructions: |\n          Find relevant issues that might be related to the current problem.\n          Include issue titles, states, and URLs.\n</code></pre> <p>Environment Variables:</p> <pre><code>export GITHUB_TOKEN=\"your-github-personal-access-token\"\n</code></pre> <p>Run HolmesGPT:</p> <pre><code>holmes ask \"check recent commits in robusta-dev/robusta repository\" --toolsets=toolsets.yaml\n</code></pre> <p>After making changes to your toolsets file, run: <pre><code>holmes toolset refresh\n</code></pre></p> <p>Helm Values:</p> <pre><code>holmes:\n  customToolsets:\n    github:\n      description: \"Fetch information from GitHub repositories\"\n      prerequisites: \"GitHub API token with repository access\"\n      tags: [source-control, github]\n      installation: |\n        1. Create a GitHub personal access token\n        2. Set the token as an environment variable\n        3. Ensure network access to GitHub API\n      tools:\n        - name: get_repository_info\n          description: \"Get information about a GitHub repository\"\n          command: |\n            curl -s -H \"Authorization: token {{ github_token }}\" \\\n              \"https://api.github.com/repos/{{ owner }}/{{ repo }}\"\n          additionalInstructions: |\n            Extract relevant repository information like description, language, last update.\n            Check for any security alerts or issues.\n\n        - name: get_recent_commits\n          description: \"Get recent commits from a repository\"\n          command: |\n            curl -s -H \"Authorization: token {{ github_token }}\" \\\n              \"https://api.github.com/repos/{{ owner }}/{{ repo }}/commits?per_page={{ limit | default(10) }}\"\n          additionalInstructions: |\n            Show commit messages, authors, and timestamps.\n            Look for patterns that might relate to the current issue.\n\n        - name: search_issues\n          description: \"Search for issues in a repository\"\n          command: |\n            curl -s -H \"Authorization: token {{ github_token }}\" \\\n              \"https://api.github.com/search/issues?q=repo:{{ owner }}/{{ repo }}+{{ search_query }}\"\n          additionalInstructions: |\n            Find relevant issues that might be related to the current problem.\n            Include issue titles, states, and URLs.\n</code></pre> <p>Environment Variables:</p> <pre><code>export GITHUB_TOKEN=\"your-github-personal-access-token\"\n</code></pre> <p>Helm Upgrade:</p> <pre><code>helm upgrade robusta robusta/robusta --values=generated_values.yaml --set clusterName=&lt;YOUR_CLUSTER_NAME&gt;\n</code></pre>"},{"location":"data-sources/custom-toolsets/#reference","title":"Reference","text":""},{"location":"data-sources/custom-toolsets/#toolset-configuration","title":"Toolset Configuration","text":"<p>A custom toolset consists of the following components:</p> <pre><code>toolsets:\n  &lt;toolset-name&gt;:\n    description: \"Human-readable description\"\n    prerequisites: \"What needs to be installed/configured\"\n    tags: [tag1, tag2]  # Optional: for categorization\n    installation: |\n      Multi-line installation instructions\n    tools:\n      - name: tool_name\n        description: \"What this tool does\"\n        command: |\n          Command or script to execute\n        parameters:  # Optional: can be inferred by LLM\n          - name: param_name\n            description: \"Parameter description\"\n        additionalInstructions: |\n          Instructions for post-processing the command output\n</code></pre>"},{"location":"data-sources/custom-toolsets/#tool-configuration","title":"Tool Configuration","text":"<p>Each tool within a toolset can be configured with:</p> <ul> <li>name: Unique identifier for the tool</li> <li>description: What the tool does (visible to the AI)</li> <li>command: Shell command or script to execute</li> <li>parameters: Optional parameter definitions (usually inferred)</li> <li>additionalInstructions: How to interpret/process the output</li> </ul>"},{"location":"data-sources/custom-toolsets/#variable-syntax","title":"Variable Syntax","text":"<p>HolmesGPT supports two types of variables in commands:</p> <ul> <li><code>{{ variable }}</code>: Dynamic variables inferred by the LLM based on context</li> <li><code>${VARIABLE}</code>: Environment variables (not visible to the LLM)</li> </ul>"},{"location":"data-sources/custom-toolsets/#tags","title":"Tags","text":"<p>Optional tags help categorize toolsets:</p> <ul> <li>core: Essential system tools</li> <li>cluster: Cluster-specific tools</li> <li>monitoring: Observability tools</li> <li>networking: Network-related tools</li> <li>storage: Storage-related tools</li> </ul>"},{"location":"data-sources/custom-toolsets/#advanced-adding-custom-binaries","title":"Advanced: Adding Custom Binaries","text":"<p>If your custom toolset requires additional binaries not available in the base HolmesGPT image, you can extend the Docker image:</p>"},{"location":"data-sources/custom-toolsets/#create-a-custom-dockerfile","title":"Create a Custom Dockerfile","text":"<pre><code>FROM us-central1-docker.pkg.dev/genuine-flight-317411/devel/holmes:latest\n\n# Install additional tools\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    your-custom-tool \\\n    another-binary \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n# Copy custom scripts\nCOPY scripts/ /usr/local/bin/\n\n# Make scripts executable\nRUN chmod +x /usr/local/bin/*.sh\n</code></pre>"},{"location":"data-sources/custom-toolsets/#build-and-push-your-image","title":"Build and Push Your Image","text":"<pre><code>docker build -t your-registry/holmes-custom:latest .\ndocker push your-registry/holmes-custom:latest\n</code></pre>"},{"location":"data-sources/custom-toolsets/#use-custom-image-in-helm-values","title":"Use Custom Image in Helm Values","text":"<pre><code>holmes:\n  image:\n    repository: your-registry/holmes-custom\n    tag: latest\n  customToolsets:\n    # Your custom toolset configuration\n</code></pre> <p>This approach allows you to include any additional tools or dependencies your custom toolsets might need.</p>"},{"location":"data-sources/permissions/","title":"Adding Permissions for Additional Resources (In-Cluster Deployments)","text":"<p>In-Cluster Only</p> <p>This page applies only to HolmesGPT running inside a Kubernetes cluster via Helm. For local CLI deployments, permissions are managed through your kubeconfig file.</p> <p>HolmesGPT may require access to additional Kubernetes resources or CRDs for specific analyses. Permissions can be extended by modifying the ClusterRole rules. The default configuration has limited resource access.</p>"},{"location":"data-sources/permissions/#common-scenarios-for-adding-permissions","title":"Common Scenarios for Adding Permissions","text":"<ol> <li>External Integrations and CRDs - Access to custom resources from ArgoCD, Istio, etc.</li> <li>Additional Kubernetes resources - Resources not included in the default permissions</li> </ol>"},{"location":"data-sources/permissions/#example-scenario-adding-argo-cd-permissions","title":"Example Scenario: Adding Argo CD Permissions","text":"<p>To enable HolmesGPT to analyze ArgoCD applications and projects, you need to add permissions for ArgoCD custom resources.</p>"},{"location":"data-sources/permissions/#steps-to-add-permissions","title":"Steps to Add Permissions","text":"Holmes Helm ChartRobusta Helm Chart <p>When using the standalone Holmes Helm Chart, update your <code>values.yaml</code>:</p> <pre><code>customClusterRoleRules:\n  - apiGroups: [\"argoproj.io\"]\n    resources: [\"applications\", \"appprojects\"]\n    verbs: [\"get\", \"list\", \"watch\"]\n</code></pre> <p>Apply the configuration:</p> <pre><code>helm upgrade holmes holmes/holmes --values=values.yaml\n</code></pre> <p>When using the Robusta Helm Chart (which includes HolmesGPT), update your <code>generated_values.yaml</code> (note: add the <code>holmes:</code> prefix):</p> <pre><code>enableHolmesGPT: true\nholmes:\n  customClusterRoleRules:\n    - apiGroups: [\"argoproj.io\"]\n      resources: [\"applications\", \"appprojects\"]\n      verbs: [\"get\", \"list\", \"watch\"]\n</code></pre> <p>Apply the configuration:</p> <pre><code>helm upgrade robusta robusta/robusta --values=generated_values.yaml --set clusterName=&lt;YOUR_CLUSTER_NAME&gt;\n</code></pre>"},{"location":"data-sources/permissions/#key-benefits","title":"Key Benefits","text":"<ul> <li>Enables HolmesGPT to analyze specific Kubernetes resources</li> <li>Allows interaction with custom resources and CRDs</li> <li>Provides more comprehensive troubleshooting capabilities</li> </ul> <p>The configuration provides flexibility to extend HolmesGPT's permissions to suit specific cluster and tooling requirements.</p>"},{"location":"data-sources/remote-mcp-servers/","title":"Remote MCP Servers","text":"<p>Warning</p> <p>Remote MCP servers are in Tech Preview stage.</p> <p>HolmesGPT can integrate with remote MCP servers using SSE mode. This capability enables HolmesGPT to access external data sources and tools in real time. This guide provides step-by-step instructions for configuring HolmesGPT to connect with remote MCP servers over SSE.</p>"},{"location":"data-sources/remote-mcp-servers/#example-mcp-server-configuration","title":"Example: MCP server configuration","text":"<p> Holmes Helm Chart Robusta Helm Chart <p>When using the standalone Holmes Helm Chart, update your <code>values.yaml</code>:</p> <pre><code>mcp_servers:\n  mcp_server_1:\n    # human-readable description of the mcp server (this is not seen by the AI model - its just for users)\n    description: \"Remote mcp server\"\n    url: \"http://example.com:8000/sse\"\n    llm_instructions: \"This server provides general data access capabilities. Use it when you need to retrieve external information or perform remote operations that aren't covered by other toolsets.\"\n\n  mcp_server_2:\n    description: \"MCP server that runs in my cluster\"\n    url: \"http://&lt;service-name&gt;.&lt;namespace&gt;.svc.cluster.local:&lt;service-port&gt;\"\n    llm_instructions: \"This is a cluster-local MCP server that provides internal cluster data and operations. Use it for accessing cluster-specific information, internal services, or custom tooling deployed within the Kubernetes environment.\"\n    config:\n      headers:\n        key: \"{{ env.my_mcp_server_key }}\" # You can use holmes environment variables as headers for the MCP server requests.</code></pre> <p>Apply the configuration:</p> <pre><code>helm upgrade holmes holmes/holmes --values=values.yaml</code></pre> <p>When using the Robusta Helm Chart (which includes HolmesGPT), update your <code>generated_values.yaml</code> (note: add the <code>holmes:</code> prefix):</p> <pre><code>enableHolmesGPT: true\nholmes:\n  mcp_servers:\n    mcp_server_1:\n      # human-readable description of the mcp server (this is not seen by the AI model - its just for users)\n      description: \"Remote mcp server\"\n      url: \"http://example.com:8000/sse\"\n      llm_instructions: \"This server provides general data access capabilities. Use it when you need to retrieve external information or perform remote operations that aren't covered by other toolsets.\"\n\n    mcp_server_2:\n      description: \"MCP server that runs in my cluster\"\n      url: \"http://&lt;service-name&gt;.&lt;namespace&gt;.svc.cluster.local:&lt;service-port&gt;\"\n      llm_instructions: \"This is a cluster-local MCP server that provides internal cluster data and operations. Use it for accessing cluster-specific information, internal services, or custom tooling deployed within the Kubernetes environment.\"\n      config:\n        headers:\n          key: \"{{ env.my_mcp_server_key }}\" # You can use holmes environment variables as headers for the MCP server requests.</code></pre> <p>Apply the configuration:</p> <pre><code>helm upgrade robusta robusta/robusta --values=generated_values.yaml --set clusterName=&lt;YOUR_CLUSTER_NAME&gt;</code></pre> </p>"},{"location":"data-sources/remote-mcp-servers/#example-working-with-stdio-mcp-servers","title":"Example: Working with Stdio MCP servers","text":"<p>MCP currently supports three transport mechanisms: stdio, Server-Sent Events (SSE), and Streamable HTTP. At this time, HolmesGPT is compatible only with MCP servers that use SSE. However, many existing MCP servers\u2014such as Dynatrace MCP\u2014rely exclusively on the stdio transport. To overcome this incompatibility, tools like Supergateway can act as a bridge by converting stdio-based MCPs into SSE-compatible endpoints.</p> <p>For this demo we will use: - Dynatrace MCP - Supergateway - runs MCP stdio-based servers over SSE</p> <p>Check out supergatway docs to find out other useful flags.</p> <p>See it in action</p>"},{"location":"data-sources/remote-mcp-servers/#1-run-stdio-mcp-as-sse","title":"1. Run stdio MCP as SSE","text":"DockerKubernetes Pod <p>This command runs the Dynatrace MCP server locally via Docker using Supergateway to wrap it with SSE support. Credentials (e.g., API keys) should be stored in a .env file passed to Docker using --env-file. you can change <code>\"npx -y @dynatrace-oss/dynatrace-mcp-server@latest /\"</code> to your specific MCP.</p> <pre><code>docker run --env-file .env -it --rm -p  8003:8003 supercorp/supergateway \\\n--stdio \"npx -y @dynatrace-oss/dynatrace-mcp-server@latest /\" \\\n--port 8003 \\\n--logLevel debug\n</code></pre> <p>Once the container starts, you should see logs similar to:</p> <pre><code>[supergateway] Starting...\n[supergateway] Supergateway is supported by Supermachine (hosted MCPs) - https://supermachine.ai\n[supergateway]   - outputTransport: sse\n[supergateway]   - Headers: (none)\n[supergateway]   - port: 8003\n[supergateway]   - stdio: npx -y @dynatrace-oss/dynatrace-mcp-server@latest /\n[supergateway]   - ssePath: /sse\n[supergateway]   - messagePath: /message\n[supergateway]   - CORS: disabled\n[supergateway]   - Health endpoints: (none)\n[supergateway] Listening on port 8003\n[supergateway] SSE endpoint: http://localhost:8003/sse\n[supergateway] POST messages: http://localhost:8003/message\n</code></pre> <p>This will run dynatrace MCP server as a pod in your cluster. credentials are passed as env vars.</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: dynatrace-mcp\n  labels:\n    app: dynatrace-mcp\nspec:\n  containers:\n    - name: supergateway\n      image: supercorp/supergateway\n      env:\n        - name: DT_ENVIRONMENT\n          value: https://abcd1234.apps.dynatrace.com\n        - name: OAUTH_CLIENT_ID\n          value: dt0s02.SAMPLE\n        - name: OAUTH_CLIENT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: dynatrace-credentials\n              key: client_secret\n      ports:\n        - containerPort: 8003\n      args:\n        - \"--stdio\"\n        - \"npx -y @dynatrace-oss/dynatrace-mcp-server@latest /\"\n        - \"--port\"\n        - \"8003\"\n        - \"--logLevel\"\n        - \"debug\"\n      stdin: true\n      tty: true\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: dynatrace-mcp\nspec:\n  selector:\n    app: dynatrace-mcp\n  ports:\n    - protocol: TCP\n      port: 8003\n      targetPort: 8003\n  type: ClusterIP\n</code></pre>"},{"location":"data-sources/remote-mcp-servers/#2-add-mcp-server-to-holmes-config","title":"2. Add MCP server to holmes config","text":"<p>With the MCP server running in SSE mode, we need to let HolmesGPT know of the mcp server. Use this config according to your use case.</p> <p>Configuration:</p> Holmes CLI <p>Use a config file, and pass it when running cli commands.</p> <p>custom_toolset.yaml:</p> <pre><code>mcp_servers:\n  mcp_server_1:\n    description: \"Dynatrace observability platform. Bring real-time observability data directly into your development workflow.\"\n    url: \"http://localhost:8003/sse\"\n    llm_instructions: \"Use Dynatrace to analyze application performance, infrastructure monitoring, and real-time observability data. Query metrics, traces, and logs to identify performance bottlenecks, errors, and system health issues in your applications and infrastructure.\"\n</code></pre> <p>You can now use Holmes via the CLI with your configured MCP server. For example:</p> <pre><code>holmes ask -t custom_toolset.yaml  \"Using dynatrace what issues do I have in my cluster?\"\n</code></pre> <p>Alternatively, you can add the <code>mcp_servers</code> configurations to ** ~/.holmes/config.yaml**, and run:</p> <pre><code>holmes ask \"Using dynatrace what issues do I have in my cluster?\"\n</code></pre> <p> Holmes Helm Chart Robusta Helm Chart <p>When using the standalone Holmes Helm Chart, update your <code>values.yaml</code>:</p> <pre><code>mcp_servers:\n  mcp_server_1:\n    description: \"Dynatrace observability platform. Bring real-time observability data directly into your development workflow.\"\n    url: \"http://dynatrace-mcp.default.svc.cluster.local:8003\"\n    llm_instructions: \"Use Dynatrace to analyze application performance, infrastructure monitoring, and real-time observability data. Query metrics, traces, and logs to identify performance bottlenecks, errors, and system health issues in your applications and infrastructure.\"</code></pre> <p>Apply the configuration:</p> <pre><code>helm upgrade holmes holmes/holmes --values=values.yaml</code></pre> <p>When using the Robusta Helm Chart (which includes HolmesGPT), update your <code>generated_values.yaml</code> (note: add the <code>holmes:</code> prefix):</p> <pre><code>enableHolmesGPT: true\nholmes:\n  mcp_servers:\n    mcp_server_1:\n      description: \"Dynatrace observability platform. Bring real-time observability data directly into your development workflow.\"\n      url: \"http://dynatrace-mcp.default.svc.cluster.local:8003\"\n      llm_instructions: \"Use Dynatrace to analyze application performance, infrastructure monitoring, and real-time observability data. Query metrics, traces, and logs to identify performance bottlenecks, errors, and system health issues in your applications and infrastructure.\"</code></pre> <p>Apply the configuration:</p> <pre><code>helm upgrade robusta robusta/robusta --values=generated_values.yaml --set clusterName=&lt;YOUR_CLUSTER_NAME&gt;</code></pre> </p> <p>After the deployment is complete, you can use HolmesGPT and ask questions like Using dynatrace what issues do I have in my cluster?.</p>"},{"location":"data-sources/builtin-toolsets/","title":"Built-in Toolsets","text":"<p>HolmesGPT includes pre-built integrations for popular monitoring and observability tools. Some work automatically with Kubernetes, while others require API keys or configuration.</p>"},{"location":"data-sources/builtin-toolsets/#available-toolsets","title":"Available Toolsets","text":"<ul> <li> AKS Node Health</li> <li> ArgoCD</li> <li> AWS</li> <li> Azure Kubernetes Service</li> <li> Azure SQL Database</li> <li> Bash</li> <li> Cilium</li> <li> Confluence</li> <li> Coralogix logs</li> <li> Datadog</li> <li> Datetime</li> <li> Docker</li> <li> GitHub</li> <li> Grafana Dashboards</li> <li> Helm</li> <li> Internet</li> <li> Kafka</li> <li> Kubernetes</li> <li> Loki</li> <li> MongoDB Atlas</li> <li> New Relic</li> <li> Notion</li> <li> OpenSearch logs</li> <li> OpenSearch status</li> <li> Prometheus</li> <li> RabbitMQ</li> <li> Robusta</li> <li> ServiceNow</li> <li> Slab</li> <li> Tempo</li> </ul>"},{"location":"data-sources/builtin-toolsets/#getting-started","title":"Getting Started","text":"<ol> <li>Choose toolsets that match your infrastructure (Prometheus, Grafana, etc.)</li> <li>Configure authentication - some need API keys, others work automatically</li> <li>Run a test investigation to verify data access</li> </ol> <p>\ud83d\udca1 Tip: Start with Kubernetes and Prometheus for basic cluster monitoring.</p>"},{"location":"data-sources/builtin-toolsets/aks-node-health/","title":"AKS Node Health","text":"<p>By enabling this toolset, HolmesGPT will be able to perform specialized health checks and troubleshooting for Azure Kubernetes Service (AKS) nodes, including node-specific diagnostics and performance analysis.</p>"},{"location":"data-sources/builtin-toolsets/aks-node-health/#prerequisites","title":"Prerequisites","text":"<ol> <li>Azure CLI installed and configured</li> <li>Appropriate Azure RBAC permissions for AKS clusters</li> <li>Access to the target AKS cluster</li> <li>Node-level access permissions</li> </ol>"},{"location":"data-sources/builtin-toolsets/aks-node-health/#configuration","title":"Configuration","text":"Holmes CLIRobusta Helm Chart <p>First, ensure you're authenticated with Azure:</p> <pre><code>az login\naz account set --subscription \"&lt;your subscription id&gt;\"\n</code></pre> <p>Then add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n  aks/node-health:\n    enabled: true\n    config:\n      subscription_id: \"&lt;your Azure subscription ID&gt;\"\n      resource_group: \"&lt;your AKS resource group&gt;\"\n      cluster_name: \"&lt;your AKS cluster name&gt;\"\n</code></pre> <p>After making changes to your configuration, run: <pre><code>holmes toolset refresh\n</code></pre></p> <pre><code>holmes:\n  toolsets:\n    aks/node-health:\n      enabled: true\n      config:\n        subscription_id: \"&lt;your Azure subscription ID&gt;\"\n        resource_group: \"&lt;your AKS resource group&gt;\"\n        cluster_name: \"&lt;your AKS cluster name&gt;\"\n</code></pre>"},{"location":"data-sources/builtin-toolsets/aks-node-health/#advanced-configuration","title":"Advanced Configuration","text":"<p>You can configure additional health check parameters:</p> <pre><code>toolsets:\n  aks/node-health:\n    enabled: true\n    config:\n      subscription_id: \"&lt;your Azure subscription ID&gt;\"\n      resource_group: \"&lt;your AKS resource group&gt;\"\n      cluster_name: \"&lt;your AKS cluster name&gt;\"\n      health_check_interval: 300  # Health check interval in seconds\n      max_unhealthy_nodes: 3  # Maximum number of unhealthy nodes to report\n</code></pre>"},{"location":"data-sources/builtin-toolsets/aks-node-health/#capabilities","title":"Capabilities","text":"Tool Name Description aks_check_node_health Perform comprehensive health checks on AKS nodes aks_get_node_metrics Get detailed metrics for AKS nodes aks_diagnose_node_issues Diagnose common node-level issues aks_check_node_readiness Check if nodes are ready and schedulable aks_get_node_events Get events related to specific nodes aks_check_node_resources Check resource utilization on nodes"},{"location":"data-sources/builtin-toolsets/aks/","title":"Azure Kubernetes Service (AKS)","text":"<p>By enabling this toolset, HolmesGPT will be able to interact with Azure Kubernetes Service clusters, providing Azure-specific troubleshooting capabilities and cluster management.</p>"},{"location":"data-sources/builtin-toolsets/aks/#prerequisites","title":"Prerequisites","text":"<ol> <li>Azure CLI installed and configured</li> <li>Appropriate Azure RBAC permissions for AKS clusters</li> <li>Access to the target AKS cluster</li> </ol>"},{"location":"data-sources/builtin-toolsets/aks/#configuration","title":"Configuration","text":"Holmes CLIRobusta Helm Chart <p>First, ensure you're authenticated with Azure:</p> <pre><code>az login\naz account set --subscription \"&lt;your subscription id&gt;\"\n</code></pre> <p>Then add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n  aks/core:\n    enabled: true\n    config:\n      subscription_id: \"&lt;your Azure subscription ID&gt;\" # Optional\n      resource_group: \"&lt;your AKS resource group&gt;\" # Optional\n      cluster_name: \"&lt;your AKS cluster name&gt;\" # Optional\n</code></pre> <p>After making changes to your configuration, run: <pre><code>holmes toolset refresh\n</code></pre></p> <pre><code>holmes:\n  toolsets:\n    aks/core:\n      enabled: true\n      config:\n        subscription_id: \"&lt;your Azure subscription ID&gt;\"\n        resource_group: \"&lt;your AKS resource group&gt;\"\n        cluster_name: \"&lt;your AKS cluster name&gt;\"\n</code></pre> <p>Update your Helm values and run a Helm upgrade: <pre><code>helm upgrade robusta robusta/robusta --values=generated_values.yaml --set clusterName=&lt;YOUR_CLUSTER_NAME&gt;\n</code></pre></p>"},{"location":"data-sources/builtin-toolsets/aks/#advanced-configuration","title":"Advanced Configuration","text":"<p>You can configure additional Azure settings:</p> <pre><code>toolsets:\n  aks/core:\n    enabled: true\n    config:\n      subscription_id: \"&lt;your Azure subscription ID&gt;\"\n      resource_group: \"&lt;your AKS resource group&gt;\"\n      cluster_name: \"&lt;your AKS cluster name&gt;\"\n      location: \"eastus\"  # Azure region\n      timeout: 60  # Request timeout in seconds\n</code></pre>"},{"location":"data-sources/builtin-toolsets/aks/#capabilities","title":"Capabilities","text":"Tool Name Description aks_get_cluster_info Get detailed information about the AKS cluster aks_get_node_pools List and describe AKS node pools aks_get_cluster_credentials Get cluster credentials for kubectl access aks_scale_node_pool Scale a specific node pool aks_get_cluster_logs Fetch AKS cluster logs aks_get_addon_status Get status of AKS addons"},{"location":"data-sources/builtin-toolsets/argocd/","title":"ArgoCD","text":"<p>By enabling this toolset, HolmesGPT will be able to fetch the status, deployment history, and configuration of ArgoCD applications.</p> <p></p>"},{"location":"data-sources/builtin-toolsets/argocd/#prerequisites","title":"Prerequisites","text":""},{"location":"data-sources/builtin-toolsets/argocd/#generating-an-argocd-token","title":"Generating an ArgoCD token","text":"<p>This toolset requires an <code>ARGOCD_AUTH_TOKEN</code> environment variable. Generate an auth token by following these steps.</p>"},{"location":"data-sources/builtin-toolsets/argocd/#adding-a-read-only-policy-to-argocd","title":"Adding a Read-only Policy to ArgoCD","text":"<p>HolmesGPT requires specific permissions to access ArgoCD data. Add the permissions below to your ArgoCD RBAC configuration.</p> <p>Edit the RBAC ConfigMap: <code>kubectl edit configmap argocd-rbac-cm -n argocd</code></p> <pre><code># Add this to the data section of your argocd-rbac-cm configmap.\n# Creates a 'holmesgpt' user with read-only permissions for troubleshooting.\ndata:\n  policy.default: role:readonly\n  policy.csv: |\n    p, role:admin, *, *, *, allow\n    p, role:admin, accounts, apiKey, *, allow\n    p, holmesgpt, accounts, apiKey, holmesgpt, allow\n    p, holmesgpt, projects, get, *, allow\n    p, holmesgpt, applications, get, *, allow\n    p, holmesgpt, repositories, get, *, allow\n    p, holmesgpt, clusters, get, *, allow\n    p, holmesgpt, applications, manifests, */*, allow\n    p, holmesgpt, applications, resources, */*, allow\n    g, admin, role:admin\n</code></pre>"},{"location":"data-sources/builtin-toolsets/argocd/#configuration","title":"Configuration","text":"<p>In addition to setting permissions and generating an auth token, you will need to tell HolmesGPT how to connect to the server. This can be done two ways:</p> <ol> <li>Using port forwarding. This is the recommended approach if your ArgoCD is inside your Kubernetes cluster.</li> <li>Setting the env var <code>ARGOCD_SERVER</code>. This is the recommended approach if your ArgoCD is reachable through a public DNS.</li> </ol>"},{"location":"data-sources/builtin-toolsets/argocd/#1-port-forwarding","title":"1. Port Forwarding","text":"<p>This is the recommended approach if your ArgoCD is inside your Kubernetes cluster.</p> <p>HolmesGPT needs permission to establish a port-forward to ArgoCD. The configuration below includes that authorization.</p> Holmes CLIRobusta Helm Chart <p>Set the following environment variables:</p> <pre><code>export ARGOCD_AUTH_TOKEN=\"&lt;your-argocd-token&gt;\"\nexport ARGOCD_OPTS=\"--port-forward --port-forward-namespace &lt;your_argocd_namespace&gt; --server &lt;your_server_address&gt; --grpc-web\"\n</code></pre> <p>Then add the following to ~/.holmes/config.yaml:</p> <pre><code>toolsets:\n    argocd/core:\n        enabled: true\n</code></pre> <p>After making changes to your configuration, run: <pre><code>holmes toolset refresh\n</code></pre></p> <pre><code>holmes:\n    customClusterRoleRules:\n        - apiGroups: [\"\"]\n          resources: [\"pods/portforward\"]\n          verbs: [\"create\"]\n    additionalEnvVars:\n        - name: ARGOCD_AUTH_TOKEN\n          value: \"&lt;your-argocd-token&gt;\"\n        - name: ARGOCD_OPTS\n          value: \"--port-forward --port-forward-namespace &lt;your_argocd_namespace&gt; --server &lt;your_server_address&gt; --grpc-web\"\n    toolsets:\n        argocd/core:\n            enabled: true\n</code></pre> <p>Update your Helm values and run a Helm upgrade: <pre><code>helm upgrade robusta robusta/robusta --values=generated_values.yaml --set clusterName=&lt;YOUR_CLUSTER_NAME&gt;\n</code></pre></p> <p>Note</p> <p>For in-cluster address, use the cluster DNS. For example: <code>--port-forward --port-forward-namespace argocd --server argocd-server.argocd.svc.cluster.local --insecure --grpc-web</code></p> <ul> <li>Add <code>--insecure</code> to work with self-signed certificates</li> <li>Change the namespace <code>--port-forward-namespace &lt;your_argocd_namespace&gt;</code> to the namespace in which your ArgoCD service is deployed</li> <li>The option <code>--grpc-web</code> in <code>ARGOCD_OPTS</code> prevents some connection errors from leaking into the tool responses and provides a cleaner output for HolmesGPT</li> </ul>"},{"location":"data-sources/builtin-toolsets/argocd/#2-server-url","title":"2. Server URL","text":"<p>This is the recommended approach if your ArgoCD is reachable through a public DNS.</p> Holmes CLIRobusta Helm Chart <p>Set the following environment variables:</p> <pre><code>export ARGOCD_AUTH_TOKEN=\"&lt;your-argocd-token&gt;\"\nexport ARGOCD_SERVER=\"argocd.example.com\"\n</code></pre> <p>Then add the following to ~/.holmes/config.yaml:</p> <pre><code>toolsets:\n    argocd/core:\n        enabled: true\n</code></pre> <p>After making changes to your configuration, run: <pre><code>holmes toolset refresh\n</code></pre></p> <p>To test, run:</p> <pre><code>holmes ask \"Which ArgoCD applications are failing and why?\"\n</code></pre> <pre><code>holmes:\n    additionalEnvVars:\n        - name: ARGOCD_AUTH_TOKEN\n          value: \"&lt;your-argocd-token&gt;\"\n        - name: ARGOCD_SERVER\n          value: \"argocd.example.com\"\n    toolsets:\n        argocd/core:\n            enabled: true\n</code></pre> <p>Update your Helm values and run a Helm upgrade: <pre><code>helm upgrade robusta robusta/robusta --values=generated_values.yaml --set clusterName=&lt;YOUR_CLUSTER_NAME&gt;\n</code></pre></p> <p>Note</p> <p>In production, always use a Kubernetes secret instead of hardcoding the token value in your Helm values.</p>"},{"location":"data-sources/builtin-toolsets/argocd/#capabilities","title":"Capabilities","text":"<p>The table below describes the specific capabilities provided by this toolset. HolmesGPT can decide to invoke any of these capabilities when answering questions or investigating issues.</p> Tool Name Description argocd_app_list List the applications in ArgoCD argocd_app_get Retrieve information about an existing application, such as its status and configuration argocd_app_manifests Retrieve manifests for an application argocd_app_resources List resources of an application argocd_app_diff Display the differences between the current state of an application and the desired state specified in its Git repository argocd_app_history List the deployment history of an application in ArgoCD argocd_repo_list List all the Git repositories that ArgoCD is currently managing argocd_proj_list List all available projects argocd_proj_get Retrieve information about an existing project, such as its applications and policies argocd_cluster_list List all known clusters"},{"location":"data-sources/builtin-toolsets/aws/","title":"AWS","text":""},{"location":"data-sources/builtin-toolsets/aws/#security","title":"Security","text":"<p>Set of tools to audit AWS CloudTrail events and audit logs.</p>"},{"location":"data-sources/builtin-toolsets/aws/#configuration","title":"Configuration","text":"Holmes CLIRobusta Helm Chart <p>First, add the following environment variables:</p> <pre><code>export AWS_ACCESS_KEY_ID=\"&lt;your AWS access key ID&gt;\"\nexport AWS_SECRET_ACCESS_KEY=\"&lt;your AWS secret access key&gt;\"\nexport AWS_DEFAULT_REGION=\"us-west-2\"\n</code></pre> <p>Then, Add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n    aws/security:\n        enabled: true\n</code></pre> <p>After making changes to your configuration, run: <pre><code>holmes toolset refresh\n</code></pre></p> <p>To test, run:</p> <pre><code>holmes ask \"Are there any security misconfigurations in my signup application, particularly in the database?\"\n</code></pre> <p>This builtin toolset is currently only available in HolmesGPT CLI.</p>"},{"location":"data-sources/builtin-toolsets/aws/#capabilities","title":"Capabilities","text":"Tool Name Description aws_cloudtrail_event_lookup Fetches events of a specified type from AWS CloudTrail along with the users that called them aws_cloudtrail_event_details Fetches and returns full event details for an AWS CloudTrail event in JSON format given an event ID aws_user_audit_logs Fetches audit logs for a specified user from AWS CloudTrail in the past 24 hours. Provide username as was output by aws_event_lookup or aws_event_details"},{"location":"data-sources/builtin-toolsets/aws/#rds","title":"RDS","text":"<p>Read access to Amazon RDS instances, events, and logs.</p>"},{"location":"data-sources/builtin-toolsets/aws/#configuration_1","title":"Configuration","text":"Holmes CLIRobusta Helm Chart <p>Configure RDS access with your AWS credentials and region settings.</p> <p>This builtin toolset is currently only available in HolmesGPT CLI.</p>"},{"location":"data-sources/builtin-toolsets/aws/#capabilities_1","title":"Capabilities","text":"Tool Name Description aws_rds_describe_instances Describe RDS instances aws_rds_events Get RDS events aws_rds_logs Retrieve RDS logs"},{"location":"data-sources/builtin-toolsets/azure-sql/","title":"Azure SQL Database","text":"<p>By enabling this toolset, HolmesGPT can analyze Azure SQL Database performance, health, and operational issues using Azure REST APIs and Query Store data.</p> <p>Warning</p> <p>This toolset is in Experimental stage.</p>"},{"location":"data-sources/builtin-toolsets/azure-sql/#prerequisites","title":"Prerequisites","text":"<ol> <li>Azure SQL Database instance</li> <li>Azure authentication (Service Principal or Azure AD Workload Identity)</li> <li>Appropriate Azure and SQL permissions</li> </ol>"},{"location":"data-sources/builtin-toolsets/azure-sql/#configuration","title":"Configuration","text":"Holmes CLIRobusta Helm Chart"},{"location":"data-sources/builtin-toolsets/azure-sql/#azure-ad-workload-identity","title":"Azure AD Workload Identity","text":"<p>Add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n  azure/sql:\n    enabled: true\n    config:\n      database:\n        subscription_id: \"your-subscription-id\"\n        resource_group: \"your-resource-group\"\n        server_name: \"your-azure-sql-server-name\"\n        database_name: \"your-azure-sql-database-name\"\n</code></pre> <p>After making changes to your configuration, run: <pre><code>holmes toolset refresh\n</code></pre></p>"},{"location":"data-sources/builtin-toolsets/azure-sql/#service-principal","title":"Service Principal","text":"<pre><code>toolsets:\n  azure/sql:\n    enabled: true\n    config:\n      tenant_id: \"your-tenant-id\"\n      client_id: \"your-client-id\"\n      client_secret: \"your-client-secret\"\n      database:\n        subscription_id: \"your-subscription-id\"\n        resource_group: \"your-resource-group\"\n        server_name: \"your-azure-sql-server-name\"\n        database_name: \"your-azure-sql-database-name\"\n</code></pre> <p>After making changes to your configuration, run: <pre><code>holmes toolset refresh\n</code></pre></p>"},{"location":"data-sources/builtin-toolsets/azure-sql/#azure-ad-workload-identity_1","title":"Azure AD Workload Identity","text":"<pre><code>holmes:\n  toolsets:\n    azure/sql:\n      enabled: true\n      config:\n        database:\n          subscription_id: \"your-subscription-id\"\n          resource_group: \"your-resource-group\"\n          server_name: \"your-azure-sql-server-name\"\n          database_name: \"your-azure-sql-database-name\"\n</code></pre>"},{"location":"data-sources/builtin-toolsets/azure-sql/#service-principal_1","title":"Service Principal","text":"<pre><code>holmes:\n  toolsets:\n    azure/sql:\n      enabled: true\n      config:\n        tenant_id: \"your-tenant-id\"\n        client_id: \"your-client-id\"\n        client_secret: \"your-client-secret\"\n        database:\n          subscription_id: \"your-subscription-id\"\n          resource_group: \"your-resource-group\"\n          server_name: \"your-azure-sql-server-name\"\n          database_name: \"your-azure-sql-database-name\"\n</code></pre>"},{"location":"data-sources/builtin-toolsets/azure-sql/#roles-access-controls","title":"Roles / Access controls","text":"<p>The service principal requires these roles:</p>"},{"location":"data-sources/builtin-toolsets/azure-sql/#azure","title":"Azure","text":"<pre><code>Azure Level (RBAC):\n\u251c\u2500\u2500 Monitoring Reader (subscription)\n\u251c\u2500\u2500 SQL DB Contributor (resource group)\n</code></pre>"},{"location":"data-sources/builtin-toolsets/azure-sql/#sql","title":"SQL","text":"<pre><code>Database Level (SQL permissions):\n\u251c\u2500\u2500 CREATE USER [holmes-service-principal] FROM EXTERNAL PROVIDER\n\u251c\u2500\u2500 GRANT VIEW SERVER STATE TO [holmes-service-principal]\n\u2514\u2500\u2500 ALTER ROLE db_datareader ADD MEMBER [holmes-service-principal]\n</code></pre>"},{"location":"data-sources/builtin-toolsets/azure-sql/#query-store","title":"Query Store","text":"<p>In addition, Query Store should be enabled on target databases</p>"},{"location":"data-sources/builtin-toolsets/azure-sql/#capabilities","title":"Capabilities","text":"Tool Name Description analyze_database_health_status Analyze overall database health and status analyze_database_performance Analyze database performance metrics analyze_database_connections Analyze database connection patterns and issues analyze_database_storage Analyze database storage usage and growth get_top_cpu_queries Get queries with highest CPU usage get_slow_queries Get slowest performing queries get_top_data_io_queries Get queries with highest data I/O usage get_top_log_io_queries Get queries with highest log I/O usage get_active_alerts Get active alerts for the database analyze_connection_failures Analyze connection failure patterns"},{"location":"data-sources/builtin-toolsets/bash/","title":"Bash Toolset","text":"<p>The bash toolset provides secure execution of common command-line tools used for troubleshooting and system analysis. It replaces multiple YAML-based toolsets with a single, comprehensive toolset that includes safety validation and command parsing.</p> <p>\u26a0\ufe0f Security Note: This toolset executes commands on the system where Holmes is running. Only validated, safe commands are allowed, and the toolset is disabled by default for security reasons.</p>"},{"location":"data-sources/builtin-toolsets/bash/#supported-commands","title":"Supported Commands","text":"<p>The bash toolset supports the following categories of commands:</p>"},{"location":"data-sources/builtin-toolsets/bash/#cloud-providers","title":"Cloud Providers","text":"<p>AWS CLI (<code>aws</code>)</p> <ul> <li>Supports various AWS services and operations</li> <li>Commands are validated for safety before execution</li> </ul> <p>Azure CLI (<code>az</code>)</p> <ul> <li>Supports Azure operations including AKS management</li> <li>Network and account operations</li> </ul>"},{"location":"data-sources/builtin-toolsets/bash/#kubernetes-tools","title":"Kubernetes Tools","text":"<p>kubectl</p> <ul> <li>Standard Kubernetes operations: get, describe, logs, events</li> <li>Resource management and cluster inspection</li> <li>Live metrics via <code>kubectl top</code></li> </ul> <p>Helm</p> <ul> <li>Helm chart operations</li> <li>Repository management</li> <li>Release inspection</li> </ul> <p>ArgoCD</p> <ul> <li>Application management</li> <li>Deployment status checking</li> </ul>"},{"location":"data-sources/builtin-toolsets/bash/#container-tools","title":"Container Tools","text":"<p>Docker</p> <ul> <li>Container inspection and management</li> <li>Image operations</li> <li>Basic Docker commands</li> </ul>"},{"location":"data-sources/builtin-toolsets/bash/#text-processing-utilities","title":"Text Processing Utilities","text":"<p>Data Processing</p> <ul> <li><code>grep</code> - Text searching and pattern matching</li> <li><code>jq</code> - JSON processing and querying</li> <li><code>sed</code> - Stream editing and text transformation</li> <li><code>awk</code> - Pattern scanning and text processing</li> </ul> <p>File Utilities</p> <ul> <li><code>cut</code> - Column extraction</li> <li><code>sort</code> - Data sorting</li> <li><code>uniq</code> - Duplicate removal</li> <li><code>head</code> - Show first lines</li> <li><code>tail</code> - Show last lines</li> <li><code>wc</code> - Word, line, and character counting</li> </ul> <p>Text Transformation</p> <ul> <li><code>tr</code> - Character translation and deletion</li> <li><code>base64</code> - Base64 encoding/decoding</li> </ul>"},{"location":"data-sources/builtin-toolsets/bash/#special-tools","title":"Special Tools","text":"<p>kubectl_run_image</p> <p>Creates temporary debug pods in Kubernetes clusters for diagnostic commands:</p> <ul> <li>Runs commands in specified container images</li> <li>Automatically cleans up temporary pods</li> <li>Supports custom namespaces and timeouts</li> <li>Useful for network debugging, DNS resolution, and environment inspection</li> </ul>"},{"location":"data-sources/builtin-toolsets/bash/#command-validation","title":"Command Validation","text":"<p>All commands undergo security validation before execution:</p> <ul> <li>Only whitelisted commands and options are allowed</li> <li>Dangerous operations are blocked (file writes, system calls, etc.)</li> <li>Commands are parsed and validated for safety</li> <li>Pipe operations between supported commands are allowed</li> </ul>"},{"location":"data-sources/builtin-toolsets/cilium/","title":"Cilium","text":"<p>By enabling this toolset, HolmesGPT will be able to interact with Cilium CNI and Hubble network observability, providing comprehensive network troubleshooting and monitoring capabilities for Kubernetes clusters.</p>"},{"location":"data-sources/builtin-toolsets/cilium/#prerequisites","title":"Prerequisites","text":"<ol> <li>Cilium CNI installed in your Kubernetes cluster</li> <li>Hubble network observability enabled (for Hubble tools)</li> <li><code>cilium</code> CLI tool installed and configured</li> <li><code>hubble</code> CLI tool installed and configured (for Hubble tools)</li> <li>Appropriate RBAC permissions for Cilium resources</li> </ol>"},{"location":"data-sources/builtin-toolsets/cilium/#configuration","title":"Configuration","text":"Holmes CLIRobusta Helm Chart <p>First, ensure your tools are properly configured:</p> <pre><code># Verify Cilium is accessible\ncilium version\ncilium status\n\n# Verify Hubble is accessible (if using Hubble tools)\nhubble version\nhubble status\n</code></pre> <p>Then add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n  cilium/core:\n    enabled: true\n  hubble/observability:\n    enabled: true\n</code></pre> <p>After making changes to your configuration, run: <pre><code>holmes toolset refresh\n</code></pre></p> <pre><code>holmes:\n  toolsets:\n    cilium/core:\n      enabled: true\n    hubble/observability:\n      enabled: true\n</code></pre> <p>Update your Helm values and run a Helm upgrade: <pre><code>helm upgrade robusta robusta/robusta --values=generated_values.yaml --set clusterName=&lt;YOUR_CLUSTER_NAME&gt;\n</code></pre></p>"},{"location":"data-sources/builtin-toolsets/cilium/#advanced-configuration","title":"Advanced Configuration","text":"<p>You can configure additional settings for enhanced functionality:</p> <pre><code>toolsets:\n  cilium/core:\n    enabled: true\n    config:\n      timeout: 60  # Command timeout in seconds\n  hubble/observability:\n    enabled: true\n    config:\n      max_flows: 10000  # Maximum flows to observe\n      timeout: 120      # Extended timeout for flow monitoring\n</code></pre>"},{"location":"data-sources/builtin-toolsets/cilium/#capabilities","title":"Capabilities","text":""},{"location":"data-sources/builtin-toolsets/cilium/#ciliumcore-toolset","title":"Cilium/Core Toolset","text":"Tool Name Description cilium_status Display overall Cilium agent status and health cilium_status_verbose Display detailed Cilium agent status with verbose output cilium_version Show Cilium version information cilium_config Display current Cilium configuration cilium_endpoint_list List all Cilium endpoints (pods with networking) cilium_endpoint_get Get detailed information about a specific endpoint by ID cilium_endpoint_health Check health status of all endpoints cilium_endpoint_logs Show logs for a specific endpoint cilium_service_list List all Cilium services and load balancer mappings cilium_service_get Get detailed information about a specific service by ID cilium_loadbalancer_list List load balancer backend mappings cilium_policy_get Get network policies applied to an endpoint cilium_policy_trace Trace policy decisions for traffic between source and destination cilium_policy_trace_verbose Detailed policy trace with verbose output cilium_monitor Monitor Cilium datapath events in real-time cilium_monitor_verbose Monitor datapath events with verbose output cilium_node_list List all nodes in the Cilium cluster cilium_clustermesh_status Display cluster mesh status for multi-cluster networking cilium_bpf_map_list List all BPF maps used by Cilium cilium_bpf_endpoint_list List endpoints from BPF maps cilium_debuginfo Generate debug information bundle for troubleshooting"},{"location":"data-sources/builtin-toolsets/cilium/#hubbleobservability-toolset","title":"Hubble/Observability Toolset","text":"Tool Name Description hubble_observe Observe network flows in real-time (last 1000 flows) hubble_observe_follow Follow network flows in real-time as they happen hubble_observe_namespace Observe flows for a specific namespace hubble_observe_pod Observe flows to/from a specific pod hubble_observe_since Observe flows since a specific time hubble_observe_http Observe HTTP traffic flows hubble_observe_dns Observe DNS queries and responses hubble_observe_kafka Observe Kafka protocol traffic hubble_observe_grpc Observe gRPC traffic flows hubble_observe_drops Show only dropped network flows (policy denials, etc.) hubble_observe_denied Show flows denied by network policies hubble_observe_service Observe flows to/from a specific service hubble_observe_port Observe flows on a specific port hubble_observe_from_pod Observe flows originating from a specific pod hubble_observe_to_pod Observe flows destined to a specific pod hubble_observe_between_namespaces Observe flows between two specific namespaces hubble_observe_json Output flow observations in JSON format for detailed analysis hubble_status Display Hubble server status and configuration hubble_list_nodes List nodes available for flow observation hubble_observe_flows_summary Get a summary of recent network flows with basic statistics hubble_observe_security_events Observe security-related network events and policy violations hubble_observe_l7_denied Show L7 (application-layer) traffic that was denied"},{"location":"data-sources/builtin-toolsets/cilium/#use-cases","title":"Use Cases","text":""},{"location":"data-sources/builtin-toolsets/cilium/#network-connectivity-troubleshooting","title":"Network Connectivity Troubleshooting","text":"<ul> <li>Pod-to-Pod Communication: Use <code>cilium_endpoint_list</code> and <code>hubble_observe_between_namespaces</code> to diagnose connectivity issues</li> <li>Service Resolution: Check <code>cilium_service_list</code> and observe DNS flows with <code>hubble_observe_dns</code></li> <li>Load Balancing Issues: Analyze <code>cilium_loadbalancer_list</code> and service traffic patterns</li> </ul>"},{"location":"data-sources/builtin-toolsets/cilium/#network-policy-debugging","title":"Network Policy Debugging","text":"<ul> <li>Policy Violations: Use <code>hubble_observe_denied</code> to see blocked traffic</li> <li>Policy Tracing: Use <code>cilium_policy_trace</code> to understand policy decisions</li> <li>Security Events: Monitor with <code>hubble_observe_security_events</code></li> </ul>"},{"location":"data-sources/builtin-toolsets/cilium/#performance-analysis","title":"Performance Analysis","text":"<ul> <li>Network Monitoring: Real-time observation with <code>cilium_monitor</code> and <code>hubble_observe_follow</code></li> <li>Flow Analysis: Detailed traffic patterns with <code>hubble_observe_json</code></li> <li>Component Health: Status checking with <code>cilium_status_verbose</code></li> </ul>"},{"location":"data-sources/builtin-toolsets/cilium/#multi-cluster-networking","title":"Multi-Cluster Networking","text":"<ul> <li>Cluster Mesh: Status and connectivity with <code>cilium_clustermesh_status</code></li> <li>Cross-Cluster Flows: Monitor inter-cluster traffic patterns</li> </ul>"},{"location":"data-sources/builtin-toolsets/cilium/#common-troubleshooting-scenarios","title":"Common Troubleshooting Scenarios","text":""},{"location":"data-sources/builtin-toolsets/cilium/#my-pods-cant-communicate","title":"\"My pods can't communicate\"","text":"<ol> <li>Check Cilium agent health: <code>cilium_status</code></li> <li>Verify endpoints are healthy: <code>cilium_endpoint_health</code></li> <li>Observe blocked flows: <code>hubble_observe_drops</code></li> <li>Trace policy decisions: <code>cilium_policy_trace</code></li> </ol>"},{"location":"data-sources/builtin-toolsets/cilium/#dns-resolution-is-failing","title":"\"DNS resolution is failing\"","text":"<ol> <li>Monitor DNS queries: <code>hubble_observe_dns</code></li> <li>Check endpoint configuration: <code>cilium_endpoint_get</code></li> <li>Verify service mappings: <code>cilium_service_list</code></li> </ol>"},{"location":"data-sources/builtin-toolsets/cilium/#network-policies-arent-working","title":"\"Network policies aren't working\"","text":"<ol> <li>View denied flows: <code>hubble_observe_denied</code></li> <li>Trace policy evaluation: <code>cilium_policy_trace_verbose</code></li> <li>Check applied policies: <code>cilium_policy_get</code></li> </ol>"},{"location":"data-sources/builtin-toolsets/cilium/#load-balancing-issues","title":"\"Load balancing issues\"","text":"<ol> <li>Examine service backends: <code>cilium_service_get</code></li> <li>Check BPF load balancer state: <code>cilium_loadbalancer_list</code></li> <li>Monitor service traffic: <code>hubble_observe_service</code></li> </ol>"},{"location":"data-sources/builtin-toolsets/confluence/","title":"Confluence","text":"<p>By enabling this toolset, HolmesGPT will be able to fetch Confluence pages. This is particularly useful if you store runbooks in Confluence and want Holmes to run investigations using these runbooks.</p> <p>This toolset requires an Atlassian API Key.</p>"},{"location":"data-sources/builtin-toolsets/confluence/#configuration","title":"Configuration","text":"Holmes CLIRobusta Helm Chart <p>Set the following environment variables and the Confluence toolset will be automatically enabled:</p> <pre><code>export CONFLUENCE_USER=\"&lt;Confluence username&gt;\"\nexport CONFLUENCE_API_KEY=\"&lt;Confluence API key&gt;\"\nexport CONFLUENCE_BASE_URL=\"&lt;Confluence base URL&gt;\"\n</code></pre> <p>To test, run:</p> <pre><code>holmes ask \"why is my application failing? Get relevant runbooks from Confluence\"\n</code></pre> <p>After making changes to your configuration, run: <pre><code>holmes toolset refresh\n</code></pre></p> <p>Helm Values:</p> <pre><code>holmes:\n    additionalEnvVars:\n        - name: CONFLUENCE_USER\n          value: &lt;Confluence username&gt;\n        - name: CONFLUENCE_API_KEY\n          value: &lt;Confluence API key&gt;\n        - name: CONFLUENCE_BASE_URL\n          value: &lt;Confluence base URL&gt;\n    toolsets:\n        confluence:\n            enabled: true\n</code></pre>"},{"location":"data-sources/builtin-toolsets/confluence/#capabilities","title":"Capabilities","text":"Tool Name Description fetch_confluence_url Fetch a page in Confluence. Use this to fetch Confluence runbooks if they are present before starting your investigation."},{"location":"data-sources/builtin-toolsets/coralogix-logs/","title":"Coralogix logs","text":"<p>By enabling this toolset, HolmesGPT will fetch pod logs from Coralogix.</p> Important: Disable Default Logging Toolset <p>Only one logging toolset should be enabled at a time. If you enable this toolset, disable the default <code>kubernetes/logs</code> toolset.</p> <p>Available Log Sources:</p> <ul> <li>Kubernetes logs - Direct pod log access (enabled by default)</li> <li>Loki - Centralized logs via Loki</li> <li>OpenSearch logs - Logs from OpenSearch/Elasticsearch</li> <li>Coralogix logs - Logs via Coralogix platform</li> <li>DataDog - Logs from DataDog</li> </ul> <p>\ud83d\udca1 Choose one: Only enable one logging toolset at a time for best performance.</p>"},{"location":"data-sources/builtin-toolsets/coralogix-logs/#prerequisites","title":"Prerequisites","text":"<ol> <li>A Coralogix API key which is assigned the <code>DataQuerying</code> permission preset</li> <li>A Coralogix domain. For example <code>eu2.coralogix.com</code></li> <li>Your team's name or hostname. For example <code>your-company-name</code></li> </ol> <p>You can deduce the <code>domain</code> and <code>team_hostname</code> configuration fields by looking at the URL you use to access the Coralogix UI.</p> <p>For example if you access Coralogix at <code>https://my-team.app.eu2.coralogix.com/</code> then the <code>team_hostname</code> is <code>my-team</code> and the Coralogix <code>domain</code> is <code>eu2.coralogix.com</code>.</p>"},{"location":"data-sources/builtin-toolsets/coralogix-logs/#configuration","title":"Configuration","text":"<p> Holmes CLI Holmes Helm Chart Robusta Helm Chart <p>Add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n  coralogix/logs:\n    enabled: true\n    config:\n      api_key: \"&lt;your Coralogix API key&gt;\"\n      domain: \"eu2.coralogix.com\"\n      team_hostname: \"your-company-name\"\n\n  kubernetes/logs:\n    enabled: false  # Disable default Kubernetes logging</code></pre> <p>When using the standalone Holmes Helm Chart, update your <code>values.yaml</code>:</p> <pre><code>toolsets:\n  coralogix/logs:\n    enabled: true\n    config:\n      api_key: \"&lt;your Coralogix API key&gt;\"\n      domain: \"eu2.coralogix.com\"\n      team_hostname: \"your-company-name\"\n\n  kubernetes/logs:\n    enabled: false  # Disable default Kubernetes logging</code></pre> <p>Apply the configuration:</p> <pre><code>helm upgrade holmes holmes/holmes --values=values.yaml</code></pre> <p>When using the Robusta Helm Chart (which includes HolmesGPT), update your <code>generated_values.yaml</code>:</p> <pre><code>holmes:\n  toolsets:\n    coralogix/logs:\n      enabled: true\n      config:\n        api_key: \"&lt;your Coralogix API key&gt;\"\n        domain: \"eu2.coralogix.com\"\n        team_hostname: \"your-company-name\"\n\n    kubernetes/logs:\n      enabled: false  # Disable default Kubernetes logging</code></pre> <p>Apply the configuration:</p> <pre><code>helm upgrade robusta robusta/robusta --values=generated_values.yaml --set clusterName=&lt;YOUR_CLUSTER_NAME&gt;</code></pre> </p>"},{"location":"data-sources/builtin-toolsets/coralogix-logs/#custom-labels-configuration-optional","title":"Custom Labels Configuration (Optional)","text":"<p>By default, the Coralogix toolset expects logs to use standard Kubernetes field names. If your Coralogix deployment uses different field names for Kubernetes metadata, you can customize the label mappings.</p> <p>This is useful when:</p> <ul> <li>Your log ingestion pipeline uses custom field names</li> <li>You have a non-standard Coralogix setup with different metadata fields</li> <li>Your Kubernetes logs are structured differently in Coralogix</li> </ul> <p>To find the correct field names, examine your logs in the Coralogix UI and identify how pod names, namespaces, log messages, and timestamps are labeled.</p>"},{"location":"data-sources/builtin-toolsets/coralogix-logs/#example-with-custom-labels","title":"Example with Custom Labels","text":"<p> Holmes CLI Holmes Helm Chart Robusta Helm Chart <p>Add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n  coralogix/logs:\n    enabled: true\n    config:\n      api_key: \"&lt;your Coralogix API key&gt;\"\n      domain: \"eu2.coralogix.com\"\n      team_hostname: \"your-company-name\"\n      labels:\n        namespace: \"resource.attributes.k8s.pod.name\" # Default\n        pod: \"resource.attributes.k8s.namespace.name\" # Default\n        log_message: \"logRecord.body\"                 # Default\n        timestamp: \"logRecord.attributes.time\"        # Default\n\n  kubernetes/logs:\n    enabled: false  # Disable default Kubernetes logging</code></pre> <p>When using the standalone Holmes Helm Chart, update your <code>values.yaml</code>:</p> <pre><code>toolsets:\n  coralogix/logs:\n    enabled: true\n    config:\n      api_key: \"&lt;your Coralogix API key&gt;\"\n      domain: \"eu2.coralogix.com\"\n      team_hostname: \"your-company-name\"\n      labels:\n        namespace: \"resource.attributes.k8s.pod.name\" # Default\n        pod: \"resource.attributes.k8s.namespace.name\" # Default\n        log_message: \"logRecord.body\"                 # Default\n        timestamp: \"logRecord.attributes.time\"        # Default\n\n  kubernetes/logs:\n    enabled: false  # Disable default Kubernetes logging</code></pre> <p>Apply the configuration:</p> <pre><code>helm upgrade holmes holmes/holmes --values=values.yaml</code></pre> <p>When using the Robusta Helm Chart (which includes HolmesGPT), update your <code>generated_values.yaml</code>:</p> <pre><code>holmes:\n  toolsets:\n    coralogix/logs:\n      enabled: true\n      config:\n        api_key: \"&lt;your Coralogix API key&gt;\"\n        domain: \"eu2.coralogix.com\"\n        team_hostname: \"your-company-name\"\n        labels:\n          namespace: \"resource.attributes.k8s.pod.name\" # Default\n          pod: \"resource.attributes.k8s.namespace.name\" # Default\n          log_message: \"logRecord.body\"                 # Default\n          timestamp: \"logRecord.attributes.time\"        # Default\n\n    kubernetes/logs:\n      enabled: false  # Disable default Kubernetes logging</code></pre> <p>Apply the configuration:</p> <pre><code>helm upgrade robusta robusta/robusta --values=generated_values.yaml --set clusterName=&lt;YOUR_CLUSTER_NAME&gt;</code></pre> </p> <p>Label Configuration Fields:</p> <ul> <li><code>namespace</code>: Field path for Kubernetes namespace name</li> <li><code>pod</code>: Field path for Kubernetes pod name</li> <li><code>log_message</code>: Field path for the actual log message content</li> <li><code>timestamp</code>: Field path for log timestamp</li> </ul> <p>All label fields are optional and will use the defaults shown above if not specified.</p>"},{"location":"data-sources/builtin-toolsets/coralogix-logs/#logs-retrieval-strategy-optional","title":"Logs Retrieval Strategy (Optional)","text":"<p>Coralogix stores logs in two tiers with different performance characteristics:</p> <ul> <li>Frequent Search: Fast queries with limited retention</li> <li>Archive: Slower queries but longer retention period</li> </ul> <p>You can configure how HolmesGPT retrieves logs using the <code>logs_retrieval_methodology</code> setting:</p>"},{"location":"data-sources/builtin-toolsets/coralogix-logs/#available-strategies","title":"Available Strategies","text":"<ul> <li><code>ARCHIVE_FALLBACK</code> (default): Try Frequent Search first, fallback to Archive if no results</li> <li><code>FREQUENT_SEARCH_ONLY</code>: Only search Frequent Search tier</li> <li><code>ARCHIVE_ONLY</code>: Only search Archive tier</li> <li><code>BOTH_FREQUENT_SEARCH_AND_ARCHIVE</code>: Search both tiers and merge results</li> <li><code>FREQUENT_SEARCH_FALLBACK</code>: Try Archive first, fallback to Frequent Search if no results</li> </ul>"},{"location":"data-sources/builtin-toolsets/coralogix-logs/#example-configuration","title":"Example Configuration","text":"<p> Holmes CLI Holmes Helm Chart Robusta Helm Chart <p>Add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n  coralogix/logs:\n    enabled: true\n    config:\n      api_key: \"&lt;your Coralogix API key&gt;\"\n      domain: \"eu2.coralogix.com\"\n      team_hostname: \"your-company-name\"\n      logs_retrieval_methodology: \"ARCHIVE_FALLBACK\"  # Default</code></pre> <p>When using the standalone Holmes Helm Chart, update your <code>values.yaml</code>:</p> <pre><code>toolsets:\n  coralogix/logs:\n    enabled: true\n    config:\n      api_key: \"&lt;your Coralogix API key&gt;\"\n      domain: \"eu2.coralogix.com\"\n      team_hostname: \"your-company-name\"\n      logs_retrieval_methodology: \"ARCHIVE_FALLBACK\"  # Default</code></pre> <p>Apply the configuration:</p> <pre><code>helm upgrade holmes holmes/holmes --values=values.yaml</code></pre> <p>When using the Robusta Helm Chart (which includes HolmesGPT), update your <code>generated_values.yaml</code>:</p> <pre><code>holmes:\n  toolsets:\n    coralogix/logs:\n      enabled: true\n      config:\n        api_key: \"&lt;your Coralogix API key&gt;\"\n        domain: \"eu2.coralogix.com\"\n        team_hostname: \"your-company-name\"\n        logs_retrieval_methodology: \"ARCHIVE_FALLBACK\"  # Default</code></pre> <p>Apply the configuration:</p> <pre><code>helm upgrade robusta robusta/robusta --values=generated_values.yaml --set clusterName=&lt;YOUR_CLUSTER_NAME&gt;</code></pre> </p> <p>Recommendations:</p> <ul> <li>Use <code>ARCHIVE_FALLBACK</code> for most cases (balances speed and coverage)</li> <li>Use <code>FREQUENT_SEARCH_ONLY</code> when you know Holmes does not need to access the log archive</li> <li>Use <code>ARCHIVE_ONLY</code> if the frequent search logs are always empty</li> <li>Use <code>BOTH_FREQUENT_SEARCH_AND_ARCHIVE</code> for comprehensive log coverage (slower)</li> </ul>"},{"location":"data-sources/builtin-toolsets/coralogix-logs/#capabilities","title":"Capabilities","text":"Tool Name Description coralogix_fetch_logs Fetch logs from Coralogix for specified pods and time ranges"},{"location":"data-sources/builtin-toolsets/datadog/","title":"Datadog","text":"<p>Connect HolmesGPT to Datadog for comprehensive observability including logs, metrics, traces, and more.</p> Important: Disable Default Logging Toolset <p>Only one logging toolset should be enabled at a time. If you enable this toolset, disable the default <code>kubernetes/logs</code> toolset.</p> <p>Available Log Sources:</p> <ul> <li>Kubernetes logs - Direct pod log access (enabled by default)</li> <li>Loki - Centralized logs via Loki</li> <li>OpenSearch logs - Logs from OpenSearch/Elasticsearch</li> <li>Coralogix logs - Logs via Coralogix platform</li> <li>DataDog - Logs from DataDog</li> </ul> <p>\ud83d\udca1 Choose one: Only enable one logging toolset at a time for best performance.</p>"},{"location":"data-sources/builtin-toolsets/datadog/#quick-start","title":"Quick Start","text":""},{"location":"data-sources/builtin-toolsets/datadog/#1-get-your-api-keys","title":"1. Get Your API Keys","text":"<p>You'll need two keys from your Datadog account:</p> <ul> <li>API Key: Found under Organization Settings &gt; API Keys</li> <li>Application Key: Found under Organization Settings &gt; Application Keys</li> </ul>"},{"location":"data-sources/builtin-toolsets/datadog/#2-configure-holmesgpt","title":"2. Configure HolmesGPT","text":"Holmes CLIHolmes Helm ChartRobusta Helm Chart <p>Set environment variables: <pre><code>export DD_API_KEY=\"your-datadog-api-key\"\nexport DD_APP_KEY=\"your-datadog-app-key\"\n</code></pre></p> <p>Add to your config file: <pre><code>toolsets:\n  # Enable all Datadog toolsets\n  datadog/logs:\n    enabled: true\n    config:\n      dd_api_key: \"{{ env.DD_API_KEY }}\"\n      dd_app_key: \"{{ env.DD_APP_KEY }}\"\n      site_api_url: https://app.datadoghq.com  # Change for EU/other regions\n\n  datadog/metrics:\n    enabled: true\n    config:\n      dd_api_key: \"{{ env.DD_API_KEY }}\"\n      dd_app_key: \"{{ env.DD_APP_KEY }}\"\n      site_api_url: https://app.datadoghq.com\n\n  datadog/traces:\n    enabled: true\n    config:\n      dd_api_key: \"{{ env.DD_API_KEY }}\"\n      dd_app_key: \"{{ env.DD_APP_KEY }}\"\n      site_api_url: https://app.datadoghq.com\n\n  datadog/rds:\n    enabled: true\n    config:\n      dd_api_key: \"{{ env.DD_API_KEY }}\"\n      dd_app_key: \"{{ env.DD_APP_KEY }}\"\n      site_api_url: https://app.datadoghq.com\n\n  datadog/general:\n    enabled: true\n    config:\n      dd_api_key: \"{{ env.DD_API_KEY }}\"\n      dd_app_key: \"{{ env.DD_APP_KEY }}\"\n      site_api_url: https://app.datadoghq.com\n</code></pre></p> <p>First, create a Kubernetes secret with your API keys: <pre><code>kubectl create secret generic holmes-datadog-secrets \\\n  --from-literal=dd-api-key=your-datadog-api-key \\\n  --from-literal=dd-app-key=your-datadog-app-key\n</code></pre></p> <p>Then add to your Holmes Helm values: <pre><code># Load API keys from secret\nadditionalEnvVars:\n  - name: DD_API_KEY\n    valueFrom:\n      secretKeyRef:\n        name: holmes-datadog-secrets\n        key: dd-api-key\n  - name: DD_APP_KEY\n    valueFrom:\n      secretKeyRef:\n        name: holmes-datadog-secrets\n        key: dd-app-key\n\ntoolsets:\n  # Enable all Datadog toolsets\n  datadog/logs:\n    enabled: true\n    config:\n      dd_api_key: \"{{ env.DD_API_KEY }}\"\n      dd_app_key: \"{{ env.DD_APP_KEY }}\"\n      site_api_url: https://app.datadoghq.com  # Change for EU/other regions\n\n  datadog/metrics:\n    enabled: true\n    config:\n      dd_api_key: \"{{ env.DD_API_KEY }}\"\n      dd_app_key: \"{{ env.DD_APP_KEY }}\"\n      site_api_url: https://app.datadoghq.com\n\n  datadog/traces:\n    enabled: true\n    config:\n      dd_api_key: \"{{ env.DD_API_KEY }}\"\n      dd_app_key: \"{{ env.DD_APP_KEY }}\"\n      site_api_url: https://app.datadoghq.com\n\n  datadog/rds:\n    enabled: true\n    config:\n      dd_api_key: \"{{ env.DD_API_KEY }}\"\n      dd_app_key: \"{{ env.DD_APP_KEY }}\"\n      site_api_url: https://app.datadoghq.com\n\n  datadog/general:\n    enabled: true\n    config:\n      dd_api_key: \"{{ env.DD_API_KEY }}\"\n      dd_app_key: \"{{ env.DD_APP_KEY }}\"\n      site_api_url: https://app.datadoghq.com\n</code></pre></p> <p>First, create a Kubernetes secret with your API keys: <pre><code>kubectl create secret generic holmes-datadog-secrets \\\n  --from-literal=dd-api-key=your-datadog-api-key \\\n  --from-literal=dd-app-key=your-datadog-app-key\n</code></pre></p> <p>Then add to your Robusta Helm values: <pre><code>runner:\n  # Load API keys from secret\n  additionalEnvVars:\n    - name: DD_API_KEY\n      valueFrom:\n        secretKeyRef:\n          name: holmes-datadog-secrets\n          key: dd-api-key\n    - name: DD_APP_KEY\n      valueFrom:\n        secretKeyRef:\n          name: holmes-datadog-secrets\n          key: dd-app-key\n\n  customToolsets:\n    # Enable all Datadog toolsets\n    datadog/logs:\n      enabled: true\n      config:\n        dd_api_key: \"{{ env.DD_API_KEY }}\"\n        dd_app_key: \"{{ env.DD_APP_KEY }}\"\n        site_api_url: https://app.datadoghq.com  # Change for EU/other regions\n\n    datadog/metrics:\n      enabled: true\n      config:\n        dd_api_key: \"{{ env.DD_API_KEY }}\"\n        dd_app_key: \"{{ env.DD_APP_KEY }}\"\n        site_api_url: https://app.datadoghq.com\n\n    datadog/traces:\n      enabled: true\n      config:\n        dd_api_key: \"{{ env.DD_API_KEY }}\"\n        dd_app_key: \"{{ env.DD_APP_KEY }}\"\n        site_api_url: https://app.datadoghq.com\n\n    datadog/rds:\n      enabled: true\n      config:\n        dd_api_key: \"{{ env.DD_API_KEY }}\"\n        dd_app_key: \"{{ env.DD_APP_KEY }}\"\n        site_api_url: https://app.datadoghq.com\n\n    datadog/general:\n      enabled: true\n      config:\n        dd_api_key: \"{{ env.DD_API_KEY }}\"\n        dd_app_key: \"{{ env.DD_APP_KEY }}\"\n        site_api_url: https://app.datadoghq.com\n</code></pre></p>"},{"location":"data-sources/builtin-toolsets/datadog/#3-test-it-works","title":"3. Test It Works","text":"<pre><code># Test logs\nholmes ask \"show me recent logs from Datadog\"\n\n# Test metrics\nholmes ask \"list available Datadog metrics\"\n\n# Test general API\nholmes ask \"list Datadog monitors\"\n</code></pre> <p>That's it! You're now connected to Datadog with all toolsets enabled.</p>"},{"location":"data-sources/builtin-toolsets/datadog/#available-toolsets","title":"Available Toolsets","text":"<p>HolmesGPT provides five specialized Datadog toolsets:</p> Toolset Purpose Common Use Cases datadog/logs Query application logs Debugging errors, tracking deployments, historical analysis datadog/metrics Access performance metrics CPU/memory monitoring, custom metrics, SLI tracking datadog/traces Analyze distributed traces Latency issues, service dependencies, bottlenecks datadog/rds Monitor RDS databases Database performance, slow queries, connection issues datadog/general Access other Datadog APIs Monitors, dashboards, SLOs, incidents, synthetics"},{"location":"data-sources/builtin-toolsets/datadog/#core-configuration","title":"Core Configuration","text":"<p>All Datadog toolsets share the same basic configuration structure:</p> <p> Holmes CLI Holmes Helm Chart Robusta Helm Chart <p>Add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n  datadog/&lt;toolset-name&gt;:\n    enabled: true\n    config:\n      dd_api_key: \"{{ env.DD_API_KEY }}\"\n      dd_app_key: \"{{ env.DD_APP_KEY }}\"\n      site_api_url: https://api.datadoghq.com  # Required - see regions below</code></pre> <p>When using the standalone Holmes Helm Chart, update your <code>values.yaml</code>:</p> <pre><code>toolsets:\n  datadog/&lt;toolset-name&gt;:\n    enabled: true\n    config:\n      dd_api_key: \"{{ env.DD_API_KEY }}\"\n      dd_app_key: \"{{ env.DD_APP_KEY }}\"\n      site_api_url: https://api.datadoghq.com  # Required - see regions below</code></pre> <p>Apply the configuration:</p> <pre><code>helm upgrade holmes holmes/holmes --values=values.yaml</code></pre> <p>When using the Robusta Helm Chart (which includes HolmesGPT), update your <code>generated_values.yaml</code>:</p> <pre><code>holmes:\n  toolsets:\n    datadog/&lt;toolset-name&gt;:\n      enabled: true\n      config:\n        dd_api_key: \"{{ env.DD_API_KEY }}\"\n        dd_app_key: \"{{ env.DD_APP_KEY }}\"\n        site_api_url: https://api.datadoghq.com  # Required - see regions below</code></pre> <p>Apply the configuration:</p> <pre><code>helm upgrade robusta robusta/robusta --values=generated_values.yaml --set clusterName=&lt;YOUR_CLUSTER_NAME&gt;</code></pre> </p>"},{"location":"data-sources/builtin-toolsets/datadog/#regional-endpoints","title":"Regional Endpoints","text":"<p>Configure the correct API endpoint for your Datadog region:</p> Region Site API URL US1 (default) <code>https://app.datadoghq.com</code> US3 <code>https://us3.datadoghq.com</code> US5 <code>https://us5.datadoghq.com</code> EU1 <code>https://app.datadoghq.eu</code> US1-FED (Government) <code>https://app.ddog-gov.com</code> AP1 (Japan) <code>https://ap1.datadoghq.com</code> AP2 (Australia) <code>https://ap2.datadoghq.com</code>"},{"location":"data-sources/builtin-toolsets/datadog/#toolset-details","title":"Toolset Details","text":""},{"location":"data-sources/builtin-toolsets/datadog/#datadog-logs","title":"Datadog Logs","text":"<p>Query and analyze logs from Datadog, including historical data from terminated pods.</p> <p>Configuration</p> <p> Holmes CLI Holmes Helm Chart Robusta Helm Chart <p>Add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n  datadog/logs:\n    enabled: true\n    config:\n      dd_api_key: \"{{ env.DD_API_KEY }}\"\n      dd_app_key: \"{{ env.DD_APP_KEY }}\"\n      site_api_url: https://api.datadoghq.com\n      request_timeout: 60  # Timeout in seconds (default: 60)\n\n      # Optional: Log search configuration\n      indexes: [\"*\"]  # Log indexes to search (default: [\"*\"])\n      storage_tiers: [\"indexes\"]  # Options: indexes, online-archives, flex\n      page_size: 300  # Results per page (default: 300)\n      default_limit: 1000  # Max logs to retrieve (default: 1000)\n\n      # Optional: Kubernetes field mappings\n      labels:\n        pod: \"pod_name\"  # Datadog field for pod name\n        namespace: \"kube_namespace\"  # Datadog field for namespace\n\n  # Disable Kubernetes native logging when using Datadog\n  kubernetes/logs:\n    enabled: false</code></pre> <p>When using the standalone Holmes Helm Chart, update your <code>values.yaml</code>:</p> <pre><code>toolsets:\n  datadog/logs:\n    enabled: true\n    config:\n      dd_api_key: \"{{ env.DD_API_KEY }}\"\n      dd_app_key: \"{{ env.DD_APP_KEY }}\"\n      site_api_url: https://api.datadoghq.com\n      request_timeout: 60  # Timeout in seconds (default: 60)\n\n      # Optional: Log search configuration\n      indexes: [\"*\"]  # Log indexes to search (default: [\"*\"])\n      storage_tiers: [\"indexes\"]  # Options: indexes, online-archives, flex\n      page_size: 300  # Results per page (default: 300)\n      default_limit: 1000  # Max logs to retrieve (default: 1000)\n\n      # Optional: Kubernetes field mappings\n      labels:\n        pod: \"pod_name\"  # Datadog field for pod name\n        namespace: \"kube_namespace\"  # Datadog field for namespace\n\n  # Disable Kubernetes native logging when using Datadog\n  kubernetes/logs:\n    enabled: false</code></pre> <p>Apply the configuration:</p> <pre><code>helm upgrade holmes holmes/holmes --values=values.yaml</code></pre> <p>When using the Robusta Helm Chart (which includes HolmesGPT), update your <code>generated_values.yaml</code>:</p> <pre><code>holmes:\n  toolsets:\n    datadog/logs:\n      enabled: true\n      config:\n        dd_api_key: \"{{ env.DD_API_KEY }}\"\n        dd_app_key: \"{{ env.DD_APP_KEY }}\"\n        site_api_url: https://api.datadoghq.com\n        request_timeout: 60  # Timeout in seconds (default: 60)\n\n        # Optional: Log search configuration\n        indexes: [\"*\"]  # Log indexes to search (default: [\"*\"])\n        storage_tiers: [\"indexes\"]  # Options: indexes, online-archives, flex\n        page_size: 300  # Results per page (default: 300)\n        default_limit: 1000  # Max logs to retrieve (default: 1000)\n\n        # Optional: Kubernetes field mappings\n        labels:\n          pod: \"pod_name\"  # Datadog field for pod name\n          namespace: \"kube_namespace\"  # Datadog field for namespace\n\n    # Disable Kubernetes native logging when using Datadog\n    kubernetes/logs:\n      enabled: false</code></pre> <p>Apply the configuration:</p> <pre><code>helm upgrade robusta robusta/robusta --values=generated_values.yaml --set clusterName=&lt;YOUR_CLUSTER_NAME&gt;</code></pre> </p> <p>Capabilities</p> Tool Description <code>fetch_pod_logs</code> Retrieve logs for specific pods with time range and filter support <p>Example Usage</p> <pre><code># Get logs for a specific pod\nholmes ask \"show me logs for pod payment-service in namespace production\"\n\n# Search for errors in the last hour\nholmes ask \"find all error logs in the last hour\"\n\n# Historical logs from deleted pods\nholmes ask \"show me logs from the crashed pod that was running yesterday\"\n</code></pre>"},{"location":"data-sources/builtin-toolsets/datadog/#datadog-metrics","title":"Datadog Metrics","text":"<p>Access and analyze metrics from your infrastructure and applications.</p> <p>Configuration</p> <p> Holmes CLI Holmes Helm Chart Robusta Helm Chart <p>Add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n  datadog/metrics:\n    enabled: true\n    config:\n      dd_api_key: \"{{ env.DD_API_KEY }}\"\n      dd_app_key: \"{{ env.DD_APP_KEY }}\"\n      site_api_url: https://api.datadoghq.com\n      request_timeout: 60  # Timeout in seconds (default: 60)\n\n      # Optional\n      default_limit: 1000  # Max data points to retrieve (default: 1000)</code></pre> <p>When using the standalone Holmes Helm Chart, update your <code>values.yaml</code>:</p> <pre><code>toolsets:\n  datadog/metrics:\n    enabled: true\n    config:\n      dd_api_key: \"{{ env.DD_API_KEY }}\"\n      dd_app_key: \"{{ env.DD_APP_KEY }}\"\n      site_api_url: https://api.datadoghq.com\n      request_timeout: 60  # Timeout in seconds (default: 60)\n\n      # Optional\n      default_limit: 1000  # Max data points to retrieve (default: 1000)</code></pre> <p>Apply the configuration:</p> <pre><code>helm upgrade holmes holmes/holmes --values=values.yaml</code></pre> <p>When using the Robusta Helm Chart (which includes HolmesGPT), update your <code>generated_values.yaml</code>:</p> <pre><code>holmes:\n  toolsets:\n    datadog/metrics:\n      enabled: true\n      config:\n        dd_api_key: \"{{ env.DD_API_KEY }}\"\n        dd_app_key: \"{{ env.DD_APP_KEY }}\"\n        site_api_url: https://api.datadoghq.com\n        request_timeout: 60  # Timeout in seconds (default: 60)\n\n        # Optional\n        default_limit: 1000  # Max data points to retrieve (default: 1000)</code></pre> <p>Apply the configuration:</p> <pre><code>helm upgrade robusta robusta/robusta --values=generated_values.yaml --set clusterName=&lt;YOUR_CLUSTER_NAME&gt;</code></pre> </p> <p>Capabilities</p> Tool Description <code>list_active_datadog_metrics</code> List metrics that have reported data in the last 24 hours <code>query_datadog_metrics</code> Query specific metrics with aggregation and filtering <code>get_datadog_metric_metadata</code> Get metadata about available metrics <code>list_datadog_metric_tags</code> List available tags and aggregations for a specific metric <p>Example Usage</p> <pre><code># List available metrics\nholmes ask \"what metrics are available for my application?\"\n\n# Query CPU usage\nholmes ask \"show me CPU usage for the payment service over the last 6 hours\"\n\n# Custom application metrics\nholmes ask \"analyze the payment_processing_time metric for anomalies\"\n</code></pre>"},{"location":"data-sources/builtin-toolsets/datadog/#datadog-traces","title":"Datadog Traces","text":"<p>Analyze distributed traces to identify performance bottlenecks and latency issues.</p> <p>Configuration</p> <p> Holmes CLI Holmes Helm Chart Robusta Helm Chart <p>Add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n  datadog/traces:\n    enabled: true\n    config:\n      dd_api_key: \"{{ env.DD_API_KEY }}\"\n      dd_app_key: \"{{ env.DD_APP_KEY }}\"\n      site_api_url: https://api.datadoghq.com\n      request_timeout: 60  # Timeout in seconds (default: 60)\n\n      # Optional\n      indexes: [\"*\"]  # Trace indexes to search (default: [\"*\"])</code></pre> <p>When using the standalone Holmes Helm Chart, update your <code>values.yaml</code>:</p> <pre><code>toolsets:\n  datadog/traces:\n    enabled: true\n    config:\n      dd_api_key: \"{{ env.DD_API_KEY }}\"\n      dd_app_key: \"{{ env.DD_APP_KEY }}\"\n      site_api_url: https://api.datadoghq.com\n      request_timeout: 60  # Timeout in seconds (default: 60)\n\n      # Optional\n      indexes: [\"*\"]  # Trace indexes to search (default: [\"*\"])</code></pre> <p>Apply the configuration:</p> <pre><code>helm upgrade holmes holmes/holmes --values=values.yaml</code></pre> <p>When using the Robusta Helm Chart (which includes HolmesGPT), update your <code>generated_values.yaml</code>:</p> <pre><code>holmes:\n  toolsets:\n    datadog/traces:\n      enabled: true\n      config:\n        dd_api_key: \"{{ env.DD_API_KEY }}\"\n        dd_app_key: \"{{ env.DD_APP_KEY }}\"\n        site_api_url: https://api.datadoghq.com\n        request_timeout: 60  # Timeout in seconds (default: 60)\n\n        # Optional\n        indexes: [\"*\"]  # Trace indexes to search (default: [\"*\"])</code></pre> <p>Apply the configuration:</p> <pre><code>helm upgrade robusta robusta/robusta --values=generated_values.yaml --set clusterName=&lt;YOUR_CLUSTER_NAME&gt;</code></pre> </p> <p>Capabilities</p> Tool Description <code>fetch_datadog_traces</code> Search and fetch traces by service, operation, or tags <code>fetch_datadog_trace_by_id</code> Get detailed information about a specific trace <code>fetch_datadog_spans</code> Search for spans with specific filters <p>Example Usage</p> <pre><code># Find slow requests\nholmes ask \"find traces where the checkout service took longer than 5 seconds\"\n\n# Analyze specific trace\nholmes ask \"analyze trace ID abc123 for performance issues\"\n\n# Service dependencies\nholmes ask \"show me traces involving both payment and inventory services\"\n</code></pre>"},{"location":"data-sources/builtin-toolsets/datadog/#datadog-rds","title":"Datadog RDS","text":"<p>Monitor and troubleshoot RDS database instances.</p> <p>Configuration</p> <p> Holmes CLI Holmes Helm Chart Robusta Helm Chart <p>Add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n  datadog/rds:\n    enabled: true\n    config:\n      dd_api_key: \"{{ env.DD_API_KEY }}\"\n      dd_app_key: \"{{ env.DD_APP_KEY }}\"\n      site_api_url: https://api.datadoghq.com\n      request_timeout: 60  # Timeout in seconds (default: 60)\n\n      # Optional\n      default_time_span_seconds: 3600  # Time span for queries (default: 1 hour)\n      default_top_instances: 10  # Number of top instances (default: 10)</code></pre> <p>When using the standalone Holmes Helm Chart, update your <code>values.yaml</code>:</p> <pre><code>toolsets:\n  datadog/rds:\n    enabled: true\n    config:\n      dd_api_key: \"{{ env.DD_API_KEY }}\"\n      dd_app_key: \"{{ env.DD_APP_KEY }}\"\n      site_api_url: https://api.datadoghq.com\n      request_timeout: 60  # Timeout in seconds (default: 60)\n\n      # Optional\n      default_time_span_seconds: 3600  # Time span for queries (default: 1 hour)\n      default_top_instances: 10  # Number of top instances (default: 10)</code></pre> <p>Apply the configuration:</p> <pre><code>helm upgrade holmes holmes/holmes --values=values.yaml</code></pre> <p>When using the Robusta Helm Chart (which includes HolmesGPT), update your <code>generated_values.yaml</code>:</p> <pre><code>holmes:\n  toolsets:\n    datadog/rds:\n      enabled: true\n      config:\n        dd_api_key: \"{{ env.DD_API_KEY }}\"\n        dd_app_key: \"{{ env.DD_APP_KEY }}\"\n        site_api_url: https://api.datadoghq.com\n        request_timeout: 60  # Timeout in seconds (default: 60)\n\n        # Optional\n        default_time_span_seconds: 3600  # Time span for queries (default: 1 hour)\n        default_top_instances: 10  # Number of top instances (default: 10)</code></pre> <p>Apply the configuration:</p> <pre><code>helm upgrade robusta robusta/robusta --values=generated_values.yaml --set clusterName=&lt;YOUR_CLUSTER_NAME&gt;</code></pre> </p> <p>Capabilities</p> Tool Description <code>datadog_rds_performance_report</code> Generate comprehensive performance report for an RDS instance <code>datadog_rds_top_worst_performing</code> Get report of worst performing RDS instances by latency, CPU, and errors <p>Example Usage</p> <pre><code># List database instances\nholmes ask \"show me all RDS instances and their status\"\n\n# Performance analysis\nholmes ask \"analyze the performance of the production database\"\n\n# Slow query analysis\nholmes ask \"find slow queries on the analytics database\"\n</code></pre>"},{"location":"data-sources/builtin-toolsets/datadog/#datadog-general","title":"Datadog General","text":"<p>Access general-purpose Datadog API endpoints for read-only operations including monitors, dashboards, SLOs, incidents, synthetics, and more.</p> <p>Configuration</p> <p> Holmes CLI Holmes Helm Chart Robusta Helm Chart <p>Add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n  datadog/general:\n    enabled: true\n    config:\n      dd_api_key: \"{{ env.DD_API_KEY }}\"\n      dd_app_key: \"{{ env.DD_APP_KEY }}\"\n      site_api_url: https://api.datadoghq.com\n      request_timeout: 60  # Timeout in seconds (default: 60)\n\n      # Optional\n      max_response_size: 10485760  # Max response size in bytes (default: 10MB)\n      allow_custom_endpoints: false  # Allow non-whitelisted endpoints (default: false)</code></pre> <p>When using the standalone Holmes Helm Chart, update your <code>values.yaml</code>:</p> <pre><code>toolsets:\n  datadog/general:\n    enabled: true\n    config:\n      dd_api_key: \"{{ env.DD_API_KEY }}\"\n      dd_app_key: \"{{ env.DD_APP_KEY }}\"\n      site_api_url: https://api.datadoghq.com\n      request_timeout: 60  # Timeout in seconds (default: 60)\n\n      # Optional\n      max_response_size: 10485760  # Max response size in bytes (default: 10MB)\n      allow_custom_endpoints: false  # Allow non-whitelisted endpoints (default: false)</code></pre> <p>Apply the configuration:</p> <pre><code>helm upgrade holmes holmes/holmes --values=values.yaml</code></pre> <p>When using the Robusta Helm Chart (which includes HolmesGPT), update your <code>generated_values.yaml</code>:</p> <pre><code>holmes:\n  toolsets:\n    datadog/general:\n      enabled: true\n      config:\n        dd_api_key: \"{{ env.DD_API_KEY }}\"\n        dd_app_key: \"{{ env.DD_APP_KEY }}\"\n        site_api_url: https://api.datadoghq.com\n        request_timeout: 60  # Timeout in seconds (default: 60)\n\n        # Optional\n        max_response_size: 10485760  # Max response size in bytes (default: 10MB)\n        allow_custom_endpoints: false  # Allow non-whitelisted endpoints (default: false)</code></pre> <p>Apply the configuration:</p> <pre><code>helm upgrade robusta robusta/robusta --values=generated_values.yaml --set clusterName=&lt;YOUR_CLUSTER_NAME&gt;</code></pre> </p> <p>Capabilities</p> Tool Description <code>datadog_api_get</code> Perform GET requests to whitelisted Datadog API endpoints <code>datadog_api_post_search</code> Perform POST search operations on whitelisted endpoints <code>list_datadog_api_resources</code> List available API resource categories and endpoints <p>Supported API Endpoints</p> <p>The general toolset provides access to the following read-only API categories:</p> <ul> <li>Monitors: List, search, and get monitor details</li> <li>Dashboards: Access dashboard configurations and lists</li> <li>SLOs: Query Service Level Objectives and their history</li> <li>Events: Search and retrieve events</li> <li>Incidents: Access incident details and timelines</li> <li>Synthetics: Retrieve synthetic test results and configurations</li> <li>Security Monitoring: Access security rules and signals</li> <li>Service Map: Query APM services and dependencies</li> <li>Hosts: List and get host information</li> <li>Usage &amp; Cost: Access usage metrics and cost estimates</li> <li>Organizations &amp; Teams: Query organizational structure</li> </ul> <p>Example Usage</p> <pre><code># List all monitors\nholmes ask \"show me all Datadog monitors\"\n\n# Get dashboard details\nholmes ask \"retrieve my application dashboard from Datadog\"\n\n# Check SLO status\nholmes ask \"what's the current status of our API availability SLO?\"\n\n# Search incidents\nholmes ask \"find recent incidents in Datadog\"\n\n# Get synthetic test results\nholmes ask \"show me the latest synthetic test results for our homepage\"\n</code></pre>"},{"location":"data-sources/builtin-toolsets/datadog/#complete-configuration-example","title":"Complete Configuration Example","text":"<p>Here's a comprehensive example enabling all Datadog toolsets:</p> <p> Holmes CLI Holmes Helm Chart Robusta Helm Chart <p>Add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n  # Logs configuration\n  datadog/logs:\n    enabled: true\n    config:\n      dd_api_key: \"{{ env.DD_API_KEY }}\"\n      dd_app_key: \"{{ env.DD_APP_KEY }}\"\n      site_api_url: https://api.datadoghq.eu  # EU region\n      request_timeout: 60\n      indexes: [\"main\", \"security\"]\n      storage_tiers: [\"indexes\", \"online-archives\"]\n      page_size: 300\n      default_limit: 2000\n      labels:\n        pod: \"pod_name\"\n        namespace: \"kube_namespace\"\n\n  # Metrics configuration\n  datadog/metrics:\n    enabled: true\n    config:\n      dd_api_key: \"{{ env.DD_API_KEY }}\"\n      dd_app_key: \"{{ env.DD_APP_KEY }}\"\n      site_api_url: https://api.datadoghq.eu\n      request_timeout: 60\n      default_limit: 5000\n\n  # Traces configuration\n  datadog/traces:\n    enabled: true\n    config:\n      dd_api_key: \"{{ env.DD_API_KEY }}\"\n      dd_app_key: \"{{ env.DD_APP_KEY }}\"\n      site_api_url: https://api.datadoghq.eu\n      request_timeout: 60\n      indexes: [\"*\"]\n\n  # RDS monitoring\n  datadog/rds:\n    enabled: true\n    config:\n      dd_api_key: \"{{ env.DD_API_KEY }}\"\n      dd_app_key: \"{{ env.DD_APP_KEY }}\"\n      site_api_url: https://api.datadoghq.eu\n      request_timeout: 60\n      default_time_span_seconds: 3600\n      default_top_instances: 10\n\n  # General API access\n  datadog/general:\n    enabled: true\n    config:\n      dd_api_key: \"{{ env.DD_API_KEY }}\"\n      dd_app_key: \"{{ env.DD_APP_KEY }}\"\n      site_api_url: https://api.datadoghq.eu\n      request_timeout: 60\n      max_response_size: 10485760\n      allow_custom_endpoints: false\n\n  # Disable Kubernetes native logging when using Datadog\n  kubernetes/logs:\n    enabled: false</code></pre> <p>When using the standalone Holmes Helm Chart, update your <code>values.yaml</code>:</p> <pre><code>toolsets:\n  # Logs configuration\n  datadog/logs:\n    enabled: true\n    config:\n      dd_api_key: \"{{ env.DD_API_KEY }}\"\n      dd_app_key: \"{{ env.DD_APP_KEY }}\"\n      site_api_url: https://api.datadoghq.eu  # EU region\n      request_timeout: 60\n      indexes: [\"main\", \"security\"]\n      storage_tiers: [\"indexes\", \"online-archives\"]\n      page_size: 300\n      default_limit: 2000\n      labels:\n        pod: \"pod_name\"\n        namespace: \"kube_namespace\"\n\n  # Metrics configuration\n  datadog/metrics:\n    enabled: true\n    config:\n      dd_api_key: \"{{ env.DD_API_KEY }}\"\n      dd_app_key: \"{{ env.DD_APP_KEY }}\"\n      site_api_url: https://api.datadoghq.eu\n      request_timeout: 60\n      default_limit: 5000\n\n  # Traces configuration\n  datadog/traces:\n    enabled: true\n    config:\n      dd_api_key: \"{{ env.DD_API_KEY }}\"\n      dd_app_key: \"{{ env.DD_APP_KEY }}\"\n      site_api_url: https://api.datadoghq.eu\n      request_timeout: 60\n      indexes: [\"*\"]\n\n  # RDS monitoring\n  datadog/rds:\n    enabled: true\n    config:\n      dd_api_key: \"{{ env.DD_API_KEY }}\"\n      dd_app_key: \"{{ env.DD_APP_KEY }}\"\n      site_api_url: https://api.datadoghq.eu\n      request_timeout: 60\n      default_time_span_seconds: 3600\n      default_top_instances: 10\n\n  # General API access\n  datadog/general:\n    enabled: true\n    config:\n      dd_api_key: \"{{ env.DD_API_KEY }}\"\n      dd_app_key: \"{{ env.DD_APP_KEY }}\"\n      site_api_url: https://api.datadoghq.eu\n      request_timeout: 60\n      max_response_size: 10485760\n      allow_custom_endpoints: false\n\n  # Disable Kubernetes native logging when using Datadog\n  kubernetes/logs:\n    enabled: false</code></pre> <p>Apply the configuration:</p> <pre><code>helm upgrade holmes holmes/holmes --values=values.yaml</code></pre> <p>When using the Robusta Helm Chart (which includes HolmesGPT), update your <code>generated_values.yaml</code>:</p> <pre><code>holmes:\n  toolsets:\n    # Logs configuration\n    datadog/logs:\n      enabled: true\n      config:\n        dd_api_key: \"{{ env.DD_API_KEY }}\"\n        dd_app_key: \"{{ env.DD_APP_KEY }}\"\n        site_api_url: https://api.datadoghq.eu  # EU region\n        request_timeout: 60\n        indexes: [\"main\", \"security\"]\n        storage_tiers: [\"indexes\", \"online-archives\"]\n        page_size: 300\n        default_limit: 2000\n        labels:\n          pod: \"pod_name\"\n          namespace: \"kube_namespace\"\n\n    # Metrics configuration\n    datadog/metrics:\n      enabled: true\n      config:\n        dd_api_key: \"{{ env.DD_API_KEY }}\"\n        dd_app_key: \"{{ env.DD_APP_KEY }}\"\n        site_api_url: https://api.datadoghq.eu\n        request_timeout: 60\n        default_limit: 5000\n\n    # Traces configuration\n    datadog/traces:\n      enabled: true\n      config:\n        dd_api_key: \"{{ env.DD_API_KEY }}\"\n        dd_app_key: \"{{ env.DD_APP_KEY }}\"\n        site_api_url: https://api.datadoghq.eu\n        request_timeout: 60\n        indexes: [\"*\"]\n\n    # RDS monitoring\n    datadog/rds:\n      enabled: true\n      config:\n        dd_api_key: \"{{ env.DD_API_KEY }}\"\n        dd_app_key: \"{{ env.DD_APP_KEY }}\"\n        site_api_url: https://api.datadoghq.eu\n        request_timeout: 60\n        default_time_span_seconds: 3600\n        default_top_instances: 10\n\n    # General API access\n    datadog/general:\n      enabled: true\n      config:\n        dd_api_key: \"{{ env.DD_API_KEY }}\"\n        dd_app_key: \"{{ env.DD_APP_KEY }}\"\n        site_api_url: https://api.datadoghq.eu\n        request_timeout: 60\n        max_response_size: 10485760\n        allow_custom_endpoints: false\n\n    # Disable Kubernetes native logging when using Datadog\n    kubernetes/logs:\n      enabled: false</code></pre> <p>Apply the configuration:</p> <pre><code>helm upgrade robusta robusta/robusta --values=generated_values.yaml --set clusterName=&lt;YOUR_CLUSTER_NAME&gt;</code></pre> </p>"},{"location":"data-sources/builtin-toolsets/datetime/","title":"Datetime \u2713","text":"<p>Enabled by Default</p> <p>This toolset is enabled by default. You do not need to configure it. You can disable it if you want to but doing so may negatively impact HolmesGPT's ability to investigate issues.</p> <p>By enabling this toolset, HolmesGPT will be able to get the current UTC date and time. This feature should be kept enabled as it can be necessary for other toolsets that rely on dates and time.</p> <p>The following built-in toolsets depend on <code>datetime</code>:</p> <ul> <li>Loki</li> <li>Prometheus</li> <li>Coralogix logs</li> </ul>"},{"location":"data-sources/builtin-toolsets/datetime/#configuration","title":"Configuration","text":"<pre><code>holmes:\n    toolsets:\n        datetime:\n            enabled: true\n</code></pre>"},{"location":"data-sources/builtin-toolsets/datetime/#capabilities","title":"Capabilities","text":"Tool Name Description get_current_time Return current time information. Useful to build queries that require time information"},{"location":"data-sources/builtin-toolsets/docker/","title":"Docker","text":"<p>Not Recommended for Kubernetes</p> <p>This integration is not recommended for monitoring a Kubernetes cluster because it is neither necessary nor useful. It is documented here for users of HolmesGPT CLI.</p> <p>Read access to Docker resources.</p>"},{"location":"data-sources/builtin-toolsets/docker/#configuration","title":"Configuration","text":"Holmes CLI <p>Add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n    docker/core:\n        enabled: true\n</code></pre> <p>After making changes to your configuration, run: <pre><code>holmes toolset refresh\n</code></pre></p>"},{"location":"data-sources/builtin-toolsets/docker/#capabilities","title":"Capabilities","text":"<p>The table below describes the specific capabilities provided by this toolset. HolmesGPT can decide to invoke any of these capabilities when answering questions or investigating issues.</p> Tool Name Description docker_images List all Docker images docker_ps List all running Docker containers docker_ps_all List all Docker containers, including stopped ones docker_inspect Inspect detailed information about a Docker container or image docker_logs Fetch the logs of a Docker container docker_top Display the running processes of a container docker_events Get real-time events from the Docker server docker_history Show the history of an image docker_diff Inspect changes to files or directories on a container's filesystem"},{"location":"data-sources/builtin-toolsets/github/","title":"Git/GitHub","text":"<p>By enabling this toolset, HolmesGPT will be able to interact with GitHub repositories, read files with line numbers, list repository contents, manage pull requests, and make file changes.</p>"},{"location":"data-sources/builtin-toolsets/github/#prerequisites","title":"Prerequisites","text":"<ol> <li>A GitHub repository URL (e.g., <code>owner/repo</code>)</li> <li>A GitHub Personal Access Token with appropriate permissions:</li> <li><code>repo</code> scope for private repositories</li> <li><code>public_repo</code> scope for public repositories</li> <li><code>pull_requests:write</code> for creating and updating PRs</li> </ol> <p>You can create a token at GitHub Settings &gt; Developer settings &gt; Personal access tokens.</p>"},{"location":"data-sources/builtin-toolsets/github/#configuration","title":"Configuration","text":"Holmes CLIRobusta Helm Chart <p>First, set the following environment variables:</p> <pre><code>export GIT_REPO=\"owner/repo\"  # e.g., \"facebook/react\"\nexport GIT_CREDENTIALS=\"&lt;your GitHub personal access token&gt;\"\nexport GIT_BRANCH=\"main\"  # optional, defaults to \"main\"\n</code></pre> <p>Then add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n  git:\n    enabled: true\n    config:\n      git_repo: \"owner/repo\"  # if not set via environment variable\n      git_credentials: \"&lt;token&gt;\"  # if not set via environment variable\n      git_branch: \"main\"  # optional, defaults to \"main\"\n</code></pre> <p>After making changes to your configuration, run: <pre><code>holmes toolset refresh\n</code></pre></p> <p>To test, run:</p> <pre><code>holmes ask \"List the files in the GitHub repository and read the README file\"\n</code></pre> <pre><code>holmes:\n  additionalEnvVars:\n    - name: GIT_REPO\n      value: \"owner/repo\"\n    - name: GIT_CREDENTIALS\n      value: \"&lt;your GitHub personal access token&gt;\"\n    - name: GIT_BRANCH\n      value: \"main\"  # optional\n  toolsets:\n    git:\n      enabled: true\n</code></pre>"},{"location":"data-sources/builtin-toolsets/github/#configuration-options","title":"Configuration Options","text":"<p>The toolset can be configured via environment variables or config file:</p> <pre><code>toolsets:\n  git:\n    enabled: true\n    config:\n      git_repo: \"owner/repo\"  # GitHub repository (e.g., \"facebook/react\")\n      git_credentials: \"&lt;token&gt;\"  # GitHub personal access token\n      git_branch: \"main\"  # Branch to use (defaults to \"main\")\n</code></pre> <p>Note: Environment variables (<code>GIT_REPO</code>, <code>GIT_CREDENTIALS</code>, <code>GIT_BRANCH</code>) take precedence over config file settings.</p>"},{"location":"data-sources/builtin-toolsets/github/#capabilities","title":"Capabilities","text":"Tool Name Description <code>git_read_file_with_line_numbers</code> Read a file from the configured branch with line numbers for each line <code>git_list_files</code> List all files and directories in the configured branch (recursive) <code>git_list_open_prs</code> List all open pull requests in the repository <code>git_execute_changes</code> Make line-based changes to files and optionally create or update PRs <code>git_update_pr</code> Update an existing PR that was created by this tool"},{"location":"data-sources/builtin-toolsets/github/#tool-details","title":"Tool Details","text":""},{"location":"data-sources/builtin-toolsets/github/#git_execute_changes","title":"git_execute_changes","text":"<p>This tool modifies files line-by-line and can create or update pull requests. It requires a two-step workflow: 1. First run with <code>dry_run=true</code> to preview changes 2. Then run with <code>dry_run=false</code> to commit changes</p> <p>Key Parameters: - <code>line</code>: Line number where the change occurs - <code>command</code>: Operation type (<code>insert</code>, <code>update</code>, or <code>remove</code>) - <code>commit_pr</code>: Either a PR title (for new PRs) or PR number like <code>#123</code> (for updating existing PRs) - <code>open_pr</code>: Set to <code>true</code> to create a new PR, <code>false</code> to just commit to a branch</p> <p>Branch Naming: When creating new PRs, branches are automatically named as <code>feature/{pr_title}</code> with spaces replaced by underscores.</p>"},{"location":"data-sources/builtin-toolsets/github/#git_update_pr","title":"git_update_pr","text":"<p>This tool updates existing PRs that were created by <code>git_execute_changes</code>. It uses the same line-based modification approach and dry_run workflow.</p>"},{"location":"data-sources/builtin-toolsets/github/#reading-and-listing-files","title":"Reading and Listing Files","text":"<ul> <li><code>git_read_file_with_line_numbers</code> and <code>git_list_files</code> operate only on the branch configured in <code>git_branch</code> (defaults to \"main\")</li> <li>To read files from other branches, you would need to reconfigure the toolset with a different branch</li> </ul>"},{"location":"data-sources/builtin-toolsets/github/#important-notes","title":"Important Notes","text":"<ul> <li>The toolset can only modify PRs it created (tracked internally)</li> <li>All file paths should be relative to the repository root</li> <li>This toolset is marked as experimental and its interface may change in future versions</li> </ul>"},{"location":"data-sources/builtin-toolsets/grafanadashboards/","title":"Grafana Dashboards","text":"<p>Connect HolmesGPT to Grafana for dashboard analysis, query extraction, and understanding your monitoring setup. This integration enables investigation of dashboard configurations and extraction of Prometheus queries for deeper analysis.</p>"},{"location":"data-sources/builtin-toolsets/grafanadashboards/#prerequisites","title":"Prerequisites","text":"<p>A Grafana service account token with the following permissions:</p> <ul> <li>Basic role \u2192 Viewer</li> </ul>"},{"location":"data-sources/builtin-toolsets/grafanadashboards/#configuration","title":"Configuration","text":"Holmes CLIRobusta Helm Chart <p>Add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n  grafana/dashboards:\n    enabled: true\n    config:\n      api_key: &lt;your grafana service account token&gt;\n      url: &lt;your grafana url&gt;  # e.g. https://acme-corp.grafana.net or http://localhost:3000\n      # Optional: Custom health check endpoint (defaults to api/health)\n      # healthcheck: api/health\n      # Optional: Additional headers for all requests\n      # headers:\n      #   X-Custom-Header: \"custom-value\"\n</code></pre> <p>After making changes to your configuration, run: <pre><code>holmes toolset refresh\n</code></pre></p> <p>To test, run:</p> <pre><code>holmes ask \"Show me all dashboards tagged with 'kubernetes'\"\n</code></pre> <pre><code>holmes:\n  toolsets:\n    grafana/dashboards:\n      enabled: true\n      config:\n        api_key: &lt;your grafana API key&gt;\n        url: &lt;your grafana url&gt;  # e.g. https://acme-corp.grafana.net\n        # Optional: Additional headers for all requests\n        # headers:\n        #   X-Custom-Header: \"custom-value\"\n</code></pre>"},{"location":"data-sources/builtin-toolsets/grafanadashboards/#capabilities","title":"Capabilities","text":"Tool Name Description grafana_search_dashboards Search for dashboards and folders by query, tags, UIDs, or folder locations grafana_get_dashboard_by_uid Retrieve complete dashboard JSON including all panels and queries grafana_get_home_dashboard Get the home dashboard configuration grafana_get_dashboard_tags List all tags used across dashboards for categorization"},{"location":"data-sources/builtin-toolsets/grafanadashboards/#how-it-works","title":"How it Works","text":""},{"location":"data-sources/builtin-toolsets/grafanadashboards/#dashboard-query-extraction","title":"Dashboard Query Extraction","text":"<p>When HolmesGPT retrieves a dashboard, it can extract and analyze Prometheus queries from dashboard panels. This is particularly useful for:</p> <ul> <li>Understanding what metrics a dashboard monitors</li> <li>Extracting queries for further investigation with the Prometheus toolset</li> <li>Analyzing dashboard time ranges and variable usage</li> </ul>"},{"location":"data-sources/builtin-toolsets/grafanadashboards/#example-usage","title":"Example Usage","text":"<p>Finding dashboards by tag: <pre><code>holmes ask \"Find all dashboards tagged with 'production' or 'kubernetes'\"\n</code></pre></p> <p>Analyzing a specific dashboard: <pre><code>holmes ask \"Show me what metrics the 'Node Exporter' dashboard monitors\"\n</code></pre></p> <p>Extracting queries for investigation: <pre><code>holmes ask \"Get the CPU usage queries from the Kubernetes cluster dashboard and check if any nodes are throttling\"\n</code></pre></p>"},{"location":"data-sources/builtin-toolsets/grafanaloki/","title":"Loki","text":"<p>Connect HolmesGPT to Loki for log analysis through Grafana or direct API access. Provides access to historical logs and advanced log queries.</p>"},{"location":"data-sources/builtin-toolsets/grafanaloki/#when-to-use-this","title":"When to Use This","text":"<ul> <li>\u2705 Your Kubernetes logs are centralized in Loki</li> <li>\u2705 You need historical log data beyond what's in pods</li> <li>\u2705 You want advanced log search capabilities</li> </ul>"},{"location":"data-sources/builtin-toolsets/grafanaloki/#prerequisites","title":"Prerequisites","text":"<ul> <li>Loki instance with logs from your Kubernetes cluster</li> <li>Grafana with Loki datasource configured (recommended) OR direct Loki API access</li> </ul> Important: Disable Default Logging Toolset <p>Only one logging toolset should be enabled at a time. If you enable this toolset, disable the default <code>kubernetes/logs</code> toolset.</p> <p>Available Log Sources:</p> <ul> <li>Kubernetes logs - Direct pod log access (enabled by default)</li> <li>Loki - Centralized logs via Loki</li> <li>OpenSearch logs - Logs from OpenSearch/Elasticsearch</li> <li>Coralogix logs - Logs via Coralogix platform</li> <li>DataDog - Logs from DataDog</li> </ul> <p>\ud83d\udca1 Choose one: Only enable one logging toolset at a time for best performance.</p>"},{"location":"data-sources/builtin-toolsets/grafanaloki/#configuration","title":"Configuration","text":"<p>Choose one of the following methods:</p>"},{"location":"data-sources/builtin-toolsets/grafanaloki/#option-1-through-grafana-recommended","title":"Option 1: Through Grafana (Recommended)","text":"<p>Required: - Grafana service account token with Viewer role - Loki datasource UID from Grafana</p> <p>Find your Loki datasource UID: <pre><code># Port forward to Grafana\nkubectl port-forward svc/grafana 3000:80\n\n# Get Loki datasource UID\ncurl -s -u admin:admin http://localhost:3000/api/datasources | jq '.[] | select(.type == \"loki\") | .uid'\n</code></pre></p>"},{"location":"data-sources/builtin-toolsets/grafanaloki/#configuration-grafana-proxy","title":"Configuration (Grafana Proxy)","text":"<p> Holmes CLI Holmes Helm Chart Robusta Helm Chart <p>Add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n  grafana/loki:\n    enabled: true\n    config:\n      api_key: &lt;your grafana API key&gt;\n      url: https://xxxxxxx.grafana.net # Your Grafana cloud account URL\n      grafana_datasource_uid: &lt;the UID of the loki data source in Grafana&gt;\n\n  kubernetes/logs:\n    enabled: false # HolmesGPT's default logging mechanism MUST be disabled</code></pre> <p>When using the standalone Holmes Helm Chart, update your <code>values.yaml</code>:</p> <pre><code>toolsets:\n  grafana/loki:\n    enabled: true\n    config:\n      api_key: &lt;your grafana API key&gt;\n      url: https://xxxxxxx.grafana.net # Your Grafana cloud account URL\n      grafana_datasource_uid: &lt;the UID of the loki data source in Grafana&gt;\n\n  kubernetes/logs:\n    enabled: false # HolmesGPT's default logging mechanism MUST be disabled</code></pre> <p>Apply the configuration:</p> <pre><code>helm upgrade holmes holmes/holmes --values=values.yaml</code></pre> <p>When using the Robusta Helm Chart (which includes HolmesGPT), update your <code>generated_values.yaml</code>:</p> <pre><code>holmes:\n  toolsets:\n    grafana/loki:\n      enabled: true\n      config:\n        api_key: &lt;your grafana API key&gt;\n        url: https://xxxxxxx.grafana.net # Your Grafana cloud account URL\n        grafana_datasource_uid: &lt;the UID of the loki data source in Grafana&gt;\n\n    kubernetes/logs:\n      enabled: false # HolmesGPT's default logging mechanism MUST be disabled</code></pre> <p>Apply the configuration:</p> <pre><code>helm upgrade robusta robusta/robusta --values=generated_values.yaml --set clusterName=&lt;YOUR_CLUSTER_NAME&gt;</code></pre> </p>"},{"location":"data-sources/builtin-toolsets/grafanaloki/#direct-connection","title":"Direct Connection","text":"<p>The toolset can directly connect to a Loki instance without proxying through a Grafana instance. This is done by not setting the <code>grafana_datasource_uid</code> field. Not setting this field makes HolmesGPT assume that it is directly connecting to Loki.</p>"},{"location":"data-sources/builtin-toolsets/grafanaloki/#configuration-direct-connection","title":"Configuration (Direct Connection)","text":"<p> Holmes CLI Holmes Helm Chart Robusta Helm Chart <p>Add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n  grafana/loki:\n    enabled: true\n    config:\n      url: http://loki.logging\n      headers:\n        X-Scope-OrgID: \"&lt;tenant id&gt;\" # Set the X-Scope-OrgID if loki multitenancy is enabled\n\n  kubernetes/logs:\n    enabled: false # HolmesGPT's default logging mechanism MUST be disabled</code></pre> <p>When using the standalone Holmes Helm Chart, update your <code>values.yaml</code>:</p> <pre><code>toolsets:\n  grafana/loki:\n    enabled: true\n    config:\n      url: http://loki.logging\n      headers:\n        X-Scope-OrgID: \"&lt;tenant id&gt;\" # Set the X-Scope-OrgID if loki multitenancy is enabled\n\n  kubernetes/logs:\n    enabled: false # HolmesGPT's default logging mechanism MUST be disabled</code></pre> <p>Apply the configuration:</p> <pre><code>helm upgrade holmes holmes/holmes --values=values.yaml</code></pre> <p>When using the Robusta Helm Chart (which includes HolmesGPT), update your <code>generated_values.yaml</code>:</p> <pre><code>holmes:\n  toolsets:\n    grafana/loki:\n      enabled: true\n      config:\n        url: http://loki.logging\n        headers:\n          X-Scope-OrgID: \"&lt;tenant id&gt;\" # Set the X-Scope-OrgID if loki multitenancy is enabled\n\n    kubernetes/logs:\n      enabled: false # HolmesGPT's default logging mechanism MUST be disabled</code></pre> <p>Apply the configuration:</p> <pre><code>helm upgrade robusta robusta/robusta --values=generated_values.yaml --set clusterName=&lt;YOUR_CLUSTER_NAME&gt;</code></pre> </p>"},{"location":"data-sources/builtin-toolsets/grafanaloki/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"data-sources/builtin-toolsets/grafanaloki/#search-labels","title":"Search Labels","text":"<p>You can tweak the labels used by the toolset to identify Kubernetes resources. This is only needed if your Loki logs settings for <code>pod</code> and <code>namespace</code> differ from the defaults.</p> <p> Holmes CLI Holmes Helm Chart Robusta Helm Chart <p>Add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n  grafana/loki:\n    enabled: true\n    config:\n      url: ...\n      labels:\n          pod: \"pod\"\n          namespace: \"namespace\"</code></pre> <p>When using the standalone Holmes Helm Chart, update your <code>values.yaml</code>:</p> <pre><code>toolsets:\n  grafana/loki:\n    enabled: true\n    config:\n      url: ...\n      labels:\n          pod: \"pod\"\n          namespace: \"namespace\"</code></pre> <p>Apply the configuration:</p> <pre><code>helm upgrade holmes holmes/holmes --values=values.yaml</code></pre> <p>When using the Robusta Helm Chart (which includes HolmesGPT), update your <code>generated_values.yaml</code>:</p> <pre><code>holmes:\n  toolsets:\n    grafana/loki:\n      enabled: true\n      config:\n        url: ...\n        labels:\n            pod: \"pod\"\n            namespace: \"namespace\"</code></pre> <p>Apply the configuration:</p> <pre><code>helm upgrade robusta robusta/robusta --values=generated_values.yaml --set clusterName=&lt;YOUR_CLUSTER_NAME&gt;</code></pre> </p> <p>Use the following commands to list Loki's labels and determine which ones to use:</p> <pre><code># Make Loki accessible locally\nkubectl port-forward svc/loki 3100:3100\n\n# List all labels. You may have to add the -H 'X-Scope-OrgID:&lt;org id&gt;' option with a valid org id\ncurl http://localhost:3100/loki/api/v1/labels\n</code></pre>"},{"location":"data-sources/builtin-toolsets/grafanaloki/#capabilities","title":"Capabilities","text":"Tool Name Description fetch_pod_logs Fetches pod logs from Loki"},{"location":"data-sources/builtin-toolsets/grafanatempo/","title":"Tempo","text":"<p>By enabling this toolset, HolmesGPT will be able to fetch trace information from Tempo to debug performance related issues, like high latency in your application.</p>"},{"location":"data-sources/builtin-toolsets/grafanatempo/#proxying-through-grafana","title":"Proxying through Grafana","text":"<p>This is the recommended approach because we intend to add more capabilities to the toolset that are only available with Grafana.</p>"},{"location":"data-sources/builtin-toolsets/grafanatempo/#prerequisites","title":"Prerequisites","text":"<p>A Grafana service account token with the following permissions:</p> <ul> <li>Basic role -&gt; Viewer</li> <li>Data sources -&gt; Reader</li> </ul> <p>Check out this video on creating a Grafana service account token.</p> <p>Getting Grafana URL</p> <p>You can find the Grafana URL required for Tempo in your Grafana cloud account settings.</p> <p>Obtaining the datasource UID</p> <p>You may have multiple Tempo data sources set up in Grafana. HolmesGPT uses a single Tempo datasource to fetch the traces and it needs to know the UID of this datasource.</p> <p>A simple way to get the datasource UID is to access the Grafana API by running the following request:</p> <pre><code># port forward if you are using Robusta's Grafana from your Kubernetes cluster\nkubectl port-forward svc/robusta-grafana 3000:80\n# List the Tempo data sources\ncurl -s -u &lt;username&gt;:&lt;password&gt; http://localhost:3000/api/datasources | jq '.[] | select(.type == \"tempo\")'\n</code></pre> <p>This will return something like:</p> <pre><code>{\n    \"id\": 3,\n    \"uid\": \"klja8hsa-8a9c-4b35-1230-7baab22b02ee\",\n    \"orgId\": 1,\n    \"name\": \"Tempo\",\n    \"type\": \"tempo\",\n    \"typeName\": \"Tempo\",\n    \"typeLogoUrl\": \"/public/app/plugins/datasource/tempo/img/tempo_icon.svg\",\n    \"access\": \"proxy\",\n    \"url\": \"http://tempo-query-frontend.tempo:3100\",\n    \"user\": \"\",\n    \"database\": \"\",\n    \"basicAuth\": false,\n    \"isDefault\": false,\n    \"jsonData\": {\n        \"tlsSkipVerify\": true\n    },\n    \"readOnly\": false\n}\n</code></pre> <p>In this case, the Tempo datasource UID is <code>klja8hsa-8a9c-4b35-1230-7baab22b02ee</code>.</p>"},{"location":"data-sources/builtin-toolsets/grafanatempo/#configuration-grafana-proxy","title":"Configuration (Grafana Proxy)","text":"Holmes CLIRobusta Helm Chart <p>Add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n  grafana/tempo:\n    enabled: true\n    config:\n      api_key: &lt;your grafana service account token&gt;\n      url: &lt;your grafana url&gt; # e.g. https://acme-corp.grafana.net\n      grafana_datasource_uid: &lt;the UID of the tempo data source in Grafana&gt;\n</code></pre> <p>After making changes to your configuration, run: <pre><code>holmes toolset refresh\n</code></pre></p> <p>To test, run:</p> <pre><code>holmes ask \"The payments DB is very slow, check tempo for any trace data\"\n</code></pre> <pre><code>holmes:\n  toolsets:\n    grafana/tempo:\n      enabled: true\n      config:\n        api_key: &lt;your grafana API key&gt;\n        url: &lt;your grafana url&gt; # e.g. https://acme-corp.grafana.net\n        grafana_datasource_uid: &lt;the UID of the tempo data source in Grafana&gt;\n</code></pre>"},{"location":"data-sources/builtin-toolsets/grafanatempo/#direct-connection","title":"Direct Connection","text":"<p>The toolset can directly connect to a Tempo instance without proxying through a Grafana instance. This is done by not setting the <code>grafana_datasource_uid</code> field. Not setting this field makes HolmesGPT assume that it is directly connecting to Tempo.</p>"},{"location":"data-sources/builtin-toolsets/grafanatempo/#configuration-direct-connection","title":"Configuration (Direct Connection)","text":"Holmes CLIRobusta Helm Chart <p>Add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n  grafana/tempo:\n    enabled: true\n    config:\n      url: http://tempo.monitoring\n      headers:\n        X-Scope-OrgID: \"&lt;tenant id&gt;\" # Set the X-Scope-OrgID if tempo multitenancy is enabled\n</code></pre> <p>After making changes to your configuration, run: <pre><code>holmes toolset refresh\n</code></pre></p> <pre><code>holmes:\n  toolsets:\n    grafana/tempo:\n      enabled: true\n      config:\n        url: http://tempo.monitoring\n        headers:\n          X-Scope-OrgID: \"&lt;tenant id&gt;\" # Set the X-Scope-OrgID if tempo multitenancy is enabled\n</code></pre>"},{"location":"data-sources/builtin-toolsets/grafanatempo/#example-usage","title":"Example Usage","text":""},{"location":"data-sources/builtin-toolsets/grafanatempo/#finding-slow-traces","title":"Finding Slow Traces","text":"<pre><code>homles ask \"Find traces where the payment service is taking longer than 1 second\"\n</code></pre> <p>Holmes will use TraceQL to search for slow operations: <pre><code>{resource.service.name=\"payment\" &amp;&amp; duration &gt; 1s}\n</code></pre></p>"},{"location":"data-sources/builtin-toolsets/grafanatempo/#analyzing-errors","title":"Analyzing Errors","text":"<pre><code>homles ask \"Show me traces with HTTP 500 errors in the frontend service\"\n</code></pre> <p>Holmes will search using: <pre><code>{resource.service.name=\"frontend\" &amp;&amp; span.http.status_code = 500}\n</code></pre></p>"},{"location":"data-sources/builtin-toolsets/grafanatempo/#capabilities","title":"Capabilities","text":"Tool Name Description tempo_fetch_traces_comparative_sample Fetches statistics and samples of fast/slow/typical traces for performance analysis tempo_search_traces_by_query Search traces using TraceQL query language (recommended) tempo_search_traces_by_tags Search traces using logfmt-encoded tags (legacy) tempo_query_trace_by_id Retrieve detailed trace information by trace ID tempo_search_tag_names Discover available tag names across traces tempo_search_tag_values Get all values for a specific tag tempo_query_metrics_instant Compute a single TraceQL metric value across time range tempo_query_metrics_range Get time series data from TraceQL metrics queries"},{"location":"data-sources/builtin-toolsets/helm/","title":"Helm \u2713","text":"<p>Enabled by Default</p> <p>This toolset is enabled by default. You do not need to configure it. You can disable it if you want to but doing so may negatively impact HolmesGPT's ability to investigate issues.</p> <p>By enabling this toolset, HolmesGPT will be able to provide read access to a cluster's Helm charts and releases.</p>"},{"location":"data-sources/builtin-toolsets/helm/#configuration","title":"Configuration","text":"Holmes CLIRobusta Helm Chart <p>Add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n    helm/core:\n        enabled: true\n</code></pre> <p>After making changes to your configuration, run: <pre><code>holmes toolset refresh\n</code></pre></p> <pre><code>holmes:\n    toolsets:\n        helm/core:\n            enabled: true\n    customClusterRoleRules:\n        - apiGroups: [\"\"]\n          resources: [\"secrets\", \"pods\", \"services\", \"configmaps\", \"persistentvolumeclaims\"]\n          verbs: [\"get\", \"list\", \"watch\"]\n        - apiGroups: [\"\"]\n          resources: [\"namespaces\"]\n          verbs: [\"get\"]\n        - apiGroups: [\"apps\"]\n          resources: [\"deployments\", \"statefulsets\", \"daemonsets\"]\n          verbs: [\"get\", \"list\", \"watch\"]\n        - apiGroups: [\"batch\"]\n          resources: [\"jobs\", \"cronjobs\"]\n          verbs: [\"get\", \"list\", \"watch\"]\n        - apiGroups: [\"networking.k8s.io\"]\n          resources: [\"ingresses\"]\n          verbs: [\"get\", \"list\", \"watch\"]\n</code></pre> <p>Update your Helm values and run a Helm upgrade: <pre><code>helm upgrade robusta robusta/robusta --values=generated_values.yaml --set clusterName=&lt;YOUR_CLUSTER_NAME&gt;\n</code></pre></p>"},{"location":"data-sources/builtin-toolsets/helm/#capabilities","title":"Capabilities","text":"<p>The table below describes the specific capabilities provided by this toolset. HolmesGPT can decide to invoke any of these capabilities when answering questions or investigating issues.</p> Tool Name Description helm_list Use to get all the current helm releases helm_values Use to gather Helm values or any released helm chart helm_status Check the status of a Helm release helm_history Get the revision history of a Helm release helm_manifest Fetch the generated Kubernetes manifest for a Helm release helm_hooks Get the hooks for a Helm release helm_chart Show the chart used to create a Helm release helm_notes Show the notes provided by the Helm chart"},{"location":"data-sources/builtin-toolsets/internet/","title":"Internet \u2713","text":"<p>Enabled by Default</p> <p>This toolset is enabled by default and should typically remain enabled.</p> <p>By enabling this toolset, HolmesGPT will be able to fetch webpages. This tool is beneficial if you provide Holmes with publicly accessible web-based runbooks.</p>"},{"location":"data-sources/builtin-toolsets/internet/#configuration","title":"Configuration","text":"<pre><code>holmes:\n    toolsets:\n        internet:\n            enabled: true\n            config: # optional\n              additional_headers:\n                Authorization: Bearer ...\n</code></pre>"},{"location":"data-sources/builtin-toolsets/internet/#capabilities","title":"Capabilities","text":"Tool Name Description fetch_webpage Fetch a webpage. Use this to fetch runbooks if they are present before starting your investigation (if no other tool like Confluence is more appropriate)"},{"location":"data-sources/builtin-toolsets/kafka/","title":"Kafka","text":"<p>By enabling this toolset, HolmesGPT will be able to fetch metadata from Kafka. This provides Holmes the ability to introspect into Kafka by listing consumers and topics or finding lagging consumer groups.</p> <p>This toolset uses the AdminClient of the confluent-kafka python library. Kafka's Java API is also a good source of documentation.</p>"},{"location":"data-sources/builtin-toolsets/kafka/#configuration","title":"Configuration","text":"<p> Holmes CLI Holmes Helm Chart Robusta Helm Chart <p>Add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n    kafka/admin:\n        enabled: true\n        config:\n            kafka_clusters:\n                - name: aks-prod-kafka\n                  kafka_broker: kafka-1.aks-prod-kafka-brokers.kafka.svc:9095\n                  kafka_username: kafka-plaintext-user\n                  kafka_password: ******\n                  kafka_sasl_mechanism: SCRAM-SHA-512\n                  kafka_security_protocol: SASL_PLAINTEXT\n                - name: gke-stg-kafka\n                  kafka_broker: gke-kafka.gke-stg-kafka-brokers.kafka.svc:9095\n                  kafka_username: kafka-plaintext-user\n                  kafka_password: ****\n                  kafka_sasl_mechanism: SCRAM-SHA-512\n                  kafka_security_protocol: SASL_PLAINTEXT</code></pre> <p>When using the standalone Holmes Helm Chart, update your <code>values.yaml</code>:</p> <pre><code>toolsets:\n    kafka/admin:\n        enabled: true\n        config:\n            kafka_clusters:\n                - name: aks-prod-kafka\n                  kafka_broker: kafka-1.aks-prod-kafka-brokers.kafka.svc:9095\n                  kafka_username: kafka-plaintext-user\n                  kafka_password: ******\n                  kafka_sasl_mechanism: SCRAM-SHA-512\n                  kafka_security_protocol: SASL_PLAINTEXT\n                - name: gke-stg-kafka\n                  kafka_broker: gke-kafka.gke-stg-kafka-brokers.kafka.svc:9095\n                  kafka_username: kafka-plaintext-user\n                  kafka_password: ****\n                  kafka_sasl_mechanism: SCRAM-SHA-512\n                  kafka_security_protocol: SASL_PLAINTEXT</code></pre> <p>Apply the configuration:</p> <pre><code>helm upgrade holmes holmes/holmes --values=values.yaml</code></pre> <p>When using the Robusta Helm Chart (which includes HolmesGPT), update your <code>generated_values.yaml</code>:</p> <pre><code>holmes:\n  toolsets:\n      kafka/admin:\n          enabled: true\n          config:\n              kafka_clusters:\n                  - name: aks-prod-kafka\n                    kafka_broker: kafka-1.aks-prod-kafka-brokers.kafka.svc:9095\n                    kafka_username: kafka-plaintext-user\n                    kafka_password: ******\n                    kafka_sasl_mechanism: SCRAM-SHA-512\n                    kafka_security_protocol: SASL_PLAINTEXT\n                  - name: gke-stg-kafka\n                    kafka_broker: gke-kafka.gke-stg-kafka-brokers.kafka.svc:9095\n                    kafka_username: kafka-plaintext-user\n                    kafka_password: ****\n                    kafka_sasl_mechanism: SCRAM-SHA-512\n                    kafka_security_protocol: SASL_PLAINTEXT</code></pre> <p>Apply the configuration:</p> <pre><code>helm upgrade robusta robusta/robusta --values=generated_values.yaml --set clusterName=&lt;YOUR_CLUSTER_NAME&gt;</code></pre> </p> <p>Below is a description of the configuration field for each cluster:</p> Config key Description name Give a meaningful name to your cluster. Holmes will use it to decide what cluster to look into. Names must be unique across all clusters. kafka_broker List of host/port pairs to use for establishing the initial connection to the Kafka cluster kafka_username Username for SASL authentication kafka_password Password for SASL authentication kafka_sasl_mechanism SASL mechanism (e.g., SCRAM-SHA-512) kafka_security_protocol Security protocol (e.g., SASL_PLAINTEXT)"},{"location":"data-sources/builtin-toolsets/kafka/#capabilities","title":"Capabilities","text":"<p>The table below describes the specific capabilities provided by this toolset. HolmesGPT can decide to invoke any of these capabilities when answering questions or investigating issues.</p> Tool Name Description kafka_list_topics List all Kafka topics kafka_describe_topic Get detailed information about a specific topic kafka_list_consumers List all consumer groups kafka_describe_consumer Get detailed information about a consumer group kafka_consumer_lag Check consumer lag for a consumer group"},{"location":"data-sources/builtin-toolsets/kubernetes/","title":"Kubernetes Toolsets","text":""},{"location":"data-sources/builtin-toolsets/kubernetes/#core","title":"Core \u2713","text":"<p>Enabled by Default</p> <p>This toolset is enabled by default and should typically remain enabled.</p> <p>By enabling this toolset, HolmesGPT will be able to describe and find Kubernetes resources like nodes, deployments, pods, etc.</p>"},{"location":"data-sources/builtin-toolsets/kubernetes/#configuration","title":"Configuration","text":"<pre><code>holmes:\n    toolsets:\n        kubernetes/core:\n            enabled: true\n</code></pre>"},{"location":"data-sources/builtin-toolsets/kubernetes/#capabilities","title":"Capabilities","text":"Tool Name Description kubectl_describe Run kubectl describe command on a specific resource kubectl_get_by_name Get details of a specific resource with labels kubectl_get_by_kind_in_namespace List all resources of a given type in a namespace kubectl_get_by_kind_in_cluster List all resources of a given type across the cluster kubectl_find_resources Search for resources matching a keyword kubectl_get_yaml Get YAML definition of a resource kubectl_events Get events for a specific resource kubectl_memory_requests_all_namespaces Get memory requests for all pods across all namespaces in MiB kubectl_memory_requests_namespace Get memory requests for all pods in a specific namespace in MiB kubernetes_jq_query Query Kubernetes resources using jq filters"},{"location":"data-sources/builtin-toolsets/kubernetes/#logs","title":"Logs \u2713","text":"<p>Enabled by Default</p> <p>This toolset is enabled by default. You do not need to configure it.</p> <p>By enabling this toolset, HolmesGPT will be able to read Kubernetes pod logs.</p> Important: Disable Default Logging Toolset <p>Only one logging toolset should be enabled at a time. If you enable this toolset, disable the default <code>kubernetes/logs</code> toolset.</p> <p>Available Log Sources:</p> <ul> <li>Kubernetes logs - Direct pod log access (enabled by default)</li> <li>Loki - Centralized logs via Loki</li> <li>OpenSearch logs - Logs from OpenSearch/Elasticsearch</li> <li>Coralogix logs - Logs via Coralogix platform</li> <li>DataDog - Logs from DataDog</li> </ul> <p>\ud83d\udca1 Choose one: Only enable one logging toolset at a time for best performance.</p>"},{"location":"data-sources/builtin-toolsets/kubernetes/#configuration_1","title":"Configuration","text":"<pre><code>holmes:\n    toolsets:\n        kubernetes/logs:\n            enabled: true\n</code></pre>"},{"location":"data-sources/builtin-toolsets/kubernetes/#capabilities_1","title":"Capabilities","text":"Tool Name Description kubectl_logs Fetch logs from a specific pod kubectl_logs_all_containers Fetch logs from all containers in a pod kubectl_previous_logs Fetch previous logs from a pod kubectl_previous_logs_all_containers Fetch previous logs from all containers in a pod kubectl_container_logs Fetch logs from a specific container in a pod kubectl_logs_grep Search for specific patterns in pod logs kubectl_logs_all_containers_grep Search for patterns in logs from all containers"},{"location":"data-sources/builtin-toolsets/kubernetes/#live-metrics","title":"Live Metrics","text":"<p>This toolset retrieves real-time CPU and memory usage for pods and nodes.</p>"},{"location":"data-sources/builtin-toolsets/kubernetes/#configuration_2","title":"Configuration","text":"<pre><code>holmes:\n    toolsets:\n        kubernetes/live_metrics:\n            enabled: true\n</code></pre>"},{"location":"data-sources/builtin-toolsets/kubernetes/#capabilities_2","title":"Capabilities","text":"Tool Name Description kubectl_top_pods Get current CPU and memory usage for pods kubectl_top_nodes Get current CPU and memory usage for nodes"},{"location":"data-sources/builtin-toolsets/kubernetes/#prometheus-stack","title":"Prometheus Stack","text":"<p>This toolset fetches Prometheus target definitions. Requires specific cluster role rules.</p>"},{"location":"data-sources/builtin-toolsets/kubernetes/#configuration_3","title":"Configuration","text":"<pre><code>holmes:\n    toolsets:\n        kubernetes/prometheus_stack:\n            enabled: true\n    customClusterRoleRules:\n        - apiGroups: [\"monitoring.coreos.com\"]\n          resources: [\"servicemonitors\", \"podmonitors\", \"prometheusrules\"]\n          verbs: [\"get\", \"list\"]\n</code></pre>"},{"location":"data-sources/builtin-toolsets/kubernetes/#capabilities_3","title":"Capabilities","text":"Tool Name Description kubectl_get_prometheus_targets Get Prometheus monitoring targets kubectl_get_service_monitors Get ServiceMonitor resources kubectl_get_pod_monitors Get PodMonitor resources"},{"location":"data-sources/builtin-toolsets/kubernetes/#resource-lineage-extras","title":"Resource Lineage Extras","text":"<p>Two variations of resource lineage toolsets: one native and one using kubectl krew. Provides tools to fetch children/dependents and parents/dependencies of Kubernetes resources.</p>"},{"location":"data-sources/builtin-toolsets/kubernetes/#configuration_4","title":"Configuration","text":"<pre><code>holmes:\n    toolsets:\n        kubernetes/resource_lineage_extras:\n            enabled: true\n        # OR\n        kubernetes/resource_lineage_extras_krew:\n            enabled: true\n</code></pre>"},{"location":"data-sources/builtin-toolsets/kubernetes/#capabilities_4","title":"Capabilities","text":"Tool Name Description kubectl_lineage_children Get child/dependent resources of a Kubernetes resource kubectl_lineage_parents Get parent/dependency resources of a Kubernetes resource"},{"location":"data-sources/builtin-toolsets/mongodb-atlas/","title":"MongoDB Atlas","text":"<p>By enabling this toolset, HolmesGPT can access MongoDB Atlas projects and processes to analyze logs, alerts, events, slow queries, and various metrics to understand the state of MongoDB projects.</p> <p>Warning</p> <p>This toolset is in Experimental stage.</p>"},{"location":"data-sources/builtin-toolsets/mongodb-atlas/#prerequisites","title":"Prerequisites","text":"<ol> <li>MongoDB Atlas account</li> <li>MongoDB Atlas API keys (Public and Private)</li> <li>MongoDB Atlas project ID</li> <li>Appropriate MongoDB Atlas permissions</li> </ol>"},{"location":"data-sources/builtin-toolsets/mongodb-atlas/#configuration","title":"Configuration","text":"Holmes CLIRobusta Helm Chart <p>First, set the following environment variables:</p> <pre><code>export MONGODB_ATLAS_PUBLIC_KEY=\"&lt;your-public-api-key&gt;\"\nexport MONGODB_ATLAS_PRIVATE_KEY=\"&lt;your-private-api-key&gt;\"\nexport MONGODB_ATLAS_PROJECT_ID=\"&lt;your-project-id&gt;\"\n</code></pre> <p>Then add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n  MongoDBAtlas:\n    enabled: true\n    config:\n      public_key: \"&lt;your-public-api-key&gt;\"\n      private_key: \"&lt;your-private-api-key&gt;\"\n      project_id: \"&lt;your-project-id&gt;\"\n</code></pre> <p>After making changes to your configuration, run: <pre><code>holmes toolset refresh\n</code></pre></p> <pre><code>holmes:\n  additionalEnvVars:\n    - name: MONGODB_ATLAS_PUBLIC_KEY\n      value: \"&lt;your-public-api-key&gt;\"\n    - name: MONGODB_ATLAS_PRIVATE_KEY\n      value: \"&lt;your-private-api-key&gt;\"\n    - name: MONGODB_ATLAS_PROJECT_ID\n      value: \"&lt;your-project-id&gt;\"\n  toolsets:\n    MongoDBAtlas:\n      enabled: true\n      config:\n        public_key: \"&lt;your-public-api-key&gt;\"\n        private_key: \"&lt;your-private-api-key&gt;\"\n        project_id: \"&lt;your-project-id&gt;\"\n</code></pre>"},{"location":"data-sources/builtin-toolsets/mongodb-atlas/#setting-up-mongodb-atlas-api-keys","title":"Setting up MongoDB Atlas API Keys","text":"<ol> <li>Log into MongoDB Atlas and navigate to your organization</li> <li>Go to Access Manager \u2192 API Keys</li> <li>Create a new API key:</li> <li>Set appropriate permissions for your use case</li> <li>Copy the public key and private key</li> <li>Get your Project ID:</li> <li>Navigate to your project</li> <li>Copy the Project ID from the project settings</li> </ol>"},{"location":"data-sources/builtin-toolsets/mongodb-atlas/#required-permissions","title":"Required Permissions","text":"<p>The API key requires the following permissions:</p> <ul> <li>Project Read Only - To read project information</li> <li>Project Data Access Admin - To access database logs and metrics</li> <li>Project Monitoring Admin - To access monitoring data and alerts</li> </ul>"},{"location":"data-sources/builtin-toolsets/mongodb-atlas/#capabilities","title":"Capabilities","text":"Tool Name Description atlas_return_project_alerts Get alerts for the MongoDB Atlas project atlas_return_project_processes Get information about processes in the project atlas_return_project_slow_queries Get slow queries from the project (last 24 hours) atlas_return_events_from_project Get events from the project (last 24 hours) atlas_return_logs_for_host_in_project Get logs for a specific host in the project atlas_return_event_type_from_project Get events of a specific type from the project"},{"location":"data-sources/builtin-toolsets/mongodb-atlas/#usage-guidelines","title":"Usage Guidelines","text":""},{"location":"data-sources/builtin-toolsets/mongodb-atlas/#performance-analysis","title":"Performance Analysis","text":"<p>When investigating performance issues:</p> <ol> <li>Start with alerts and events: Use <code>atlas_return_project_alerts</code> and <code>atlas_return_events_from_project</code> first to identify known issues</li> <li>Check slow queries: Use <code>atlas_return_project_slow_queries</code> to identify performance bottlenecks</li> <li>Review logs: Use <code>atlas_return_logs_for_host_in_project</code> for detailed log analysis</li> </ol>"},{"location":"data-sources/builtin-toolsets/mongodb-atlas/#time-range-limitations","title":"Time Range Limitations","text":"<ul> <li><code>atlas_return_project_slow_queries</code> returns data from the last 24 hours only</li> <li><code>atlas_return_events_from_project</code> returns data from the last 24 hours only</li> <li>If you need data from a different time range, the toolset will inform you it's not currently supported</li> </ul>"},{"location":"data-sources/builtin-toolsets/mongodb-atlas/#query-analysis","title":"Query Analysis","text":"<ul> <li>When analyzing slow queries, the toolset will show the actual query text for every slow query</li> <li>For requests asking for a specific number of slow queries (e.g., \"top 10 slow queries\"), the toolset will not duplicate queries from different processes</li> </ul>"},{"location":"data-sources/builtin-toolsets/mongodb-atlas/#troubleshooting","title":"Troubleshooting","text":""},{"location":"data-sources/builtin-toolsets/mongodb-atlas/#common-issues","title":"Common Issues","text":"<ol> <li>Authentication Failures</li> <li>Verify your API keys are correct</li> <li>Check that the API key has appropriate permissions</li> <li> <p>Ensure the project ID is correct</p> </li> <li> <p>Permission Errors</p> </li> <li>Verify the API key has the required permissions listed above</li> <li> <p>Check that the key is associated with the correct organization</p> </li> <li> <p>No Data Returned</p> </li> <li>Verify the project ID is correct</li> <li>Check that there are active processes in the project</li> <li>Ensure the time range contains relevant data</li> </ol>"},{"location":"data-sources/builtin-toolsets/mongodb-atlas/#api-rate-limits","title":"API Rate Limits","text":"<p>MongoDB Atlas API has rate limits. If you encounter rate limiting:</p> <ul> <li>Wait before making additional requests</li> <li>Consider the frequency of your queries</li> <li>Check MongoDB Atlas documentation for current rate limits</li> </ul>"},{"location":"data-sources/builtin-toolsets/mongodb-atlas/#references","title":"References","text":"<ul> <li>MongoDB Atlas API Documentation</li> <li>MongoDB Atlas API Authentication</li> <li>MongoDB Atlas Monitoring</li> </ul>"},{"location":"data-sources/builtin-toolsets/newrelic/","title":"New Relic","text":"<p>By enabling this toolset, HolmesGPT will be able to pull traces and logs from New Relic for investigations.</p>"},{"location":"data-sources/builtin-toolsets/newrelic/#prerequisites","title":"Prerequisites","text":"<ol> <li>A New Relic API Key with necessary permissions to access traces and logs</li> <li>Your New Relic Account ID</li> </ol> <p>You can find these in your New Relic account under Administration &gt; API keys and Account settings.</p>"},{"location":"data-sources/builtin-toolsets/newrelic/#configuration","title":"Configuration","text":"Holmes CLIRobusta Helm Chart <p>Add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n  newrelic:\n    enabled: true\n    config:\n      nr_api_key: \"&lt;your New Relic API key&gt;\"\n      nr_account_id: \"&lt;your New Relic account ID&gt;\"\n      is_eu_datacenter: false  # Set to true if using New Relic EU region\n</code></pre> <p>After making changes to your configuration, run: <pre><code>holmes toolset refresh\n</code></pre></p> <pre><code>holmes:\n  toolsets:\n    newrelic:\n      enabled: true\n      config:\n        nr_api_key: \"&lt;your New Relic API key&gt;\"\n        nr_account_id: \"&lt;your New Relic account ID&gt;\"\n        is_eu_datacenter: false  # Set to true if using New Relic EU region\n</code></pre>"},{"location":"data-sources/builtin-toolsets/newrelic/#capabilities","title":"Capabilities","text":"Tool Name Description newrelic_execute_nrql_query Execute NRQL queries for Traces, APM, Spans, Logs and more"},{"location":"data-sources/builtin-toolsets/newrelic/#how-it-works","title":"How it Works","text":"<p>You don't need to know NRQL to use this toolset. Holmes will automatically construct and execute NRQL queries based on your investigation needs.</p> <p>For example, when investigating application logs, Holmes might execute a query like: <pre><code>SELECT message, timestamp FROM Log WHERE pod_name = 'your-app' SINCE 1 hour ago\n</code></pre></p> <p>To learn more about NRQL syntax, see the New Relic Query Language documentation.</p>"},{"location":"data-sources/builtin-toolsets/notion/","title":"Notion","text":"<p>Notion Integration for HolmesGPT</p> <p>Enabling this toolset allows HolmesGPT to fetch pages from Notion, making it useful when providing Notion-based runbooks.</p>"},{"location":"data-sources/builtin-toolsets/notion/#setup-instructions","title":"Setup Instructions","text":"<ol> <li> <p>Create a Webhook Integration</p> <ul> <li>Go to the Notion Developer Portal.</li> <li>Create a new integration with read content capabilities.</li> </ul> </li> <li> <p>Grant Access to Pages</p> <ul> <li>Open the desired Notion page.</li> <li>Click the three dots in the top right.</li> <li>Select Connections and add your integration.</li> </ul> </li> <li> <p>Configure Authentication</p> <ul> <li>Retrieve the Internal Integration Secret from Notion.</li> <li>Create a Kubernetes secret in your cluster with this key.</li> <li>Configure the <code>NOTION_AUTH</code> environment variable.</li> </ul> </li> </ol>"},{"location":"data-sources/builtin-toolsets/notion/#configuration","title":"Configuration","text":"Holmes CLIRobusta Helm Chart <p>First, set the environment variable: <pre><code>export NOTION_AUTH=\"&lt;your Notion integration secret&gt;\"\n</code></pre></p> <p>Then add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist: <pre><code>toolsets:\n    notion:\n        enabled: true\n</code></pre></p> <p>After making changes to your configuration, run: <pre><code>holmes toolset refresh\n</code></pre></p> <pre><code>holmes:\n    additionalEnvVars:\n        - name: NOTION_AUTH\n          value: \"&lt;your Notion integration secret&gt;\"\n    toolsets:\n        notion:\n            enabled: true\n            config:\n                additional_headers:\n                    Authorization: Bearer {{ env.NOTION_AUTH }}\n</code></pre> <p>Update your Helm values and run a Helm upgrade: <pre><code>helm upgrade robusta robusta/robusta --values=generated_values.yaml --set clusterName=&lt;YOUR_CLUSTER_NAME&gt;\n</code></pre></p>"},{"location":"data-sources/builtin-toolsets/notion/#capabilities","title":"Capabilities","text":"<p>The table below describes the specific capabilities provided by this toolset. HolmesGPT can decide to invoke any of these capabilities when answering questions or investigating issues.</p> Tool Name Description fetch_notion_webpage Fetch a Notion webpage. Use this to fetch Notion runbooks if they are present before starting your investigation"},{"location":"data-sources/builtin-toolsets/opensearch-logs/","title":"OpenSearch Logs","text":"<p>By enabling this toolset, HolmesGPT will fetch pod logs from OpenSearch.</p> Important: Disable Default Logging Toolset <p>Only one logging toolset should be enabled at a time. If you enable this toolset, disable the default <code>kubernetes/logs</code> toolset.</p> <p>Available Log Sources:</p> <ul> <li>Kubernetes logs - Direct pod log access (enabled by default)</li> <li>Loki - Centralized logs via Loki</li> <li>OpenSearch logs - Logs from OpenSearch/Elasticsearch</li> <li>Coralogix logs - Logs via Coralogix platform</li> <li>DataDog - Logs from DataDog</li> </ul> <p>\ud83d\udca1 Choose one: Only enable one logging toolset at a time for best performance.</p>"},{"location":"data-sources/builtin-toolsets/opensearch-logs/#configuration","title":"Configuration","text":"Holmes CLIRobusta Helm Chart <p>Add the following to ~/.holmes/config.yaml, creating the file if it doesn't exist:</p> <pre><code>toolsets:\n  opensearch/logs:\n    enabled: true\n    config:\n      opensearch_url: &lt;your opensearch/elastic URL&gt;\n      index_pattern: &lt;name of the index to use&gt; # The pattern matching the indexes containing the logs. Supports wildcards. For example `fluentd-*`\n      opensearch_auth_header: \"ApiKey &lt;...&gt;\" # An optional header value set to the `Authorization` header for every request to opensearch\n      labels: # set the labels according to how values are mapped in your opensearch cluster\n        pod: \"kubernetes.pod_name\"\n        namespace: \"kubernetes.namespace_name\"\n        timestamp: \"@timestamp\"\n        message: \"message\"\n\n  kubernetes/logs:\n    enabled: false # HolmesGPT's default logging mechanism MUST be disabled\n</code></pre> <p>After making changes to your configuration, run: <pre><code>holmes toolset refresh\n</code></pre></p> <pre><code>holmes:\n  toolsets:\n    opensearch/logs:\n      enabled: true\n      config:\n        opensearch_url: https://skdjasid.europe-west1.gcp.cloud.es.io:443 # The URL to your opensearch cluster.\n        index_pattern: fluentd-* # The pattern matching the indexes containing the logs. Supports wildcards\n        opensearch_auth_header: \"ApiKey b0ZlwQWEsdwAkv047bafirkallDFWJIWDWdwlQQ==\" # An optional header value set to the `Authorization` header for every request to opensearch.\n        labels: # set the labels according to how values are mapped in your opensearch cluster\n          pod: \"kubernetes.pod_name\"\n          namespace: \"kubernetes.namespace_name\"\n          timestamp: \"@timestamp\"\n          message: \"message\"\n\n    kubernetes/logs:\n      enabled: false # HolmesGPT's default logging mechanism MUST be disabled\n</code></pre> <p>Update your Helm values and run a Helm upgrade: <pre><code>helm upgrade robusta robusta/robusta --values=generated_values.yaml --set clusterName=&lt;YOUR_CLUSTER_NAME&gt;\n</code></pre></p>"},{"location":"data-sources/builtin-toolsets/opensearch-logs/#configuring-index_pattern-and-labels","title":"Configuring index_pattern and labels","text":"<p>You can tweak the labels used by the toolset to identify kubernetes resources. This is optional and only needed if your logs settings differ from the defaults in the example below.</p> <pre><code>toolsets:\n  opensearch/logs:\n    enabled: true\n    config:\n      index_pattern: fluentd-*\n      labels:\n        pod: \"kubernetes.pod_name\"\n        namespace: \"kubernetes.namespace_name\"\n        timestamp: \"@timestamp\"\n        message: \"message\"\n</code></pre> <p>Below is a screenshot of a query that was done using Elastic dev tools to find out what should be the values for the labels.</p> <p></p> <p>In the image above, the following values and labels are identified by a yellow rectangle:</p> Configuration field Value Description index_pattern fluentd-* This defines what opensearch indexes should be used to fetch logs pod kubernetes.pod_name The kubernetes pod name namespace kubernetes.namespace_name The kubernetes namespace timestamp @timestamp This timestamp is used to search logs by time range. message message This is the content of the log message"},{"location":"data-sources/builtin-toolsets/opensearch-logs/#capabilities","title":"Capabilities","text":"Tool Name Description fetch_pod_logs Retrieve logs using opensearch"},{"location":"data-sources/builtin-toolsets/opensearch-status/","title":"OpenSearch status","text":"<p>By enabling this toolset, HolmesGPT will be able to access cluster metadata information like health, shards, and settings. This allows HolmesGPT to better troubleshoot problems with one or more OpenSearch clusters.</p>"},{"location":"data-sources/builtin-toolsets/opensearch-status/#configuration","title":"Configuration","text":"<p>The configuration for OpenSearch is passed through to the underlying opensearch-py library. Consult this library's user guide or reference documentation for configuring the connection to OpenSearch, including how to authenticate this toolset to an OpenSearch cluster.</p> <p> Holmes CLI Holmes Helm Chart Robusta Helm Chart <p>Add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n    opensearch/status:\n        enabled: true\n        config:\n            opensearch_clusters:\n                - hosts:\n                    - host1.com\n                    - host2.com\n                  headers:\n                    header1: \"value1\"\n                  use_ssl: &lt;boolean&gt;\n                  ssl_assert_hostname: &lt;boolean&gt;\n                  verify_certs: &lt;boolean&gt;\n                  ssl_show_warn: &lt;boolean&gt;\n                  http_auth:\n                    username: &lt;basic auth username&gt;\n                    password: &lt;basic auth password&gt;</code></pre> <p>When using the standalone Holmes Helm Chart, update your <code>values.yaml</code>:</p> <pre><code>toolsets:\n    opensearch/status:\n        enabled: true\n        config:\n            opensearch_clusters:\n                - hosts:\n                    - host1.com\n                    - host2.com\n                  headers:\n                    header1: \"value1\"\n                  use_ssl: &lt;boolean&gt;\n                  ssl_assert_hostname: &lt;boolean&gt;\n                  verify_certs: &lt;boolean&gt;\n                  ssl_show_warn: &lt;boolean&gt;\n                  http_auth:\n                    username: &lt;basic auth username&gt;\n                    password: &lt;basic auth password&gt;</code></pre> <p>Apply the configuration:</p> <pre><code>helm upgrade holmes holmes/holmes --values=values.yaml</code></pre> <p>When using the Robusta Helm Chart (which includes HolmesGPT), update your <code>generated_values.yaml</code>:</p> <pre><code>holmes:\n  toolsets:\n      opensearch/status:\n          enabled: true\n          config:\n              opensearch_clusters:\n                  - hosts:\n                      - host1.com\n                      - host2.com\n                    headers:\n                      header1: \"value1\"\n                    use_ssl: &lt;boolean&gt;\n                    ssl_assert_hostname: &lt;boolean&gt;\n                    verify_certs: &lt;boolean&gt;\n                    ssl_show_warn: &lt;boolean&gt;\n                    http_auth:\n                      username: &lt;basic auth username&gt;\n                      password: &lt;basic auth password&gt;</code></pre> <p>Apply the configuration:</p> <pre><code>helm upgrade robusta robusta/robusta --values=generated_values.yaml --set clusterName=&lt;YOUR_CLUSTER_NAME&gt;</code></pre> </p> <p>Here is an example of an insecure OpenSearch configuration for local development using a bearer token:</p> Holmes CLIRobusta Helm Chart <p>First, set the environment variables: <pre><code>export OPENSEARCH_URL=\"&lt;opensearch host URL&gt;\"\nexport OPENSEARCH_BEARER_TOKEN=\"&lt;secret bearer token&gt;\"\n</code></pre></p> <p>Then add the following to ~/.holmes/config.yaml: <pre><code>toolsets:\n    opensearch/status:\n        enabled: true\n        config:\n            opensearch_clusters:\n                - hosts:\n                    - host: \"{{ env.OPENSEARCH_URL }}\"\n                      port: 9200\n</code></pre></p> <p>After making changes to your configuration, run: <pre><code>holmes toolset refresh\n</code></pre></p> <pre><code>holmes:\n    additionalEnvVars:\n        - name: OPENSEARCH_URL\n          value: \"&lt;opensearch host URL&gt;\"\n        - name: OPENSEARCH_BEARER_TOKEN\n          value: \"&lt;secret bearer token&gt;\"\n    toolsets:\n        opensearch/status:\n            enabled: true\n            config:\n                opensearch_clusters:\n                    - hosts:\n                        - host: \"{{ env.OPENSEARCH_URL }}\"\n                          port: 9200\n</code></pre>"},{"location":"data-sources/builtin-toolsets/opensearch-status/#capabilities","title":"Capabilities","text":"<p>The table below describes the specific capabilities provided by this toolset. HolmesGPT can decide to invoke any of these capabilities when answering questions or investigating issues.</p> Tool Name Description opensearch_cluster_health Get cluster health information opensearch_cluster_stats Get cluster statistics opensearch_node_info Get information about cluster nodes opensearch_index_stats Get statistics for specific indices opensearch_shard_allocation Get shard allocation information"},{"location":"data-sources/builtin-toolsets/prometheus/","title":"Prometheus","text":"<p>Connect HolmesGPT to Prometheus for metrics analysis and query generation. This integration enables detection of memory leaks, CPU throttling, queue backlogs, and performance issues.</p>"},{"location":"data-sources/builtin-toolsets/prometheus/#prerequisites","title":"Prerequisites","text":"<ul> <li>A running and accessible Prometheus server</li> <li>Ensure HolmesGPT can connect to the Prometheus endpoint</li> </ul>"},{"location":"data-sources/builtin-toolsets/prometheus/#configuration","title":"Configuration","text":"<p> Holmes CLI Holmes Helm Chart Robusta Helm Chart <p>Add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n    prometheus/metrics:\n        enabled: true\n        config:\n            prometheus_url: http://&lt;your-prometheus-service&gt;:9090\n\n            # Optional:\n            #headers:\n            #    Authorization: \"Basic &lt;base_64_encoded_string&gt;\"</code></pre> <p>When using the standalone Holmes Helm Chart, update your <code>values.yaml</code>:</p> <pre><code>toolsets:\n    prometheus/metrics:\n        enabled: true\n        config:\n            prometheus_url: http://&lt;your-prometheus-service&gt;:9090\n\n            # Optional:\n            #headers:\n            #    Authorization: \"Basic &lt;base_64_encoded_string&gt;\"</code></pre> <p>Apply the configuration:</p> <pre><code>helm upgrade holmes holmes/holmes --values=values.yaml</code></pre> <p>When using the Robusta Helm Chart (which includes HolmesGPT), update your <code>generated_values.yaml</code>:</p> <pre><code>holmes:\n  toolsets:\n      prometheus/metrics:\n          enabled: true\n          config:\n              prometheus_url: http://&lt;your-prometheus-service&gt;:9090\n\n              # Optional:\n              #headers:\n              #    Authorization: \"Basic &lt;base_64_encoded_string&gt;\"</code></pre> <p>Apply the configuration:</p> <pre><code>helm upgrade robusta robusta/robusta --values=generated_values.yaml --set clusterName=&lt;YOUR_CLUSTER_NAME&gt;</code></pre> </p> <p>\ud83d\udca1 Alternative: Set environment variables instead of using the config file: - <code>PROMETHEUS_URL</code>: The Prometheus server URL - <code>PROMETHEUS_AUTH_HEADER</code>: Optional authorization header value (e.g., \"Bearer token123\")</p>"},{"location":"data-sources/builtin-toolsets/prometheus/#validation","title":"Validation","text":"<p>To test your connection, run:</p> <pre><code>holmes ask \"Show me the CPU usage for the last hour\"\n</code></pre>"},{"location":"data-sources/builtin-toolsets/prometheus/#troubleshooting","title":"Troubleshooting","text":""},{"location":"data-sources/builtin-toolsets/prometheus/#finding-your-prometheus-url","title":"Finding your Prometheus URL","text":"<p>There are several ways to find your Prometheus URL:</p> <p>Option 1: Simple method (port-forwarding)</p> <pre><code># Find Prometheus services\nkubectl get svc -A | grep prometheus\n\n# Port forward for testing\nkubectl port-forward svc/&lt;your-prometheus-service&gt; 9090:9090 -n &lt;namespace&gt;\n# Then access Prometheus at: http://localhost:9090\n</code></pre> <p>Option 2: Advanced method (get full cluster DNS URL)</p> <p>If you want to find the full internal DNS URL for Prometheus, run:</p> <pre><code>kubectl get svc --all-namespaces -o jsonpath='{range .items[*]}{.metadata.name}{\".\"}{.metadata.namespace}{\".svc.cluster.local:\"}{.spec.ports[0].port}{\"\\n\"}{end}' | grep prometheus | grep -Ev 'operat|alertmanager|node|coredns|kubelet|kube-scheduler|etcd|controller' | awk '{print \"http://\"$1}'\n</code></pre> <p>This will print all possible Prometheus service URLs in your cluster. Pick the one that matches your deployment.</p>"},{"location":"data-sources/builtin-toolsets/prometheus/#common-issues","title":"Common Issues","text":"<ul> <li>Connection refused: Check if the Prometheus URL is accessible from HolmesGPT.</li> <li>Authentication errors: Verify the headers configuration for secured Prometheus endpoints.</li> <li>No metrics returned: Ensure that Prometheus is scraping your targets.</li> </ul>"},{"location":"data-sources/builtin-toolsets/prometheus/#advanced-configuration","title":"Advanced Configuration","text":"<p>You can further customize the Prometheus toolset with the following options:</p> <pre><code>toolsets:\n  prometheus/metrics:\n    enabled: true\n    config:\n      prometheus_url: http://&lt;prometheus-host&gt;:9090\n      healthcheck: \"-/healthy\"  # Path for health checking (default: -/healthy)\n      headers:\n        Authorization: \"Basic &lt;base_64_encoded_string&gt;\"\n\n      # Time windows and limits\n      default_metadata_time_window_hrs: 1  # Time window for metadata APIs (default: 1 hour)\n      query_response_size_limit: 20000  # Max characters in query response (default: 20000)\n\n      # Timeout configuration\n      default_query_timeout_seconds: 20  # Default timeout for PromQL queries (default: 20)\n      max_query_timeout_seconds: 180  # Maximum allowed timeout for PromQL queries (default: 180)\n      default_metadata_timeout_seconds: 20  # Default timeout for metadata/discovery APIs (default: 20)\n      max_metadata_timeout_seconds: 60  # Maximum allowed timeout for metadata APIs (default: 60)\n\n      # Other options\n      rules_cache_duration_seconds: 1800  # Cache duration for Prometheus rules (default: 30 minutes)\n      prometheus_ssl_enabled: true  # Enable SSL verification (default: true)\n      tool_calls_return_data: true  # If false, disables returning Prometheus data (default: true)\n      additional_labels:  # Additional labels to add to all queries\n        cluster: \"production\"\n</code></pre> <p>Config option explanations:</p> <ul> <li><code>prometheus_url</code>: The base URL for Prometheus. Should include protocol and port.</li> <li><code>healthcheck</code>: Path used for health checking Prometheus or Mimir/Cortex endpoint. Defaults to <code>-/healthy</code> for Prometheus, use <code>/ready</code> for Grafana Mimir.</li> <li><code>headers</code>: Extra headers for all Prometheus HTTP requests (e.g., for authentication).</li> <li><code>default_metadata_time_window_hrs</code>: Time window (in hours) for metadata/discovery APIs to look for active metrics. Default: 1 hour.</li> <li><code>query_response_size_limit</code>: Maximum number of characters in a query response before truncation. Set to <code>null</code> to disable. Default: 20000.</li> <li><code>default_query_timeout_seconds</code>: Default timeout for PromQL queries. Can be overridden per query. Default: 20.</li> <li><code>max_query_timeout_seconds</code>: Maximum allowed timeout for PromQL queries. Default: 180.</li> <li><code>default_metadata_timeout_seconds</code>: Default timeout for metadata/discovery API calls. Default: 20.</li> <li><code>max_metadata_timeout_seconds</code>: Maximum allowed timeout for metadata API calls. Default: 60.</li> <li><code>rules_cache_duration_seconds</code>: How long to cache Prometheus rules. Set to <code>null</code> to disable caching. Default: 1800 (30 minutes).</li> <li><code>prometheus_ssl_enabled</code>: Enable SSL certificate verification. Default: true.</li> <li><code>tool_calls_return_data</code>: If <code>false</code>, disables returning Prometheus data to HolmesGPT (useful if you hit token limits). Default: true.</li> <li><code>additional_labels</code>: Dictionary of labels to add to all queries (currently only implemented for AWS/AMP).</li> </ul>"},{"location":"data-sources/builtin-toolsets/prometheus/#capabilities","title":"Capabilities","text":"Tool Name Description list_prometheus_rules List all defined Prometheus rules with descriptions and annotations get_metric_names Get list of metric names (fastest discovery method) - requires match filter get_label_values Get all values for a specific label (e.g., pod names, namespaces) get_all_labels Get list of all label names available in Prometheus get_series Get time series matching a selector (returns full label sets) get_metric_metadata Get metadata (type, description, unit) for metrics execute_prometheus_instant_query Execute an instant PromQL query (single point in time) execute_prometheus_range_query Execute a range PromQL query for time series data with graph generation"},{"location":"data-sources/builtin-toolsets/prometheus/#coralogix-prometheus-configuration","title":"Coralogix Prometheus Configuration","text":"<p>To use a Coralogix PromQL endpoint with HolmesGPT:</p> <ol> <li>Go to Coralogix Documentation and choose the relevant PromQL endpoint for your region.</li> <li>In Coralogix, create an API key with permissions to query metrics (Data Flow \u2192 API Keys).</li> <li> <p>Create a Kubernetes secret for the API key and expose it as an environment variable in your Helm values:</p> <pre><code>holmes:\n  additionalEnvVars:\n    - name: CORALOGIX_API_KEY\n      valueFrom:\n        secretKeyRef:\n          name: coralogix-api-key\n          key: CORALOGIX_API_KEY\n</code></pre> </li> <li> <p>Add the following under your toolsets in the Helm chart:</p> <pre><code>holmes:\n  toolsets:\n    prometheus/metrics:\n      enabled: true\n      config:\n        healthcheck: \"/api/v1/query?query=up\"  # This is important for Coralogix\n        prometheus_url: \"https://prom-api.eu2.coralogix.com\"  # Use your region's endpoint\n        headers:\n          token: \"{{ env.CORALOGIX_API_KEY }}\"\n        default_metadata_time_window_hrs: 72  # Look back 72 hours for metrics\n        tool_calls_return_data: true\n</code></pre> </li> </ol>"},{"location":"data-sources/builtin-toolsets/prometheus/#aws-managed-prometheus-amp-configuration","title":"AWS Managed Prometheus (AMP) Configuration","text":"<p>To connect HolmesGPT to AWS Managed Prometheus:</p> <pre><code>holmes:\n  toolsets:\n    prometheus/metrics:\n      enabled: true\n      config:\n        prometheus_url: https://aps-workspaces.us-east-1.amazonaws.com/workspaces/ws-xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx/\n        aws_region: us-east-1\n        aws_service_name: aps  # Default value, can be omitted\n        # Optional: Specify credentials (otherwise uses default AWS credential chain)\n        aws_access_key: \"{{ env.AWS_ACCESS_KEY_ID }}\"\n        aws_secret_access_key: \"{{ env.AWS_SECRET_ACCESS_KEY }}\"\n        # Optional: Assume a role for cross-account access\n        assume_role_arn: \"arn:aws:iam::123456789012:role/PrometheusReadRole\"\n        refresh_interval_seconds: 900  # Refresh AWS credentials every 15 minutes (default)\n</code></pre> <p>Notes: - The toolset automatically detects AWS configuration when <code>aws_region</code> is present - Uses SigV4 authentication for all requests - Supports IAM roles and cross-account access via <code>assume_role_arn</code> - Credentials refresh automatically based on <code>refresh_interval_seconds</code></p>"},{"location":"data-sources/builtin-toolsets/prometheus/#grafana-cloud-mimir-configuration","title":"Grafana Cloud (Mimir) Configuration","text":"<p>To connect HolmesGPT to Grafana Cloud's Prometheus/Mimir endpoint:</p> <ol> <li>Create a service account token in Grafana Cloud:</li> <li>Navigate to \"Administration \u2192 Service accounts\"</li> <li>Create a new service account</li> <li> <p>Generate a service account token (starts with <code>glsa_</code>)</p> </li> <li> <p>Find your Prometheus datasource UID: <pre><code>curl -H \"Authorization: Bearer YOUR_GLSA_TOKEN\" \\\n     \"https://YOUR-INSTANCE.grafana.net/api/datasources\" | \\\n     jq '.[] | select(.type==\"prometheus\") | {name, uid}'\n</code></pre></p> </li> <li> <p>Configure HolmesGPT: <pre><code>holmes:\n  toolsets:\n    prometheus/metrics:\n      enabled: true\n      config:\n        prometheus_url: https://YOUR-INSTANCE.grafana.net/api/datasources/proxy/uid/PROMETHEUS_DATASOURCE_UID\n        headers:\n          Authorization: Bearer YOUR_GLSA_TOKEN\n</code></pre></p> </li> </ol> <p>Important notes:</p> <ul> <li>Use the proxy endpoint URL format <code>/api/datasources/proxy/uid/</code> - this handles authentication and routing to Mimir automatically</li> <li>The toolset automatically detects and uses the most appropriate APIs for discovery</li> </ul>"},{"location":"data-sources/builtin-toolsets/rabbitmq/","title":"RabbitMQ","text":"<p>By enabling this toolset, HolmesGPT will be able to detect RabbitMQ partitions, memory alerts, and disk alerts and suggest mitigations.</p> <p>This toolset follows a two-step process to detect partition:</p> <ol> <li>The nodes and partitioning status is obtained by fetching information from the configured <code>management_url</code>.</li> <li>If some nodes are reported as not-running, the toolset will try to contact these nodes individually and deduce any partitioning state for any node that is actually running.</li> </ol>"},{"location":"data-sources/builtin-toolsets/rabbitmq/#configuration","title":"Configuration","text":"<p> Holmes CLI Holmes Helm Chart Robusta Helm Chart <p>Add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n  rabbitmq/core:\n    enabled: true\n    config:\n      clusters:\n        - id: rabbitmq # must be unique across all configured clusters\n          username: &lt;user&gt;\n          password: &lt;password&gt;\n          management_url: &lt;http://rabbitmq.rabbitmq:15672&gt;</code></pre> <p>When using the standalone Holmes Helm Chart, update your <code>values.yaml</code>:</p> <pre><code>toolsets:\n  rabbitmq/core:\n    enabled: true\n    config:\n      clusters:\n        - id: rabbitmq # must be unique across all configured clusters\n          username: &lt;user&gt;\n          password: &lt;password&gt;\n          management_url: &lt;http://rabbitmq.rabbitmq:15672&gt;</code></pre> <p>Apply the configuration:</p> <pre><code>helm upgrade holmes holmes/holmes --values=values.yaml</code></pre> <p>When using the Robusta Helm Chart (which includes HolmesGPT), update your <code>generated_values.yaml</code>:</p> <pre><code>holmes:\n  toolsets:\n    rabbitmq/core:\n      enabled: true\n      config:\n        clusters:\n          - id: rabbitmq # must be unique across all configured clusters\n            username: &lt;user&gt;\n            password: &lt;password&gt;\n            management_url: &lt;http://rabbitmq.rabbitmq:15672&gt;</code></pre> <p>Apply the configuration:</p> <pre><code>helm upgrade robusta robusta/robusta --values=generated_values.yaml --set clusterName=&lt;YOUR_CLUSTER_NAME&gt;</code></pre> </p>"},{"location":"data-sources/builtin-toolsets/rabbitmq/#advanced-configuration","title":"Advanced configuration","text":"<p>Below is the full list of options for this toolset:</p> <pre><code>rabbitmq/core:\n  enabled: true\n  config:\n    clusters:\n      - id: rabbitmq # must be unique across all configured clusters\n        username: &lt;user&gt;\n        password: &lt;password&gt;\n        management_url: &lt;http://rabbitmq.rabbitmq:15672&gt;\n        request_timeout_seconds: 30 # timeout for HTTP requests\n</code></pre>"},{"location":"data-sources/builtin-toolsets/rabbitmq/#capabilities","title":"Capabilities","text":"Tool Name Description get_rabbitmq_cluster_status Get cluster status and partition information get_rabbitmq_node_info Get detailed information about RabbitMQ nodes get_rabbitmq_queue_info Get information about queues get_rabbitmq_exchange_info Get information about exchanges get_rabbitmq_memory_usage Get memory usage statistics get_rabbitmq_disk_usage Get disk usage statistics"},{"location":"data-sources/builtin-toolsets/robusta/","title":"Robusta","text":"<p>Optional - Requires Robusta SaaS</p> <p>This toolset is NOT enabled by default. It requires integration with the Robusta SaaS platform and proper authentication credentials.</p> <p>The Robusta toolset provides advanced observability capabilities by connecting HolmesGPT to the Robusta SaaS platform. When enabled, it gives HolmesGPT access to historical data, change tracking, and resource recommendations that are not available from standard Kubernetes APIs.</p>"},{"location":"data-sources/builtin-toolsets/robusta/#prerequisites","title":"Prerequisites","text":"<p>To use this toolset, you need:</p> <ol> <li>An active Robusta SaaS account</li> <li>Valid authentication credentials (provided via environment variables or configuration file)</li> <li>The Robusta platform deployed in your cluster</li> </ol>"},{"location":"data-sources/builtin-toolsets/robusta/#what-it-adds","title":"What It Adds","text":"<p>When connected to Robusta SaaS, HolmesGPT gains access to:</p> <ul> <li>Historical Alert Data: Fetch detailed metadata about past alerts and incidents, including context that may no longer be available in Prometheus or AlertManager</li> <li>Change Tracking: Query configuration changes across your entire cluster within specific time ranges, helping identify what changed before an incident</li> <li>Resource Recommendations: Get AI-powered recommendations for resource requests and limits based on actual historical usage patterns</li> </ul>"},{"location":"data-sources/builtin-toolsets/robusta/#configuration","title":"Configuration","text":"<p>The toolset requires authentication to Robusta SaaS. You can provide credentials in three ways:</p>"},{"location":"data-sources/builtin-toolsets/robusta/#option-1-automatic-via-robusta-helm-chart","title":"Option 1: Automatic (via Robusta Helm Chart)","text":"<p>If you deploy HolmesGPT as part of the Robusta Helm chart, credentials are automatically configured. The Helm chart handles mounting the necessary secrets and configuration files.</p>"},{"location":"data-sources/builtin-toolsets/robusta/#option-2-environment-variables","title":"Option 2: Environment Variables","text":"<pre><code>export ROBUSTA_UI_TOKEN=\"&lt;base64-encoded-token&gt;\"\n# OR provide individual credentials:\nexport ROBUSTA_ACCOUNT_ID=\"&lt;account-id&gt;\"\nexport STORE_URL=\"&lt;store-url&gt;\"\nexport STORE_API_KEY=\"&lt;api-key&gt;\"\nexport STORE_EMAIL=\"&lt;email&gt;\"\nexport STORE_PASSWORD=\"&lt;password&gt;\"\n</code></pre>"},{"location":"data-sources/builtin-toolsets/robusta/#option-3-configuration-file","title":"Option 3: Configuration File","text":"<p>The toolset will automatically look for credentials in <code>/etc/robusta/config/active_playbooks.yaml</code> (or the path specified by <code>ROBUSTA_CONFIG_PATH</code>).</p>"},{"location":"data-sources/builtin-toolsets/robusta/#enabling-the-toolset","title":"Enabling the Toolset","text":"<pre><code>holmes:\n    toolsets:\n        robusta:\n            enabled: true\n</code></pre>"},{"location":"data-sources/builtin-toolsets/robusta/#capabilities","title":"Capabilities","text":"Tool Name Description fetch_finding_by_id Fetches detailed metadata about a specific Robusta finding (alerts, deployment updates, etc.) including historical context fetch_configuration_changes_metadata Retrieves all configuration changes in a given time range, optionally filtered by namespace or workload fetch_resource_recommendation Provides resource optimization recommendations based on actual historical usage for Deployments, StatefulSets, DaemonSets, and Jobs"},{"location":"data-sources/builtin-toolsets/robusta/#use-cases","title":"Use Cases","text":"<p>This toolset is particularly useful for:</p> <ul> <li>Root Cause Analysis: Understanding what configuration changes occurred before an incident</li> <li>Resource Optimization: Getting data-driven recommendations for right-sizing workloads</li> <li>Historical Investigation: Accessing alert context and metadata that may have been lost or expired in other systems</li> <li>Change Management: Tracking who changed what and when across your infrastructure</li> </ul>"},{"location":"data-sources/builtin-toolsets/robusta/#notes","title":"Notes","text":"<ul> <li>The toolset will only be functional if valid Robusta SaaS credentials are provided</li> <li>If credentials are missing or invalid, the toolset will be disabled automatically</li> <li>This integration provides read-only access to your Robusta data</li> </ul>"},{"location":"data-sources/builtin-toolsets/servicenow/","title":"ServiceNow","text":"<p>By enabling this toolset, HolmesGPT will be able to interact with ServiceNow for ticket management, incident tracking, and accessing knowledge base articles during investigations.</p> <p>Warning</p> <p>This toolset is in Experimental stage.</p>"},{"location":"data-sources/builtin-toolsets/servicenow/#prerequisites","title":"Prerequisites","text":"<ol> <li>ServiceNow instance URL</li> <li>ServiceNow API key or username and password</li> <li>Appropriate ServiceNow roles and permissions</li> </ol>"},{"location":"data-sources/builtin-toolsets/servicenow/#setting-up-servicenow-api-access","title":"Setting up ServiceNow API Access","text":"<p>Full configuration guide</p>"},{"location":"data-sources/builtin-toolsets/servicenow/#create-an-inbound-authentication-profile","title":"Create an inbound authentication profile","text":"<ol> <li>Navigate to All &gt; System Web Services &gt; API Access Policies &gt; Inbound Authentication Profiles</li> <li>Select New</li> <li>Select Create API Key authentication profiles</li> <li>Auth Parameter &gt; add x-sn-apikey: Auth Header</li> <li>Submit the form</li> </ol>"},{"location":"data-sources/builtin-toolsets/servicenow/#create-a-rest-api-key","title":"Create a REST API key","text":"<ol> <li>Navigate to All &gt; System Web Services &gt; API Access Policies &gt; REST API Key</li> <li>Select New</li> <li>Set name, description, and user. Set expiry date if desired. &gt; Submit</li> <li>Open the record that was created to view the token generated by the ServiceNow AI Platform for the user</li> </ol>"},{"location":"data-sources/builtin-toolsets/servicenow/#create-a-rest-api-access-policy","title":"Create a REST API Access policy","text":"<ol> <li>Navigate to All &gt; System Web Services &gt; REST API Access Policies</li> <li>Select New</li> <li>REST API = Table API</li> <li>Uncheck Apply to all tables &gt; Select table &gt; change_request</li> <li>In select profile from step 1 (API Key)</li> </ol>"},{"location":"data-sources/builtin-toolsets/servicenow/#configuration","title":"Configuration","text":"Holmes CLIRobusta Helm Chart"},{"location":"data-sources/builtin-toolsets/servicenow/#api-key-authentication-recommended","title":"API Key Authentication (Recommended)","text":"<p>First, set the following environment variables:</p> <pre><code>export SERVICENOW_INSTANCE=\"&lt;your servicenow instance name&gt;\"  # e.g., \"dev12345\"\nexport SERVICENOW_API_KEY=\"&lt;your servicenow api key&gt;\"\n</code></pre> <p>Then add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n  servicenow/tickets:\n    enabled: true\n    config:\n      api_key: \"&lt;your servicenow api key&gt;\"\n      instance: \"&lt;your servicenow instance name&gt;\"\n      verify_ssl: true\n      timeout: 30\n</code></pre> <p>After making changes to your configuration, run: <pre><code>holmes toolset refresh\n</code></pre></p>"},{"location":"data-sources/builtin-toolsets/servicenow/#usernamepassword-authentication","title":"Username/Password Authentication","text":"<p>First, set the following environment variables:</p> <pre><code>export SERVICENOW_INSTANCE=\"&lt;your servicenow instance url&gt;\"\nexport SERVICENOW_USERNAME=\"&lt;your servicenow username&gt;\"\nexport SERVICENOW_PASSWORD=\"&lt;your servicenow password&gt;\"\n</code></pre> <p>Then add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n  servicenow/tickets:\n    enabled: true\n    config:\n      verify_ssl: true\n      timeout: 30\n</code></pre> <p>After making changes to your configuration, run: <pre><code>holmes toolset refresh\n</code></pre></p>"},{"location":"data-sources/builtin-toolsets/servicenow/#api-key-authentication-recommended_1","title":"API Key Authentication (Recommended)","text":"<pre><code>holmes:\n  additionalEnvVars:\n    - name: SERVICENOW_INSTANCE\n      value: \"&lt;your servicenow instance name&gt;\"\n    - name: SERVICENOW_API_KEY\n      value: \"&lt;your servicenow api key&gt;\"\n  toolsets:\n    servicenow/tickets:\n      enabled: true\n      config:\n        api_key: \"&lt;your servicenow api key&gt;\"\n        instance: \"&lt;your servicenow instance name&gt;\"\n        verify_ssl: true\n        timeout: 30\n</code></pre>"},{"location":"data-sources/builtin-toolsets/servicenow/#usernamepassword-authentication_1","title":"Username/Password Authentication","text":"<pre><code>holmes:\n  additionalEnvVars:\n    - name: SERVICENOW_INSTANCE\n      value: \"&lt;your servicenow instance url&gt;\"\n    - name: SERVICENOW_USERNAME\n      value: \"&lt;your servicenow username&gt;\"\n    - name: SERVICENOW_PASSWORD\n      value: \"&lt;your servicenow password&gt;\"\n  toolsets:\n    servicenow/tickets:\n      enabled: true\n      config:\n        verify_ssl: true\n        timeout: 30\n</code></pre>"},{"location":"data-sources/builtin-toolsets/servicenow/#advanced-configuration","title":"Advanced Configuration","text":"<p>You can customize ServiceNow integration settings:</p> <pre><code>toolsets:\n  servicenow/tickets:\n    enabled: true\n    config:\n      verify_ssl: true\n      timeout: 30  # Request timeout in seconds\n      max_results: 100  # Maximum number of tickets to fetch\n      default_table: \"incident\"  # Default ServiceNow table to query\n</code></pre>"},{"location":"data-sources/builtin-toolsets/servicenow/#capabilities","title":"Capabilities","text":"Tool Name Description servicenow_create_incident Create a new incident ticket in ServiceNow servicenow_get_incident Get details of a specific incident servicenow_search_incidents Search for incidents based on criteria servicenow_update_incident Update an existing incident servicenow_get_knowledge_base Search ServiceNow knowledge base articles servicenow_create_change_request Create a change request ticket"},{"location":"data-sources/builtin-toolsets/slab/","title":"Slab","text":"<p>By enabling this toolset, HolmesGPT will be able to consult runbooks from Slab pages.</p> <p>Retrieve your Slab API token prior to configuring this toolset. Do note that Slab API is only available for Slab premium users. See here.</p>"},{"location":"data-sources/builtin-toolsets/slab/#configuration","title":"Configuration","text":"Holmes CLIRobusta Helm Chart <p>First, set the environment variable: <pre><code>export SLAB_API_KEY=\"&lt;your Slab API key&gt;\"\n</code></pre></p> <p>Then add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist: <pre><code>toolsets:\n    slab:\n        enabled: true\n</code></pre></p> <p>After making changes to your configuration, run: <pre><code>holmes toolset refresh\n</code></pre></p> <pre><code>holmes:\n    additionalEnvVars:\n        - name: SLAB_API_KEY\n          value: \"&lt;your Slab API key&gt;\"\n    toolsets:\n        slab:\n            enabled: true\n</code></pre> <p>Update your Helm values and run a Helm upgrade: <pre><code>helm upgrade robusta robusta/robusta --values=generated_values.yaml --set clusterName=&lt;YOUR_CLUSTER_NAME&gt;\n</code></pre></p> <p>To test, run:</p> <pre><code>holmes ask \"Why is my pod failing, if it's a crashloopbackoff use the runbooks from Slab\"\n</code></pre>"},{"location":"data-sources/builtin-toolsets/slab/#capabilities","title":"Capabilities","text":"<p>The table below describes the specific capabilities provided by this toolset. HolmesGPT can decide to invoke any of these capabilities when answering questions or investigating issues.</p> Tool Name Description fetch_slab_document Fetch a document from Slab. Use this to fetch runbooks if they are present before starting your investigation."},{"location":"development/","title":"Development","text":"<p>Extend HolmesGPT with custom integrations and contribute to the project.</p>"},{"location":"development/#available-development-guides","title":"Available Development Guides","text":"<ul> <li>Contributing Guidelines - How to contribute to the HolmesGPT project</li> <li>Contributing Documentation - How to contribute to documentation</li> </ul>"},{"location":"development/#evaluations","title":"Evaluations","text":"<ul> <li>Evaluations Overview - Understanding HolmesGPT's evaluation framework</li> <li>Adding a New Eval - Create your own evaluation tests</li> <li>Reporting with Braintrust - Analyze evaluation results</li> </ul>"},{"location":"development/#development-resources","title":"Development Resources","text":"<ul> <li>Source Code: GitHub Repository</li> <li>Issue Tracker: GitHub Issues</li> <li>Community: Slack Channel</li> <li>Documentation: You're reading it!</li> </ul>"},{"location":"development/transformers/","title":"Tool Output Transformers","text":"<p>HolmesGPT supports transformers that can process tool outputs before they're sent to the primary LLM. This enables automatic summarization of large outputs, reducing context window usage while preserving essential information.</p>"},{"location":"development/transformers/#overview","title":"Overview","text":"<p>Transformers are functions that take a tool's raw output and transform it before returning to the LLM. The primary use case is the <code>llm_summarize</code> transformer, which uses a fast secondary model to summarize lengthy outputs from tools like <code>kubectl describe</code>, log queries, or metrics collection.</p>"},{"location":"development/transformers/#configuration","title":"Configuration","text":""},{"location":"development/transformers/#global-configuration","title":"Global Configuration","text":"<p>Configure transformer behavior globally in your HolmesGPT configuration:</p> <pre><code># CLI flags\nholmes ask \"what pods are unhealthy?\" --fast-model gpt-4o-mini\n\n# Environment variables\nexport FAST_MODEL=\"gpt-4o-mini\"\n\n# Or via config file\n# ~/.holmes/config.yaml:\n# fast_model: gpt-4o-mini\n</code></pre> Parameter Description Default <code>--fast-model</code> Fast model for summarization tasks <code>None</code> (disabled)"},{"location":"development/transformers/#tool-level-configuration","title":"Tool-Level Configuration","text":"<p>Tools can declare transformers in their definitions:</p>"},{"location":"development/transformers/#yaml-tools","title":"YAML Tools","text":"<pre><code># Basic summarization with defaults\n- name: \"kubectl_get_by_kind_in_namespace\"\n  description: \"Get all resources of a type in a namespace\"\n  command: \"kubectl get --show-labels -o wide {{ kind }} -n {{ namespace }}\"\n  transformers:\n    - name: llm_summarize\n      config: {}\n\n# Custom threshold and prompt\n- name: \"kubectl_describe\"\n  description: \"Describe a Kubernetes resource\"\n  command: \"kubectl describe {{ kind }} {{ name }}{% if namespace %} -n {{ namespace }}{% endif %}\"\n  transformers:\n    - name: llm_summarize\n      config:\n        input_threshold: 1000\n        prompt: |\n          Summarize this kubectl describe output focusing on:\n          - What needs attention or immediate action\n          - Resource status and health indicators\n          - Any errors, warnings, or non-standard states\n          - Key configuration details that could affect functionality\n          - When possible, mention exact field names so the user can grep for specific details\n</code></pre>"},{"location":"development/transformers/#python-toolsets","title":"Python Toolsets","text":"<pre><code>from holmes.core.transformers import Transformer\n\nclass PrometheusToolset(Toolset):\n    def __init__(self):\n        super().__init__(\n            name=\"prometheus/metrics\",\n            tools=[\n                ListPrometheusRules(\n                    toolset=self,\n                    transformers=[\n                        Transformer(name=\"llm_summarize\", config={})  # use default config\n                    ]\n                ),\n                ListAvailableMetrics(\n                    toolset=self,\n                    transformers=[\n                        Transformer(\n                            name=\"llm_summarize\",\n                            config={\n                                \"input_threshold\": 800,\n                                \"prompt\": \"Summarize the available Prometheus metrics, grouping similar metrics and highlighting any unusual patterns.\"\n                            }\n                        )\n                    ]\n                ),\n            ]\n        )\n</code></pre>"},{"location":"development/transformers/#mcp-tools","title":"MCP Tools","text":"<p>To be implemented in future phases, allowing MCP tools to leverage transformers similarly to YAML and Python tools.</p>"},{"location":"development/transformers/#llm-summarize-transformer","title":"LLM Summarize Transformer","text":"<p>The <code>llm_summarize</code> transformer is the primary transformer available in HolmesGPT.</p>"},{"location":"development/transformers/#behavior","title":"Behavior","text":"<ol> <li>Threshold Check: Only processes outputs longer than <code>input_threshold</code> characters</li> <li>Fast Model Required: Skips summarization if no <code>--fast-model</code> is configured</li> <li>Context Preservation: Maintains essential debugging information while reducing size</li> <li>Error Handling: Falls back to original output if summarization fails</li> <li>Non-Expanding Fallback: If the generated summary is not smaller than the original output, preserves the original output to prevent expansion</li> </ol>"},{"location":"development/transformers/#configuration-options","title":"Configuration Options","text":"Option Description Default <code>input_threshold</code> Minimum characters to trigger summarization <code>1000</code> characters (default) <code>prompt</code> Custom summarization instructions Default diagnostic prompt"},{"location":"development/transformers/#default-prompt","title":"Default Prompt","text":"<p>The default summarization prompt is optimized for operational diagnostics:</p> <pre><code>Summarize this operational data focusing on:\n- What needs attention or immediate action\n- Group similar entries into a single line and description\n- Make sure to mention outliers, errors, and non-standard patterns\n- List normal/healthy patterns as aggregate descriptions\n- When listing problematic entries, also try to use aggregate descriptions when possible\n- When possible, mention exact keywords, IDs, or patterns so the user can filter/search the original data and drill down on the parts they care about\n</code></pre>"},{"location":"development/transformers/#when-to-use-transformers","title":"When to Use Transformers","text":""},{"location":"development/transformers/#good-candidates-for-transformers","title":"\u2705 Good Candidates for Transformers","text":"<ul> <li>Large kubectl outputs (<code>kubectl get -A</code>, <code>kubectl describe</code>)</li> <li>Log aggregation results with many similar entries</li> <li>Metrics queries returning extensive time series data</li> <li>Database query results with repetitive rows</li> <li>API responses with verbose metadata</li> </ul>"},{"location":"development/transformers/#poor-candidates-for-transformers","title":"\u274c Poor Candidates for Transformers","text":"<ul> <li>Small, structured outputs (single resource descriptions)</li> <li>Error messages that need exact preservation</li> <li>Configuration files where details matter</li> <li>Already concise outputs under the threshold</li> </ul>"},{"location":"development/transformers/#examples","title":"Examples","text":""},{"location":"development/transformers/#kubernetes-resource-listing","title":"Kubernetes Resource Listing","text":"<p>Without Transformer: <pre><code>NAME                                READY   STATUS      RESTARTS   AGE     IP           NODE\npod-1                              1/1     Running     0          5d      10.1.1.1     node-1\npod-2                              1/1     Running     0          5d      10.1.1.2     node-1\npod-3                              1/1     Running     0          5d      10.1.1.3     node-2\npod-4                              0/1     CrashLoopBackOff  15    1h      10.1.1.4     node-2\n[... 100 more similar pods ...]\n</code></pre></p> <p>With Transformer: <pre><code>Found 104 pods across 2 nodes:\n- 103 pods are healthy and running (age: 5d, on node-1 and node-2)\n- 1 pod in CrashLoopBackOff state: pod-4 (15 restarts, 1h old, IP 10.1.1.4, node-2)\n- Search with \"grep pod-4\" or \"grep CrashLoopBackOff\" to drill down on the problematic pod\n</code></pre></p>"},{"location":"development/transformers/#log-analysis","title":"Log Analysis","text":"<p>Without Transformer: <pre><code>2024-01-15T10:30:01Z INFO Starting application...\n2024-01-15T10:30:02Z INFO Database connection established\n2024-01-15T10:30:03Z INFO Loading configuration...\n[... 1000 similar INFO logs ...]\n2024-01-15T10:35:15Z ERROR Failed to connect to Redis: connection timeout\n2024-01-15T10:35:16Z WARN Retrying Redis connection (attempt 1/3)\n</code></pre></p> <p>With Transformer: <pre><code>Log analysis (2024-01-15 10:30-10:35):\n- 1000+ INFO messages showing normal application startup and operations\n- 1 ERROR: Redis connection timeout at 10:35:15Z\n- 1 WARN: Redis retry attempt at 10:35:16Z\n- Search with \"grep ERROR\" or \"grep Redis\" to investigate the connection issue\n</code></pre></p>"},{"location":"development/transformers/#best-practices","title":"Best Practices","text":""},{"location":"development/transformers/#prompt-design","title":"Prompt Design","text":"<ol> <li>Focus on actionable information - what needs attention</li> <li>Group similar items - avoid repetitive listings</li> <li>Preserve searchable keywords - help users drill down</li> <li>Highlight anomalies - errors, warnings, outliers</li> <li>Use aggregate descriptions - \"5 pods in pending state\" vs listing each</li> </ol>"},{"location":"development/transformers/#configuration_1","title":"Configuration","text":"<ol> <li>Set appropriate thresholds - avoid summarizing small outputs</li> <li>Use fast models - gpt-4o-mini, claude-haiku for cost/speed</li> <li>Customize prompts - tailor to specific tool output types</li> <li>Test thoroughly - ensure key information isn't lost</li> </ol>"},{"location":"development/transformers/#tool-integration","title":"Tool Integration","text":"<ol> <li>High-value targets first - kubectl, logs, metrics</li> <li>Preserve debug capability - users should be able to get raw output</li> <li>Graceful degradation - work without transformers configured</li> <li>Monitor effectiveness - track context window reduction</li> </ol>"},{"location":"development/transformers/#troubleshooting","title":"Troubleshooting","text":""},{"location":"development/transformers/#transformer-not-running","title":"Transformer Not Running","text":"<ul> <li>Check fast model configuration: Ensure <code>--fast-model</code> is set</li> <li>Verify threshold: Output must exceed <code>input_threshold</code> characters</li> <li>Review tool configuration: Confirm <code>transformers</code> is properly defined</li> </ul>"},{"location":"development/transformers/#poor-summarization-quality","title":"Poor Summarization Quality","text":"<ul> <li>Customize the prompt: Add domain-specific instructions</li> <li>Adjust threshold: Lower threshold for smaller outputs</li> <li>Try different fast models: Some models excel at different tasks</li> <li>Check original output: Ensure raw data contains the expected information</li> </ul>"},{"location":"development/transformers/#performance-issues","title":"Performance Issues","text":"<ul> <li>Monitor token usage: Fast models should be cost-effective</li> <li>Set reasonable thresholds: Avoid processing small outputs</li> <li>Consider rate limits: Fast model APIs have usage constraints</li> <li>Cache when possible: Some tools may benefit from result caching</li> </ul>"},{"location":"development/transformers/#migration-guide","title":"Migration Guide","text":""},{"location":"development/transformers/#existing-yaml-tools","title":"Existing YAML Tools","text":"<p>Add transformer configuration to tools that generate large outputs:</p> <pre><code># Before\n- name: \"my_large_output_tool\"\n  command: \"some command that produces lots of output\"\n\n# After\n- name: \"my_large_output_tool\"\n  command: \"some command that produces lots of output\"\n  transformers:\n    - name: llm_summarize\n      config:\n        input_threshold: 1000\n        prompt: \"Custom prompt for this tool's output type\"\n</code></pre>"},{"location":"development/transformers/#python-toolsets_1","title":"Python Toolsets","text":"<p>Update tool constructors to accept transformer configurations:</p> <pre><code>from holmes.core.transformers import Transformer\n\n# Before\nMyTool(toolset=self)\n\n# After\nMyTool(\n    toolset=self,\n    transformers=[\n        Transformer(name=\"llm_summarize\", config={\"input_threshold\": 800})\n    ]\n)\n</code></pre> <p>For more information, see the HolmesGPT documentation.</p>"},{"location":"development/evaluations/","title":"HolmesGPT Evaluations","text":"<p>We use 150+ evaluations ('evals' for short) to benchmark HolmesGPT, map out areas for improvement, and compare performance across different models.</p> <p>We also use the evals as regression tests on every commit.</p> <p>View latest evaluation results \u2192</p>"},{"location":"development/evaluations/#test-categories","title":"Test Categories","text":"<ul> <li>Regression tests (<code>easy</code>): Scenarios that must always pass</li> <li>Advanced tests (<code>medium</code> and <code>hard</code>): More challenging scenarios</li> <li>Specialized tests: Focused on specific capabilities (logs, kubernetes, prometheus, etc.)</li> </ul>"},{"location":"development/evaluations/#quick-start","title":"Quick Start","text":""},{"location":"development/evaluations/#running-evaluations","title":"Running Evaluations","text":"<pre><code># Prerequisites\npoetry install --with=dev\n\n# Run regression tests (should always pass)\nRUN_LIVE=true poetry run pytest -m 'llm and easy' --no-cov\n\n# Run specific test\nRUN_LIVE=true poetry run pytest tests/llm/test_ask_holmes.py -k \"01_how_many_pods\"\n\n# Run with multiple iterations for reliable results\nRUN_LIVE=true ITERATIONS=10 poetry run pytest -m 'llm and easy'\n</code></pre> <p>\u2192 Complete guide to running evaluations</p>"},{"location":"development/evaluations/#adding-new-tests","title":"Adding New Tests","text":"<p>Create test scenarios to improve coverage:</p> <pre><code># test_case.yaml\nuser_prompt: 'Is the nginx pod healthy?'\nexpected_output:\n  - nginx pod is healthy\nbefore_test: kubectl apply -f ./manifest.yaml\nafter_test: kubectl delete -f ./manifest.yaml\n</code></pre> <p>\u2192 Guide to adding new evaluations</p>"},{"location":"development/evaluations/#analyzing-results","title":"Analyzing Results","text":"<p>Track and debug evaluation results with Braintrust:</p> <pre><code>export BRAINTRUST_API_KEY=your-key\nRUN_LIVE=true poetry run pytest -m 'llm and easy'\n</code></pre> <p>\u2192 Reporting and analysis guide</p>"},{"location":"development/evaluations/#automated-benchmarking","title":"Automated Benchmarking","text":"<p>Our CI/CD pipeline runs evaluations automatically:</p> <ul> <li>Weekly - Every Sunday at 2 AM UTC (comprehensive testing with 10 iterations)</li> <li>Pull Requests - When eval-related files are modified (quick validation)</li> <li>On-demand - Via GitHub Actions UI</li> </ul> <p>Results are published here and archived in history.</p>"},{"location":"development/evaluations/#model-comparison","title":"Model Comparison","text":"<p>Compare different LLMs to find the best for your use case:</p> <pre><code># Test multiple models in one run\nRUN_LIVE=true MODEL=gpt-4o,anthropic/claude-sonnet-4-20250514 \\\n  CLASSIFIER_MODEL=gpt-4o \\\n  poetry run pytest -m 'llm and easy'\n</code></pre> <p>See the latest results for current model performance comparisons.</p>"},{"location":"development/evaluations/#resources","title":"Resources","text":"<ul> <li>Running Evaluations - Complete guide to running tests</li> <li>Adding New Evaluations - Contribute test scenarios</li> <li>Reporting with Braintrust - Analyze results in detail</li> <li>Historical Results - Past benchmark data</li> </ul>"},{"location":"development/evaluations/adding-evals/","title":"Adding a New Eval","text":"<p>Create test cases that measure HolmesGPT's diagnostic accuracy and help track improvements over time.</p>"},{"location":"development/evaluations/adding-evals/#prerequisites","title":"Prerequisites","text":"<p>Install HolmesGPT python dependencies:</p> <pre><code>poetry install --with=dev\n</code></pre>"},{"location":"development/evaluations/adding-evals/#quick-start-running-your-first-eval","title":"Quick Start: Running Your First Eval","text":"<p>Try running an existing eval to understand how the system works. We'll use eval 80_pvc_storage_class_mismatch as an example:</p> <pre><code># Run eval #80 with Claude Sonnet 4.5 (this specific eval passes reliably with Sonnet 4.5)\nRUN_LIVE=true MODEL=anthropic/claude-sonnet-4-20250514 \\\n  CLASSIFIER_MODEL=gpt-4.1 \\\n  poetry run pytest tests/llm/test_ask_holmes.py -k \"80_pvc_storage_class_mismatch\"\n\n# Compare with GPT-4o (may not pass as reliably)\nRUN_LIVE=true MODEL=gpt-4o \\\n  poetry run pytest tests/llm/test_ask_holmes.py -k \"80_pvc_storage_class_mismatch\"\n\n# Compare with GPT-4.1 (may not pass as reliably)\nRUN_LIVE=true MODEL=gpt-4.1 \\\n  poetry run pytest tests/llm/test_ask_holmes.py -k \"80_pvc_storage_class_mismatch\"\n\n# Test multiple models at once to compare performance\nRUN_LIVE=true MODEL=gpt-4o,gpt-4.1,anthropic/claude-sonnet-4-20250514 \\\n  CLASSIFIER_MODEL=gpt-4.1 \\\n  poetry run pytest tests/llm/test_ask_holmes.py -k \"80_pvc_storage_class_mismatch\"\n</code></pre> <p>Note: Eval #80 demonstrates how different models perform differently - Sonnet 4.5 passes this specific eval reliably while weaker models like GPT-4o and GPT-4.1 may struggle with this scenario.</p>"},{"location":"development/evaluations/adding-evals/#quick-start","title":"Quick Start","text":"<ol> <li> <p>Create test folder: <code>tests/llm/fixtures/test_ask_holmes/99_your_test/</code></p> </li> <li> <p>Create <code>test_case.yaml</code>: <pre><code>user_prompt: 'Is the nginx pod healthy?'\nexpected_output:\n  - nginx pod is healthy\nbefore_test: kubectl apply -f ./manifest.yaml\nafter_test: kubectl delete -f ./manifest.yaml\n</code></pre></p> </li> <li> <p>Create <code>manifest.yaml</code> with your test scenario: <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\n  namespace: default\nspec:\n  containers:\n  - name: nginx\n    image: nginx:latest\n    ports:\n    - containerPort: 80\n</code></pre></p> </li> <li> <p>Run test: <pre><code># With GPT-4.1\nRUN_LIVE=true MODEL=gpt-4.1 \\\n  poetry run pytest tests/llm/test_ask_holmes.py -k \"99_your_test\" -v\n\n# With Claude Sonnet 4.5 (must set CLASSIFIER_MODEL since Anthropic models can't be used as classifiers)\nRUN_LIVE=true MODEL=anthropic/claude-sonnet-4-20250514 \\\n  CLASSIFIER_MODEL=gpt-4.1 \\\n  poetry run pytest tests/llm/test_ask_holmes.py -k \"99_your_test\" -v\n</code></pre></p> </li> </ol> <p>Note on CLASSIFIER_MODEL: An LLM judges whether tests pass. Only OpenAI models (like <code>gpt-4.1</code>) work as classifiers. Set <code>CLASSIFIER_MODEL=gpt-4.1</code> explicitly when using Anthropic models. For OpenAI models, it defaults to <code>MODEL</code>.</p>"},{"location":"development/evaluations/adding-evals/#test_caseyaml-configuration","title":"test_case.yaml Configuration","text":"<p>Configure your test by defining these fields in <code>test_case.yaml</code>:</p>"},{"location":"development/evaluations/adding-evals/#required-fields","title":"Required Fields","text":"<ul> <li><code>user_prompt</code>: Question for Holmes</li> <li><code>expected_output</code>: List of required elements in response</li> <li><code>before_test</code>/<code>after_test</code>: Setup/teardown commands (run with <code>RUN_LIVE=true</code>)</li> </ul>"},{"location":"development/evaluations/adding-evals/#optional-fields","title":"Optional Fields","text":"<ul> <li><code>tags</code>: List of test markers (e.g., <code>[easy, kubernetes, logs]</code>)</li> <li><code>skip</code>: Boolean to skip test</li> <li><code>skip_reason</code>: Explanation why test is skipped</li> <li><code>mocked_date</code>: Override system time for test (e.g., <code>\"2025-06-23T11:34:00Z\"</code>)</li> <li><code>cluster_name</code>: Specify kubernetes cluster name</li> <li><code>include_files</code>: List of files to include in context (like CLI's <code>--include</code> flag)</li> <li><code>runbooks</code>: Override runbook catalog:   <pre><code>runbooks:\n  catalog:\n    - description: \"Database Connection Troubleshooting\"\n      link: \"database_troubleshooting.md\"\n      update_date: \"2025-07-01\"\n</code></pre></li> <li><code>toolsets</code>: Configure toolsets (can also use separate <code>toolsets.yaml</code> file):   <pre><code>toolsets:\n  aws/lambda:\n    enabled: true\n  aws/cloudwatch:\n    enabled: false\n</code></pre></li> <li><code>port_forwards</code>: Configure port forwarding for tests</li> <li><code>test_env_vars</code>: Environment variables during test execution</li> <li><code>mock_policy</code>: Control mock behavior (<code>always_mock</code>, <code>never_mock</code>, or <code>inherit</code>)</li> <li><code>conversation_history</code>: For multi-turn conversation tests</li> <li><code>expected_sections</code>: For investigation tests only</li> </ul>"},{"location":"development/evaluations/adding-evals/#mock-data-usage","title":"Mock Data Usage","text":"<p>Live evaluations (<code>RUN_LIVE=true</code>) are strongly preferred because they're more reliable and accurate.</p>"},{"location":"development/evaluations/adding-evals/#generating-mock-data","title":"Generating Mock Data","text":"<pre><code># Generate mocks for one test\npoetry run pytest tests/llm/test_ask_holmes.py -k \"your_test\" --generate-mocks\n\n# Remove any existing mocks for your test and generate them from scratch\npoetry run pytest tests/llm/test_ask_holmes.py -k \"your_test\" --regenerate-all-mocks\n</code></pre> <p>Mock files are named: <code>{tool_name}_{context}.txt</code></p>"},{"location":"development/evaluations/adding-evals/#mock-data-guidelines","title":"Mock Data Guidelines","text":"<p>When creating mock data:</p> <ul> <li>Never generate mock data manually - always use <code>--generate-mocks</code> with live execution</li> <li>Mock data should match real-world responses exactly</li> <li>Include all fields that would be present in actual responses</li> <li>Maintain proper timestamps and data relationships</li> </ul>"},{"location":"development/evaluations/adding-evals/#important-notes-about-mocks","title":"Important Notes About Mocks","text":"<ul> <li>Mock data captures only one investigation path - LLMs may take completely different approaches</li> <li>Tests with mocks often fail when the LLM chooses a different but equally valid investigation strategy</li> <li>Mock execution misses the dynamic nature of real troubleshooting</li> <li>Always develop and validate tests with <code>RUN_LIVE=true</code></li> <li>Mock data becomes stale as APIs and tool behaviors evolve</li> </ul>"},{"location":"development/evaluations/adding-evals/#advanced-features","title":"Advanced Features","text":""},{"location":"development/evaluations/adding-evals/#toolsets-configuration","title":"Toolsets Configuration","text":"<p>You can configure which toolsets are available during your test in two ways:</p> <ol> <li> <p>Inline in test_case.yaml: <pre><code>toolsets:\n  kubernetes/core:\n    enabled: true\n  aws/cloudwatch:\n    enabled: false\n</code></pre></p> </li> <li> <p>Separate toolsets.yaml file (preferred for complex configurations): <pre><code># toolsets.yaml\ntoolsets:\n  grafana/loki:\n    enabled: true\n    config:\n      url: http://loki.app-143.svc.cluster.local:3100\n      api_key: \"\"\n  kafka/admin:\n    enabled: true\n    config:\n      kafka_clusters:\n        - name: \"kafka\"\n          kafka_broker: \"kafka:9092\"\n</code></pre></p> </li> </ol>"},{"location":"development/evaluations/adding-evals/#port-forwarding","title":"Port Forwarding","text":"<p>Some tests require access to services that are not directly exposed. You can configure port forwards that will be automatically set up and torn down for your test:</p> <pre><code>port_forwards:\n  - namespace: app-01\n    service: rabbitmq\n    local_port: 15672\n    remote_port: 15672\n  - namespace: app-01\n    service: prometheus\n    local_port: 9090\n    remote_port: 9090\n</code></pre> <p>Note: Use unique local ports across all tests to avoid conflicts</p> <p>Port forwards are:</p> <ul> <li>Automatically started before any tests run</li> <li>Shared across all tests in a session to avoid conflicts</li> <li>Always cleaned up after tests complete, even if tests are interrupted</li> <li>Run regardless of <code>--skip-setup</code> or <code>--skip-cleanup</code> flags</li> </ul> <p>Important notes:</p> <ul> <li>Use unique local ports across all tests to avoid conflicts</li> <li>Port forwards persist for the entire test session</li> <li>If a port is already in use, the test will fail with helpful debugging information</li> <li>Use <code>lsof -ti :&lt;port&gt;</code> to find processes using a port</li> <li>Port forwards work with both mock and live (<code>RUN_LIVE=true</code>) test modes</li> </ul>"},{"location":"development/evaluations/adding-evals/#toolset-configuration","title":"Toolset Configuration","text":"<p>Create <code>toolsets.yaml</code> to customize available tools:</p> <pre><code>toolsets:\n  prometheus/metrics:\n    enabled: true\n    config:\n      prometheus_url: \"http://custom-prometheus:9090\"\n  grafana/dashboards:\n    enabled: false  # Disable specific toolsets\n</code></pre>"},{"location":"development/evaluations/adding-evals/#mock-policy","title":"Mock Policy","text":"<pre><code>mock_policy: \"inherit\"  # Options: inherit (default), never_mock, always_mock\n</code></pre> <ul> <li><code>inherit</code>: Use global settings</li> <li><code>never_mock</code>: Force live execution (skipped if RUN_LIVE not set)</li> <li><code>always_mock</code>: Always use mocks (avoid when possible)</li> </ul>"},{"location":"development/evaluations/adding-evals/#custom-runbooks","title":"Custom Runbooks","text":"<pre><code>runbooks:\n  catalog:\n    - description: \"DNS troubleshooting\"\n      link: \"dns-runbook.md\"  # Place .md file in test directory\n</code></pre> <p>Options:</p> <ul> <li>No field: Use default runbooks</li> <li><code>runbooks: {}</code>: No runbooks available</li> <li><code>runbooks: {catalog: [...]}</code>: Custom catalog</li> </ul>"},{"location":"development/evaluations/adding-evals/#tagging","title":"Tagging","text":"<p>Evals support tags for organization, filtering, and reporting purposes. Tags help categorize tests by their characteristics and enable selective test execution.</p>"},{"location":"development/evaluations/adding-evals/#available-tags","title":"Available Tags","text":"<p>The valid tags are defined in the test constants file in the repository.</p> <p>Some examples</p> <ul> <li><code>logs</code> - Tests HolmesGPT's ability to find and interpret logs correctly</li> <li><code>context_window</code> - Tests handling of data that exceeds the LLM's context window</li> <li><code>synthetic</code> - Tests that use manually generated mock data (cannot be run live)</li> <li><code>datetime</code> - Tests date/time handling and interpretation</li> <li>etc.</li> </ul>"},{"location":"development/evaluations/latest-results/","title":"HolmesGPT LLM Evaluation Benchmark Results","text":"<p>Generated: 2025-10-12 17:03 UTC Total Duration: 1h 48m 23s Iterations: 1 Judge (classifier) model: azure/gpt-4.1</p>"},{"location":"development/evaluations/latest-results/#about-this-benchmark","title":"About this Benchmark","text":"<p>HolmesGPT is continuously evaluated against real-world Kubernetes and cloud troubleshooting scenarios.</p> <p>If you find scenarios that HolmesGPT does not perform well on, please consider adding them as evals to the benchmark.</p>"},{"location":"development/evaluations/latest-results/#model-accuracy-comparison","title":"Model Accuracy Comparison","text":"Model Pass Fail Skip/Error Total Success Rate gpt-4o 52 41 12 105 \ud83d\udfe1 56% (52/93) eu.anthropic.claude-sonnet-4-20250514-v1:0 82 13 10 105 \ud83d\udfe1 86% (82/95) gpt-4.1 67 27 11 105 \ud83d\udfe1 71% (67/94) gpt-5 74 20 11 105 \ud83d\udfe1 79% (74/94) novita/deepseek/deepseek-v3.1-terminus 75 20 10 105 \ud83d\udfe1 79% (75/95) novita/qwen/qwen3-next-80b-a3b-instruct 55 40 10 105 \ud83d\udfe1 58% (55/95)"},{"location":"development/evaluations/latest-results/#model-cost-comparison","title":"Model Cost Comparison","text":"Model Tests Avg Cost Min Cost Max Cost Total Cost gpt-4o 93 $0.18 $0.03 $1.00 $16.67 eu.anthropic.claude-sonnet-4-20250514-v1:0 93 $0.25 $0.06 $1.01 $22.85 gpt-4.1 94 $0.11 $0.02 $0.66 $10.68 gpt-5 94 $0.19 $0.02 $0.59 $17.43"},{"location":"development/evaluations/latest-results/#model-latency-comparison","title":"Model Latency Comparison","text":"Model Avg (s) Min (s) Max (s) P50 (s) P95 (s) gpt-4o 26.6 8.0 67.1 25.9 55.3 eu.anthropic.claude-sonnet-4-20250514-v1:0 48.9 9.8 263.9 43.4 100.8 gpt-4.1 40.7 5.5 645.1 25.4 51.7 gpt-5 138.5 17.4 859.1 81.6 752.3 novita/deepseek/deepseek-v3.1-terminus 75.5 21.1 221.1 71.1 142.2 novita/qwen/qwen3-next-80b-a3b-instruct 82.8 12.0 1100.6 34.8 296.6 <p>\u26a0\ufe0f Note: 7 test(s) excluded from latency calculations due to throttling/timeout errors (eu.anthropic.claude-sonnet-4-20250514-v1:0: 2, novita/qwen/qwen3-next-80b-a3b-instruct: 5)</p>"},{"location":"development/evaluations/latest-results/#performance-by-tag","title":"Performance by Tag","text":"<p>Success rate by test category and model:</p> Tag gpt-4o eu.anthropic.claude-sonnet-4-20250514-v1:0 gpt-4.1 gpt-5 novita/deepseek/deepseek-v3.1-terminus novita/qwen/qwen3-next-80b-a3b-instruct Warnings chain-of-causation \ud83d\udd34 0% (0/7) \ud83d\udfe1 71% (5/7) \ud83d\udd34 0% (0/7) \ud83d\udfe1 57% (4/7) \ud83d\udfe1 29% (2/7) \ud83d\udfe1 14% (1/7) \u26a0\ufe0f 6 skipped context_window \ud83d\udfe1 14% (1/7) \ud83d\udfe1 57% (4/7) \ud83d\udfe1 57% (4/7) \ud83d\udfe1 86% (6/7) \ud83d\udfe1 57% (4/7) \ud83d\udfe1 29% (2/7) counting \ud83d\udfe2 100% (4/4) \ud83d\udfe2 100% (4/4) \ud83d\udfe2 100% (4/4) \ud83d\udfe1 75% (\u00be) \ud83d\udfe2 100% (4/4) \ud83d\udfe2 100% (4/4) database \ud83d\udd34 0% (0/1) \ud83d\udfe2 100% (1/1) \ud83d\udd34 0% (0/1) \ud83d\udfe2 100% (1/1) \ud83d\udfe2 100% (1/1) \ud83d\udfe2 100% (1/1) \u26a0\ufe0f 18 skipped datadog \ud83d\udfe1 67% (\u2154) \ud83d\udfe1 75% (\u00be) \ud83d\udfe1 75% (\u00be) \ud83d\udfe1 75% (\u00be) \ud83d\udfe1 75% (\u00be) \ud83d\udfe1 75% (\u00be) \u26a0\ufe0f 1 skipped datetime \ud83d\udfe1 50% (2/4) \ud83d\udfe1 50% (2/4) \ud83d\udfe1 50% (2/4) \ud83d\udfe2 100% (4/4) \ud83d\udfe1 75% (\u00be) \ud83d\udfe1 50% (2/4) \u26a0\ufe0f 12 skipped easy \ud83d\udfe1 91% (32/35) \ud83d\udfe1 92% (33/36) \ud83d\udfe1 97% (35/36) \ud83d\udfe1 83% (30/36) \ud83d\udfe1 94% (34/36) \ud83d\udfe1 86% (31/36) \u26a0\ufe0f 1 skipped hard \ud83d\udfe1 20% (3/15) \ud83d\udfe1 80% (12/15) \ud83d\udfe1 20% (3/15) \ud83d\udfe1 47% (7/15) \ud83d\udfe1 47% (7/15) \ud83d\udfe1 40% (6/15) \u26a0\ufe0f 30 skipped kafka \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26a0\ufe0f 12 skipped kubernetes \ud83d\udfe1 49% (23/47) \ud83d\udfe1 85% (40/47) \ud83d\udfe1 66% (31/47) \ud83d\udfe1 79% (37/47) \ud83d\udfe1 72% (34/47) \ud83d\udfe1 55% (26/47) \u26a0\ufe0f 6 skipped logs \ud83d\udfe1 46% (12/26) \ud83d\udfe1 78% (21/27) \ud83d\udfe1 62% (16/26) \ud83d\udfe1 74% (20/27) \ud83d\udfe1 74% (20/27) \ud83d\udfe1 44% (12/27) \u26a0\ufe0f 38 skipped medium \ud83d\udfe1 40% (17/43) \ud83d\udfe1 84% (37/44) \ud83d\udfe1 67% (29/43) \ud83d\udfe1 86% (37/43) \ud83d\udfe1 77% (34/44) \ud83d\udfe1 41% (18/44) \u26a0\ufe0f 33 skipped network \ud83d\udfe1 75% (\u00be) \ud83d\udfe2 100% (4/4) \ud83d\udfe1 75% (\u00be) \ud83d\udfe1 75% (\u00be) \ud83d\udfe2 100% (4/4) \ud83d\udfe2 100% (4/4) no-cicd \ud83d\udfe2 100% (1/1) \ud83d\udd34 0% (0/1) \ud83d\udfe2 100% (1/1) \ud83d\udfe2 100% (1/1) \ud83d\udfe2 100% (1/1) \ud83d\udfe2 100% (1/1) numerical \ud83d\udfe2 100% (1/1) \ud83d\udfe2 100% (1/1) \ud83d\udfe2 100% (1/1) \ud83d\udfe2 100% (1/1) \ud83d\udfe2 100% (1/1) \ud83d\udfe2 100% (1/1) port-forward \ud83d\udfe1 22% (2/9) \ud83d\udfe1 67% (6/9) \ud83d\udfe1 56% (5/9) \ud83d\udfe1 67% (6/9) \ud83d\udfe1 22% (2/9) \ud83d\udfe1 22% (2/9) prometheus \ud83d\udfe1 25% (\u00bc) \ud83d\udfe1 75% (\u00be) \ud83d\udfe2 100% (4/4) \ud83d\udfe2 100% (4/4) \ud83d\udfe1 50% (2/4) \ud83d\udfe1 25% (\u00bc) question-answer \ud83d\udfe1 75% (\u00be) \ud83d\udfe2 100% (4/4) \ud83d\udfe2 100% (4/4) \ud83d\udfe2 100% (4/4) \ud83d\udfe2 100% (4/4) \ud83d\udfe1 75% (\u00be) runbooks \ud83d\udfe1 67% (4/6) \ud83d\udfe2 100% (6/6) \ud83d\udfe1 83% (\u215a) \ud83d\udfe2 100% (6/6) \ud83d\udfe2 100% (6/6) \ud83d\udfe1 67% (4/6) \u26a0\ufe0f 6 skipped slackbot \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26a0\ufe0f 6 skipped traces \ud83d\udd34 0% (0/5) \ud83d\udfe1 60% (\u2157) \ud83d\udd34 0% (0/5) \ud83d\udfe1 80% (\u2158) \ud83d\udd34 0% (0/5) \ud83d\udd34 0% (0/5) transparency \ud83d\udfe1 79% (11/14) \ud83d\udfe1 93% (13/14) \ud83d\udfe1 93% (13/14) \ud83d\udfe1 86% (12/14) \ud83d\udfe1 71% (10/14) \ud83d\udfe1 43% (6/14) \u26a0\ufe0f 6 skipped Overall \ud83d\udfe1 56% (52/93) \ud83d\udfe1 86% (82/95) \ud83d\udfe1 71% (67/94) \ud83d\udfe1 79% (74/94) \ud83d\udfe1 79% (75/95) \ud83d\udfe1 58% (55/95) \u26a0\ufe0f 64 skipped"},{"location":"development/evaluations/latest-results/#raw-results","title":"Raw Results","text":"<p>Status of all evaluations across models. Color coding:</p> <ul> <li>\ud83d\udfe2 Passing 100% (stable)</li> <li>\ud83d\udfe1 Passing 1-99%</li> <li>\ud83d\udd34 Passing 0% (failing)</li> <li>\ud83d\udd27 Mock data failure (missing or invalid test data)</li> <li>\u26a0\ufe0f Setup failure (environment/infrastructure issue)</li> <li>\u23f1\ufe0f Timeout or rate limit error</li> <li>\u23ed\ufe0f Test skipped (e.g., known issue or precondition not met)</li> </ul> Eval ID gpt-4o eu.anthropic.claude-sonnet-4-20250514-v1:0 gpt-4.1 gpt-5 novita/deepseek/deepseek-v3.1-terminus novita/qwen/qwen3-next-80b-a3b-instruct 01_how_many_pods \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 02_what_is_wrong_with_pod \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 03_what_is_the_command_to_port_forward \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 04_related_k8s_events \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 05_image_version \ud83d\udd17 \ud83d\udfe2 \u23f1\ufe0f \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 08_sock_shop_frontend \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 09_crashpod \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 100a_historical_logs \ud83d\udd17 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 100b_historical_logs_nonstandard_label \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 101_historical_logs_pod_deleted \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 103_logs_transparency_default_limit \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 104a_postgres_root_issue \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 104b_postgres_missing_index_pgstat \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 104c_postgres_minimal_missing_index \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 105_redis_wrong_data_structure \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 107_log_filter_http_status_code \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 108_logs_nearby_lines \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 109_logs_transparency_not_found \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 10_image_pull_backoff \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 110_k8s_events_image_pull \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 111_disabled_datadog_traces \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 111_pod_names_contain_service \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 112_find_pvcs_by_uuid \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 114_checkout_latency_tracing_rebuild[0] \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 115_checkout_errors_tracing[0] \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udd34 11_init_containers \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 121_new_relic_checkout_errors_tracing[0] \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udd34 122_new_relic_checkout_latency_tracing_rebuild[0] \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udd34 123_new_relic_checkout_errors_tracing[0] \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udd34 12_job_crashing \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \u23f1\ufe0f 13a_pending_node_selector_basic \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 13b_pending_node_selector_detailed \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 14_pending_resources \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 156_kafka_opensearch_latency \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 159_prometheus_high_cardinality_cpu[0] \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udd34 159_prometheus_high_cardinality_cpu[1] \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 159_prometheus_high_cardinality_cpu[2] \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udd34 15_failed_readiness_probe \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 16_failed_no_toolset_found \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 17_oom_kill \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 19_detect_missing_app_details \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 20_long_log_file_search \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 21_job_fail_curl_no_svc_account \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 22_high_latency_dbi_down \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 23_app_error_in_current_logs \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 24_misconfigured_pvc \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 24a_misconfigured_pvc_basic \ud83d\udd17 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 24b_misconfigured_pvc_detailed \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 25_misconfigured_ingress_class \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 26_page_render_times \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 27a_multi_container_logs \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 27b_multi_container_logs \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 28_permissions_error \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 33_cpu_metrics_discovery \ud83d\udd17 \ud83d\udfe2 \u23f1\ufe0f \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 39_failed_toolset \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udd34 41_setup_argo \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 42_dns_issues_result_new_tools_no_runbook \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 42_dns_issues_steps_new_tools \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 43_current_datetime_from_prompt \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 43_slack_deployment_logs \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 44_slack_statefulset_logs \ud83d\udd17 \ud83d\udd27 \ud83d\udd27 \ud83d\udd27 \ud83d\udd27 \ud83d\udd27 \ud83d\udd27 45_fetch_deployment_logs_simple \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 48_logs_since_thursday \ud83d\udd17 \ud83d\udd27 \ud83d\udd27 \ud83d\udd27 \ud83d\udd27 \ud83d\udd27 \ud83d\udd27 50_logs_since_specific_date \ud83d\udd17 \ud83d\udd27 \ud83d\udfe2 \ud83d\udd27 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 50a_logs_since_last_specific_month \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 51_logs_summarize_errors \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 52_logs_login_issues \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 53_logs_find_term \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 54_not_truncated_when_getting_pods \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 55_kafka_runbook \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 57_wrong_namespace \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 59_label_based_counting \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 60_count_less_than \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 61_exact_match_counting \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 62_fetch_error_logs_with_errors \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 63_fetch_error_logs_no_errors \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 64_keda_vs_hpa_confusion \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 65_health_check_followup \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 71_connection_pool_starvation \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 73a_time_window_anomaly \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 73b_time_window_anomaly \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udd34 76_service_discovery_issue \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 77_liveness_probe_misconfiguration \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 78a_missing_cpu_limits \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \u23f1\ufe0f 78b_cpu_quota_exceeded \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 79_configmap_mount_issue \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 80_pvc_storage_class_mismatch \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 81_service_account_permission_denied \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 82_pod_anti_affinity_conflict \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udd34 83_secret_not_found \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 84_network_policy_blocking_traffic \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 85_hpa_not_scaling \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 86_configmap_like_but_secret \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 89_runbook_missing_cloudwatch \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 90_runbook_basic_selection \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 91f_datadog_logs_historical_pod \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 93_calling_datadog[0] \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 93_calling_datadog[1] \ud83d\udd17 \ud83d\udd27 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 93_calling_datadog[2] \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 93_events_since_specific_date \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd27 \ud83d\udfe2 \ud83d\udfe2 94_runbook_transparency \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 96_no_matching_runbook \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 97_logs_clarification_needed \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udd34 98_logs_transparency_default_time \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 99_logs_transparency_custom_time \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 SUMMARY \ud83d\udfe1 56% (52/93) \ud83d\udfe1 86% (82/95) \ud83d\udfe1 71% (67/94) \ud83d\udfe1 79% (74/94) \ud83d\udfe1 79% (75/95) \ud83d\udfe1 58% (55/95)"},{"location":"development/evaluations/latest-results/#detailed-raw-results","title":"Detailed Raw Results","text":"Eval ID gpt-4o eu.anthropic.claude-sonnet-4-20250514-v1:0 gpt-4.1 gpt-5 novita/deepseek/deepseek-v3.1-terminus novita/qwen/qwen3-next-80b-a3b-instruct 01_how_many_pods \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 21.6s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 21.4s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 20.6s / \ud83d\udcb0 $0.05 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 26.4s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 27.3s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 15.4s 02_what_is_wrong_with_pod \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 30.4s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 35.6s / \ud83d\udcb0 $0.17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 26.4s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 63.6s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 75.8s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 31.6s 03_what_is_the_command_to_port_forward \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 26.0s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 29.0s / \ud83d\udcb0 $0.16 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 26.3s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 58.9s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 43.8s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 24.1s 04_related_k8s_events \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 18.2s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 30.9s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 22.4s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 51.7s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 44.6s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 27.4s 05_image_version \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 16.2s / \ud83d\udcb0 $0.07 \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 621.2s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 23.3s / \ud83d\udcb0 $0.07 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 20.2s / \ud83d\udcb0 $0.02 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 45.7s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 22.1s 08_sock_shop_frontend \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 09_crashpod \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 55.3s / \ud83d\udcb0 $0.20 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 43.7s / \ud83d\udcb0 $0.21 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 631.4s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 53.6s / \ud83d\udcb0 $0.19 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 74.5s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 30.1s 100a_historical_logs \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 23.7s / \ud83d\udcb0 $0.15 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 83.8s / \ud83d\udcb0 $0.35 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 24.2s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 859.1s / \ud83d\udcb0 $0.49 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 86.2s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 49.2s 100b_historical_logs_nonstandard_label \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 29.7s / \ud83d\udcb0 $0.20 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 94.3s / \ud83d\udcb0 $0.39 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 23.2s / \ud83d\udcb0 $0.11 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 171.0s / \ud83d\udcb0 $0.28 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 83.4s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 77.2s 101_historical_logs_pod_deleted \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 22.2s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 60.1s / \ud83d\udcb0 $0.32 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 27.5s / \ud83d\udcb0 $0.11 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 191.0s / \ud83d\udcb0 $0.32 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 93.8s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 164.4s 103_logs_transparency_default_limit \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 22.4s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 37.3s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 29.3s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 44.2s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 64.4s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 65.1s 104a_postgres_root_issue \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 30.5s / \ud83d\udcb0 $0.23 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 55.5s / \ud83d\udcb0 $0.39 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 48.6s / \ud83d\udcb0 $0.21 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 191.3s / \ud83d\udcb0 $0.48 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 94.5s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 62.8s 104b_postgres_missing_index_pgstat \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 104c_postgres_minimal_missing_index \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 105_redis_wrong_data_structure \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 107_log_filter_http_status_code \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 31.7s / \ud83d\udcb0 $0.20 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 70.4s / \ud83d\udcb0 $0.28 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 25.4s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 192.2s / \ud83d\udcb0 $0.35 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 123.2s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 161.0s 108_logs_nearby_lines \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 29.3s / \ud83d\udcb0 $0.22 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 50.8s / \ud83d\udcb0 $0.40 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 32.6s / \ud83d\udcb0 $0.30 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 159.7s / \ud83d\udcb0 $0.27 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 106.3s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 71.5s 109_logs_transparency_not_found \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 26.5s / \ud83d\udcb0 $0.19 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 29.1s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 24.3s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 72.9s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 71.2s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 49.0s 10_image_pull_backoff \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 30.4s / \ud83d\udcb0 $0.23 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 44.6s / \ud83d\udcb0 $0.25 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 33.1s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 93.5s / \ud83d\udcb0 $0.23 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 56.9s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 71.5s 110_k8s_events_image_pull \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 23.4s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 31.2s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 23.8s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 46.3s / \ud83d\udcb0 $0.05 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 82.9s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 31.2s 111_disabled_datadog_traces \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 14.9s / \ud83d\udcb0 $0.03 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 27.0s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 14.3s / \ud83d\udcb0 $0.02 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 128.7s / \ud83d\udcb0 $0.15 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 66.3s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 23.2s 111_pod_names_contain_service \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 25.1s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 56.4s / \ud83d\udcb0 $0.25 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 37.5s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 146.3s / \ud83d\udcb0 $0.18 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 57.3s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 34.8s 112_find_pvcs_by_uuid \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 17.3s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 41.7s / \ud83d\udcb0 $0.23 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 30.1s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 53.9s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 65.8s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 36.7s 114_checkout_latency_tracing_rebuild[0] \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 65.7s / \ud83d\udcb0 $1.00 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 66.8s / \ud83d\udcb0 $0.55 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 27.6s / \ud83d\udcb0 $0.17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 206.5s / \ud83d\udcb0 $0.51 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 221.1s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 81.1s 115_checkout_errors_tracing[0] \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 67.1s / \ud83d\udcb0 $0.77 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 76.9s / \ud83d\udcb0 $0.52 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 645.1s / \ud83d\udcb0 $0.23 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 167.7s / \ud83d\udcb0 $0.40 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 135.7s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 81.0s 11_init_containers \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 25.4s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 44.8s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 27.8s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 90.8s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 69.0s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 33.2s 121_new_relic_checkout_errors_tracing[0] \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 25.9s / \ud83d\udcb0 $0.16 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 100.3s / \ud83d\udcb0 $0.44 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 21.2s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 208.5s / \ud83d\udcb0 $0.35 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 66.4s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 240.6s 122_new_relic_checkout_latency_tracing_rebuild[0] \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 23.0s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 105.7s / \ud83d\udcb0 $0.55 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 33.1s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 153.9s / \ud83d\udcb0 $0.35 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 146.8s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 956.2s 123_new_relic_checkout_errors_tracing[0] \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 17.4s / \ud83d\udcb0 $0.07 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 124.9s / \ud83d\udcb0 $0.69 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 24.8s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 225.8s / \ud83d\udcb0 $0.58 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 38.4s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 22.8s 12_job_crashing \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 28.1s / \ud83d\udcb0 $0.18 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 49.4s / \ud83d\udcb0 $0.21 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 28.5s / \ud83d\udcb0 $0.11 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 82.8s / \ud83d\udcb0 $0.16 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 112.4s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 489.4s 13a_pending_node_selector_basic \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 25.4s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 41.3s / \ud83d\udcb0 $0.21 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 28.1s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 99.5s / \ud83d\udcb0 $0.20 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 87.1s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 404.9s 13b_pending_node_selector_detailed \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 30.8s / \ud83d\udcb0 $0.18 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 43.7s / \ud83d\udcb0 $0.20 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 33.5s / \ud83d\udcb0 $0.11 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 21.8s / \ud83d\udcb0 $0.02 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 91.1s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 18.3s 14_pending_resources \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 33.7s / \ud83d\udcb0 $0.28 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 48.2s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 24.2s / \ud83d\udcb0 $0.11 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 24.3s / \ud83d\udcb0 $0.02 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 77.0s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 74.3s 156_kafka_opensearch_latency \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 159_prometheus_high_cardinality_cpu[0] \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 60.9s / \ud83d\udcb0 $0.67 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 43.9s / \ud83d\udcb0 $0.28 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 28.9s / \ud83d\udcb0 $0.16 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 163.2s / \ud83d\udcb0 $0.22 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 63.2s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 34.7s 159_prometheus_high_cardinality_cpu[1] \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 31.9s / \ud83d\udcb0 $0.28 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 45.1s / \ud83d\udcb0 $0.20 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 25.0s / \ud83d\udcb0 $0.22 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 108.4s / \ud83d\udcb0 $0.19 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 168.3s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 41.9s 159_prometheus_high_cardinality_cpu[2] \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 30.4s / \ud83d\udcb0 $0.25 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 39.0s / \ud83d\udcb0 $0.36 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 25.0s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 81.4s / \ud83d\udcb0 $0.10 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 64.5s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 296.6s 15_failed_readiness_probe \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 28.2s / \ud83d\udcb0 $0.19 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 46.3s / \ud83d\udcb0 $0.28 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 23.8s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 71.4s / \ud83d\udcb0 $0.19 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 77.8s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 31.7s 16_failed_no_toolset_found \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 20.8s / \ud83d\udcb0 $0.07 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 19.2s / \ud83d\udcb0 $0.06 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 15.9s / \ud83d\udcb0 $0.03 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 39.8s / \ud83d\udcb0 $0.04 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 91.0s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 15.3s 17_oom_kill \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 26.0s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 43.4s / \ud83d\udcb0 $0.25 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 23.4s / \ud83d\udcb0 $0.05 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 112.1s / \ud83d\udcb0 $0.17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 68.3s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 43.7s 19_detect_missing_app_details \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 29.5s / \ud83d\udcb0 $0.18 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 69.4s / \ud83d\udcb0 $0.23 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 38.7s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 65.8s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 75.0s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 710.0s 20_long_log_file_search \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 33.7s / \ud83d\udcb0 $0.19 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 69.7s / \ud83d\udcb0 $0.25 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 29.3s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 81.6s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 111.8s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 29.0s 21_job_fail_curl_no_svc_account \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 30.3s / \ud83d\udcb0 $0.22 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 39.9s / \ud83d\udcb0 $0.20 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 26.5s / \ud83d\udcb0 $0.09 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 19.8s / \ud83d\udcb0 $0.02 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 67.5s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 35.9s 22_high_latency_dbi_down \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 55.4s / \ud83d\udcb0 $0.57 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 78.8s / \ud83d\udcb0 $0.51 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 31.4s / \ud83d\udcb0 $0.16 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 118.0s / \ud83d\udcb0 $0.24 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 87.5s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 17.2s 23_app_error_in_current_logs \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 29.1s / \ud83d\udcb0 $0.19 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 44.9s / \ud83d\udcb0 $0.26 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 36.1s / \ud83d\udcb0 $0.17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 151.8s / \ud83d\udcb0 $0.28 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 82.7s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 78.2s 24_misconfigured_pvc \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 29.1s / \ud83d\udcb0 $0.21 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 50.7s / \ud83d\udcb0 $0.24 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 32.2s / \ud83d\udcb0 $0.14 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 18.8s / \ud83d\udcb0 $0.02 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 97.4s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 31.1s 24a_misconfigured_pvc_basic \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 33.4s / \ud83d\udcb0 $0.23 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 38.2s / \ud83d\udcb0 $0.17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 27.2s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 91.2s / \ud83d\udcb0 $0.15 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 34.0s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 40.2s 24b_misconfigured_pvc_detailed \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 23.8s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 41.3s / \ud83d\udcb0 $0.13 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 31.2s / \ud83d\udcb0 $0.11 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 19.6s / \ud83d\udcb0 $0.02 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 88.1s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 32.7s 25_misconfigured_ingress_class \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 13.5s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 263.9s / \ud83d\udcb0 $0.42 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 14.5s / \ud83d\udcb0 $0.06 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 243.1s / \ud83d\udcb0 $0.21 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 112.8s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 201.1s 26_page_render_times \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 23.8s / \ud83d\udcb0 $0.18 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 40.9s / \ud83d\udcb0 $0.28 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 22.7s / \ud83d\udcb0 $0.16 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 771.7s / \ud83d\udcb0 $0.32 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 64.3s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 26.3s 27a_multi_container_logs \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 12.6s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 30.5s / \ud83d\udcb0 $0.12 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 11.8s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 61.5s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 56.4s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 38.5s 27b_multi_container_logs \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 21.4s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 31.7s / \ud83d\udcb0 $0.20 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 27.3s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 76.7s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 37.5s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 22.7s 28_permissions_error \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 15.5s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 19.7s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 18.2s / \ud83d\udcb0 $0.06 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 40.2s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 29.7s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 25.3s 33_cpu_metrics_discovery \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 20.6s / \ud83d\udcb0 $0.13 \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 622.2s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 23.7s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 69.7s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 148.6s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 17.5s 39_failed_toolset \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 17.7s / \ud83d\udcb0 $0.03 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 45.2s / \ud83d\udcb0 $0.18 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 17.2s / \ud83d\udcb0 $0.02 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 147.5s / \ud83d\udcb0 $0.34 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 78.1s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 692.3s 41_setup_argo \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 14.9s / \ud83d\udcb0 $0.03 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 19.9s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 17.0s / \ud83d\udcb0 $0.03 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 70.2s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 37.5s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 140.8s 42_dns_issues_result_new_tools_no_runbook \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 27.0s / \ud83d\udcb0 $0.23 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 80.7s / \ud83d\udcb0 $0.53 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 39.4s / \ud83d\udcb0 $0.29 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 166.8s / \ud83d\udcb0 $0.28 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 111.3s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 105.4s 42_dns_issues_steps_new_tools \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 46.1s / \ud83d\udcb0 $0.26 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 100.8s / \ud83d\udcb0 $0.33 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 51.7s / \ud83d\udcb0 $0.23 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 260.1s / \ud83d\udcb0 $0.22 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 109.7s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 105.5s 43_current_datetime_from_prompt \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 15.2s / \ud83d\udcb0 $0.03 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 14.8s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 16.5s / \ud83d\udcb0 $0.04 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 29.8s / \ud83d\udcb0 $0.02 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 26.1s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 22.3s 43_slack_deployment_logs \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 44_slack_statefulset_logs \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 45_fetch_deployment_logs_simple \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 42.0s / \ud83d\udcb0 $0.40 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 31.2s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 24.5s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 652.0s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 55.6s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 24.3s 48_logs_since_thursday \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 50_logs_since_specific_date \ud83d\udd17 \u26aa\ufe0f - \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 23.6s / \ud83d\udcb0 $0.12 \u26aa\ufe0f - \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 41.4s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 37.8s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 14.7s 50a_logs_since_last_specific_month \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 24.4s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 38.9s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 20.0s / \ud83d\udcb0 $0.05 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 90.4s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 84.0s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 17.2s 51_logs_summarize_errors \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 25.6s / \ud83d\udcb0 $0.16 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 33.8s / \ud83d\udcb0 $0.16 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 26.9s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 49.7s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 60.2s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 41.3s 52_logs_login_issues \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 27.6s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 45.2s / \ud83d\udcb0 $0.18 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 32.0s / \ud83d\udcb0 $0.14 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 26.7s / \ud83d\udcb0 $0.03 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 69.1s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 1100.6s 53_logs_find_term \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 28.1s / \ud83d\udcb0 $0.18 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 35.6s / \ud83d\udcb0 $0.19 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 25.4s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 52.1s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 60.0s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 26.3s 54_not_truncated_when_getting_pods \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 17.5s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 42.0s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 31.4s / \ud83d\udcb0 $0.13 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 770.4s / \ud83d\udcb0 $0.59 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 71.1s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 28.9s 55_kafka_runbook \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 57_wrong_namespace \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 23.2s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 33.2s / \ud83d\udcb0 $0.16 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 23.0s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 75.3s / \ud83d\udcb0 $0.16 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 52.2s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 654.0s 59_label_based_counting \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 19.7s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 21.9s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 21.2s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 27.7s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 34.7s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 22.2s 60_count_less_than \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 20.3s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 22.6s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 20.8s / \ud83d\udcb0 $0.06 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 29.4s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 60.8s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 20.2s 61_exact_match_counting \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 20.9s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 22.7s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 21.7s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 28.5s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 32.4s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 24.5s 62_fetch_error_logs_with_errors \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 25.6s / \ud83d\udcb0 $0.17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 31.8s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 24.5s / \ud83d\udcb0 $0.07 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 27.6s / \ud83d\udcb0 $0.03 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 41.8s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 38.5s 63_fetch_error_logs_no_errors \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 24.1s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 34.9s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 23.8s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 48.8s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 57.6s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 24.2s 64_keda_vs_hpa_confusion \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 15.0s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 61.9s / \ud83d\udcb0 $0.32 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 20.3s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 96.1s / \ud83d\udcb0 $0.21 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 68.2s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 21.0s 65_health_check_followup \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 26.7s / \ud83d\udcb0 $0.16 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 62.2s / \ud83d\udcb0 $0.41 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 33.9s / \ud83d\udcb0 $0.19 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 129.9s / \ud83d\udcb0 $0.31 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 89.4s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 188.2s 71_connection_pool_starvation \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 30.3s / \ud83d\udcb0 $0.20 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 47.1s / \ud83d\udcb0 $0.40 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 25.2s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 62.5s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 117.1s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 128.1s 73a_time_window_anomaly \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 29.9s / \ud83d\udcb0 $0.22 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 48.6s / \ud83d\udcb0 $0.23 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 30.9s / \ud83d\udcb0 $0.22 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 57.6s / \ud83d\udcb0 $0.16 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 62.2s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 28.9s 73b_time_window_anomaly \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 28.0s / \ud83d\udcb0 $0.17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 40.9s / \ud83d\udcb0 $0.37 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 31.9s / \ud83d\udcb0 $0.21 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 70.3s / \ud83d\udcb0 $0.16 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 59.1s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 30.3s 76_service_discovery_issue \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 42.4s / \ud83d\udcb0 $0.38 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 47.7s / \ud83d\udcb0 $0.23 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 164.0s / \ud83d\udcb0 $0.36 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 86.5s / \ud83d\udcb0 $0.17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 71.6s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 47.2s 77_liveness_probe_misconfiguration \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 20.0s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 49.1s / \ud83d\udcb0 $0.24 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 25.4s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 102.5s / \ud83d\udcb0 $0.25 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 77.9s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 34.7s 78a_missing_cpu_limits \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 22.3s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 36.6s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 27.2s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 92.4s / \ud83d\udcb0 $0.16 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 85.5s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 307.2s 78b_cpu_quota_exceeded \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 26.6s / \ud83d\udcb0 $0.23 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 49.4s / \ud83d\udcb0 $0.21 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 26.8s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 94.9s / \ud83d\udcb0 $0.23 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 82.9s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 39.9s 79_configmap_mount_issue \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 32.5s / \ud83d\udcb0 $0.23 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 37.6s / \ud83d\udcb0 $0.18 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 25.2s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 51.5s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 47.5s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 27.6s 80_pvc_storage_class_mismatch \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 32.3s / \ud83d\udcb0 $0.20 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 43.7s / \ud83d\udcb0 $0.20 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 30.7s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 104.7s / \ud83d\udcb0 $0.23 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 54.2s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 104.6s 81_service_account_permission_denied \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 26.0s / \ud83d\udcb0 $0.17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 53.9s / \ud83d\udcb0 $0.27 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 34.6s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 73.2s / \ud83d\udcb0 $0.26 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 103.4s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 30.6s 82_pod_anti_affinity_conflict \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 26.2s / \ud83d\udcb0 $0.18 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 60.0s / \ud83d\udcb0 $0.24 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 20.5s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 106.8s / \ud83d\udcb0 $0.19 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 103.4s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 43.4s 83_secret_not_found \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 31.3s / \ud83d\udcb0 $0.20 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 42.7s / \ud83d\udcb0 $0.20 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 22.7s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 752.3s / \ud83d\udcb0 $0.33 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 70.7s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 51.0s 84_network_policy_blocking_traffic \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 32.7s / \ud83d\udcb0 $0.24 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 60.2s / \ud83d\udcb0 $0.23 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 31.1s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 82.4s / \ud83d\udcb0 $0.17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 107.2s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 77.7s 85_hpa_not_scaling \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 22.9s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 43.4s / \ud83d\udcb0 $0.16 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 23.2s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 75.4s / \ud83d\udcb0 $0.17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 80.1s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 28.2s 86_configmap_like_but_secret \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 29.9s / \ud83d\udcb0 $0.20 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 42.6s / \ud83d\udcb0 $0.21 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 27.8s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 140.3s / \ud83d\udcb0 $0.28 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 85.7s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 46.6s 89_runbook_missing_cloudwatch \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 21.6s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 31.3s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 18.7s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 47.1s / \ud83d\udcb0 $0.04 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 56.7s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 101.1s 90_runbook_basic_selection \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 33.2s / \ud83d\udcb0 $0.20 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 118.3s / \ud83d\udcb0 $1.01 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 174.1s / \ud83d\udcb0 $0.66 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 247.8s / \ud83d\udcb0 $0.39 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 133.5s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 130.8s 91f_datadog_logs_historical_pod \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 14.9s / \ud83d\udcb0 $0.04 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 85.8s / \ud83d\udcb0 $0.30 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 31.8s / \ud83d\udcb0 $0.14 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 138.3s / \ud83d\udcb0 $0.21 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 74.6s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 150.4s 93_calling_datadog[0] \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 16.2s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 10.3s / \ud83d\udcb0 $0.27 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 7.1s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 29.1s / \ud83d\udcb0 $0.17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 30.9s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 17.9s 93_calling_datadog[1] \ud83d\udd17 \u26aa\ufe0f - \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 9.8s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 6.7s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 21.6s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 21.1s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 12.1s 93_calling_datadog[2] \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 14.8s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 10.1s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 5.5s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 25.8s / \ud83d\udcb0 $0.19 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 22.2s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 12.0s 93_events_since_specific_date \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 10.4s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 17.0s / \ud83d\udcb0 $0.17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 8.9s / \ud83d\udcb0 $0.06 \u26aa\ufe0f - \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 23.9s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 12.6s 94_runbook_transparency \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 28.8s / \ud83d\udcb0 $0.19 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 61.2s / \ud83d\udcb0 $0.29 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 30.6s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 810.0s / \ud83d\udcb0 $0.55 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 112.1s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 85.4s 96_no_matching_runbook \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 27.5s / \ud83d\udcb0 $0.19 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 72.9s / \ud83d\udcb0 $0.69 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 32.4s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 126.5s / \ud83d\udcb0 $0.20 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 84.9s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 15.1s 97_logs_clarification_needed \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 8.0s / \ud83d\udcb0 $0.03 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 35.1s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 15.3s / \ud83d\udcb0 $0.05 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 17.4s / \ud83d\udcb0 $0.02 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 142.2s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 81.3s 98_logs_transparency_default_time \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 99_logs_transparency_custom_time \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 22.5s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 33.8s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 21.5s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 37.0s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 59.6s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 34.2s <p>Results are automatically generated and updated weekly. View full traces and detailed analysis in Braintrust experiment: local-benchmark-20251012-151418.</p>"},{"location":"development/evaluations/reporting/","title":"Reporting with Braintrust","text":"<p>This guide explains how to use Braintrust to analyze evaluation results, debug failures, and compare model performance.</p>"},{"location":"development/evaluations/reporting/#overview","title":"Overview","text":"<p>Braintrust is a platform for tracking and analyzing LLM evaluations. HolmesGPT evals can be used without Braintrust but using Braintrust has a few advantages:</p> <ul> <li>We can track how Holmes perform over time</li> <li>It's easier to run and debug many evals with Braintrust over simpler pytests because Braintrust organises the different components of a HolmesGPT investigation like the input, tool calls, reasoning for scoring, etc.</li> </ul>"},{"location":"development/evaluations/reporting/#setting-up-braintrust","title":"Setting Up Braintrust","text":""},{"location":"development/evaluations/reporting/#1-create-account","title":"1. Create Account","text":"<ol> <li>Visit braintrust.dev</li> <li>Sign up for an account</li> <li>Create a new project (e.g., \"HolmesGPT\")</li> </ol>"},{"location":"development/evaluations/reporting/#2-get-api-key","title":"2. Get API Key","text":"<ol> <li>Click your profile icon (top right)</li> <li>Go to Settings \u2192 API Keys</li> <li>Generate a new API key</li> <li>Copy the key (starts with <code>sk-</code>)</li> </ol>"},{"location":"development/evaluations/reporting/#3-configure-environment","title":"3. Configure Environment","text":"<pre><code>export BRAINTRUST_API_KEY=sk-your-api-key-here\nexport BRAINTRUST_ORG=your-org-name\n</code></pre> <p>Note: Both <code>BRAINTRUST_API_KEY</code> and <code>BRAINTRUST_ORG</code> are required for Braintrust integration to work.</p>"},{"location":"development/evaluations/reporting/#running-evaluations-with-braintrust","title":"Running Evaluations with Braintrust","text":""},{"location":"development/evaluations/reporting/#basic-evaluation-run","title":"Basic Evaluation Run","text":"<pre><code>export BRAINTRUST_API_KEY=sk-your-key\nexport BRAINTRUST_ORG=your-org\n\n# Run all regression tests with Braintrust tracking\nRUN_LIVE=true poetry run pytest -m 'llm and easy' --no-cov\n\n# Run specific test with tracking\nRUN_LIVE=true poetry run pytest tests/llm/test_ask_holmes.py -k \"01_how_many_pods\"\n</code></pre>"},{"location":"development/evaluations/reporting/#named-experiment","title":"Named Experiment","text":"<pre><code>export BRAINTRUST_API_KEY=sk-your-key\nexport BRAINTRUST_ORG=your-org\n\n# Run with multiple iterations for reliable results\nRUN_LIVE=true ITERATIONS=10 EXPERIMENT_ID=baseline_gpt41 MODEL=gpt-4.1 poetry run pytest -m 'llm and easy' -n 10\n\n# Compare with different model\nRUN_LIVE=true ITERATIONS=10 EXPERIMENT_ID=claude4 MODEL=anthropic/claude-sonnet-4-20250514 CLASSIFIER_MODEL=gpt-4.1 poetry run pytest -m 'llm and easy' -n 10\n</code></pre>"},{"location":"development/evaluations/reporting/#key-environment-variables","title":"Key Environment Variables","text":"Variable Purpose <code>UPLOAD_DATASET</code> Sync test cases to Braintrust <code>EXPERIMENT_ID</code> Name your experiment run. This makes it easier to find and track in Braintrust's UI <code>MODEL</code> The LLM model for Holmes to use <code>CLASSIFIER_MODEL</code> The LLM model to use for scoring the answer (LLM as judge)"},{"location":"development/evaluations/reporting/#analyzing-evaluation-results","title":"Analyzing Evaluation Results","text":""},{"location":"development/evaluations/reporting/#output","title":"Output","text":"<p>The main Span of an evaluation will present the input (either the AlertManager issue or the user's question for Ask Holmes) as well as HolmesGPT's answer.</p> <p></p>"},{"location":"development/evaluations/reporting/#score-types","title":"Score Types","text":"<p>Correctness Score: - Measures accuracy of LLM responses - Values: 0 or 1 - Shows how well output matches expectations</p> <p></p>"},{"location":"development/evaluations/reporting/#debugging-failed-evaluations","title":"Debugging Failed Evaluations","text":""},{"location":"development/evaluations/reporting/#1-identify-failing-tests","title":"1. Identify Failing Tests","text":"<p>In the experiment view: - Sort by score (ascending) to see worst performers - Filter by specific score types - Look for patterns in failures</p>"},{"location":"development/evaluations/reporting/#2-examine-tool-call-traces","title":"2. Examine Tool Call Traces","text":"<p>Click on a failing test to see: - Input: The original prompt/question - Tool Calls: Which tools the LLM invoked - Tool Results: What data each tool returned - Output: The LLM's final response - Expected: What the test expected</p> <p></p>"},{"location":"development/evaluations/running-evals/","title":"HolmesGPT Evaluations","text":"<p>Evaluations are automated tests that measure HolmesGPT's accuracy on real-world scenarios.</p> <p>They are used to both catch regressions and measure the impact of new features.</p> <p>Example: pod crashloop eval.</p>"},{"location":"development/evaluations/running-evals/#eval-tags","title":"Eval Tags","text":"<p>Evals are tagged and grouped into categories. Two common tags are <code>easy</code> and <code>medium</code>:</p> <ul> <li><code>easy</code> - regression tests - scenarios that HolmesGPT passes today and must continue to pass after any change</li> <li><code>medium</code> - more challenging scenarios that push boundaries of what HolmesGPT can do</li> </ul> <p>Changes to HolmesGPT are good if they allow us to promote an eval from <code>easy</code> to <code>medium</code> without increasing latency by too much.</p>"},{"location":"development/evaluations/running-evals/#getting-started","title":"Getting Started","text":""},{"location":"development/evaluations/running-evals/#prerequisites","title":"Prerequisites","text":"<p>Install HolmesGPT python dependencies:</p> <pre><code>poetry install --with=dev\n</code></pre>"},{"location":"development/evaluations/running-evals/#quick-start-running-your-first-eval","title":"Quick Start: Running Your First Eval","text":"<p>Try running a single eval to understand how the system works. We'll use eval 80_pvc_storage_class_mismatch as an example:</p> <pre><code># Run eval #80 with Claude Sonnet 4.5 (this specific eval passes reliably with Sonnet 4.5)\nRUN_LIVE=true MODEL=anthropic/claude-sonnet-4-20250514 \\\n  CLASSIFIER_MODEL=gpt-4.1 \\\n  poetry run pytest tests/llm/test_ask_holmes.py -k \"80_pvc_storage_class_mismatch\"\n\n# Compare with GPT-4o (may not pass as reliably)\nRUN_LIVE=true MODEL=gpt-4o \\\n  poetry run pytest tests/llm/test_ask_holmes.py -k \"80_pvc_storage_class_mismatch\"\n\n# Compare with GPT-4.1 (may not pass as reliably)\nRUN_LIVE=true MODEL=gpt-4.1 \\\n  poetry run pytest tests/llm/test_ask_holmes.py -k \"80_pvc_storage_class_mismatch\"\n\n# Test multiple models at once to compare performance\nRUN_LIVE=true MODEL=gpt-4o,gpt-4.1,anthropic/claude-sonnet-4-20250514 \\\n  CLASSIFIER_MODEL=gpt-4.1 \\\n  poetry run pytest tests/llm/test_ask_holmes.py -k \"80_pvc_storage_class_mismatch\"\n</code></pre> <p>Note: This eval demonstrates how different models perform differently - Sonnet 4.5 passes this specific eval reliably while weaker models like GPT-4o and GPT-4.1 may struggle with this scenario.</p>"},{"location":"development/evaluations/running-evals/#running-full-benchmark-suite","title":"Running Full Benchmark Suite","text":"<p>Once you're comfortable running individual evals, you can run the full benchmark suite to test all important evals at once. The easiest way to do this locally is using the <code>run_benchmarks_local.sh</code> script, which mirrors the exact behavior of our CI/CD workflow:</p> <pre><code># Run with defaults (easy tests, default models, 1 iteration)\n./run_benchmarks_local.sh\n\n# Test specific models\n./run_benchmarks_local.sh 'gpt-4o,anthropic/claude-sonnet-4-20250514'\n\n# Run with custom markers and iterations\n./run_benchmarks_local.sh 'gpt-4o' 'easy and kubernetes' 3\n\n# Filter specific tests by name\n./run_benchmarks_local.sh 'gpt-4o' 'easy' 1 '01_how_many_pods'\n\n# Run with parallel workers for faster execution\n./run_benchmarks_local.sh 'gpt-4o' 'easy' 1 '' 6\n</code></pre>"},{"location":"development/evaluations/running-evals/#environment-variables","title":"Environment Variables","text":"<p>Essential variables for controlling test behavior:</p> Variable Purpose Example <code>RUN_LIVE</code> Use real tools instead of mocks <code>RUN_LIVE=true</code> <code>ITERATIONS</code> Run each test N times <code>ITERATIONS=10</code> <code>MODEL</code> LLM to test <code>MODEL=gpt-4.1</code> <code>CLASSIFIER_MODEL</code> LLM for scoring (needed for Anthropic) <code>CLASSIFIER_MODEL=gpt-4.1</code>"},{"location":"development/evaluations/running-evals/#advanced-usage","title":"Advanced Usage","text":""},{"location":"development/evaluations/running-evals/#selecting-which-evals-to-run","title":"Selecting Which Evals to Run","text":"<p>For more control over which evals to run, you can use pytest directly with markers (tags) or test name patterns:</p> <pre><code># Run all easy evals (regression tests - should always pass)\nRUN_LIVE=true poetry run pytest -m 'llm and easy' --no-cov\n\n# Run challenging tests\nRUN_LIVE=true poetry run pytest -m 'llm and medium' --no-cov\n\n# Run evals with a specific tag (e.g., tests involving logs)\nRUN_LIVE=true poetry run pytest -m \"llm and logs\" --no-cov\n\n# Run a specific eval by name\nRUN_LIVE=true poetry run pytest tests/llm/test_ask_holmes.py -k \"01_how_many_pods\"\n</code></pre> <p>Available markers: See <code>pyproject.toml</code> for all available markers. Common ones include: - <code>easy</code> - Regression tests that should always pass - <code>medium</code> - More challenging scenarios - <code>logs</code> - Tests involving log analysis - <code>kubernetes</code> - Kubernetes-specific tests</p>"},{"location":"development/evaluations/running-evals/#testing-different-models","title":"Testing Different Models","text":"<p>The <code>MODEL</code> environment variable is equivalent to the <code>--model</code> flag on the <code>holmes ask</code> CLI command. You can test HolmesGPT with different LLM providers:</p> <pre><code># Test with GPT-4.1 (default)\nRUN_LIVE=true MODEL=gpt-4.1 poetry run pytest -m 'llm and easy'\n\n# Test with Claude\n# Note: CLASSIFIER_MODEL must be set to OpenAI or Azure as Anthropic models are not currently supported for classification\nRUN_LIVE=true MODEL=anthropic/claude-opus-4-1-20250805 CLASSIFIER_MODEL=gpt-4.1 poetry run pytest -m 'llm and easy'\n\n# Test with Azure OpenAI\n# Set required Azure environment variables for your deployment\nexport AZURE_API_KEY=your-azure-api-key\nexport AZURE_API_BASE=https://your-deployment.openai.azure.com/\nexport AZURE_API_VERSION=2024-02-15-preview\nRUN_LIVE=true MODEL=azure/your-deployment-name CLASSIFIER_MODEL=azure/your-deployment-name poetry run pytest -m 'llm and easy'\n</code></pre> <p>Important Notes:</p> <ul> <li>When using Anthropic models, you must set <code>CLASSIFIER_MODEL</code> to an OpenAI or Azure model because the evaluation framework's classifier currently only supports these providers</li> <li>For any model provider, ensure you have the necessary API keys and environment variables set (e.g., <code>OPENAI_API_KEY</code>, <code>ANTHROPIC_API_KEY</code>, <code>AZURE_API_KEY</code>)</li> <li>The model specified here is passed directly to LiteLLM, so any model supported by LiteLLM can be used</li> </ul>"},{"location":"development/evaluations/running-evals/#multi-model-benchmarking","title":"Multi-Model Benchmarking","text":"<p>HolmesGPT supports running evaluations across multiple models simultaneously to compare their performance:</p> <pre><code># Test multiple models in a single run\n# Models are specified as comma-separated list\nRUN_LIVE=true MODEL=gpt-4o,anthropic/claude-sonnet-4-20250514 \\\n  CLASSIFIER_MODEL=gpt-4o \\\n  poetry run pytest -m 'llm and easy' --no-cov\n# Run with multiple iterations for statistically significant results\nRUN_LIVE=true ITERATIONS=10 \\\n  MODEL=gpt-4o,anthropic/claude-sonnet-4-20250514 \\\n  CLASSIFIER_MODEL=gpt-4o \\\n  poetry run pytest -m 'llm and easy' -n 10\n\n# Test specific scenario across models\nRUN_LIVE=true MODEL=gpt-4o,gpt-4o-mini \\\n  poetry run pytest tests/llm/test_ask_holmes.py -k \"01_how_many_pods\"\n</code></pre> <p>When running multi-model benchmarks: - Results will show a Model Comparison Table with side-by-side performance metrics - Each model's pass rate, execution times, and P90 percentiles are displayed - Tests are parameterized by model, so you'll see separate results for each model/test combination - Use <code>CLASSIFIER_MODEL</code> to ensure consistent scoring across all models</p>"},{"location":"development/evaluations/running-evals/#running-evals-with-multiple-iterations","title":"Running Evals with Multiple Iterations","text":"<p>LLMs are non-deterministic - they produce different outputs for the same input. 10 iterations is a good rule of thumb for reliable results.</p> <pre><code># Recommended: Run with multiple iterations\nRUN_LIVE=true ITERATIONS=10 poetry run pytest -m 'llm and easy' --no-cov\n\n# Quick check: Single run (less reliable)\nRUN_LIVE=true poetry run pytest -m 'llm and easy' --no-cov\n</code></pre>"},{"location":"development/evaluations/running-evals/#using-run_livetrue-vs-mock-data","title":"Using RUN_LIVE=true vs Mock Data","text":"<p>Some evals support mock-data and don't need a live Kubernetes cluster to run. However, for the most accurate evaluation you should set <code>RUN_LIVE=true</code> which tests HolmesGPT with a live Kubernetes cluster not mock data.</p> <p>This is important because LLMs can take multiple paths to reach conclusions, and mock data only captures one path.</p>"},{"location":"development/evaluations/running-evals/#parallel-execution","title":"Parallel Execution","text":"<p>Speed up test runs with parallel workers:</p> <pre><code># Run with 10 parallel workers\nRUN_LIVE=true ITERATIONS=10 poetry run pytest tests/llm/ -n 10\n</code></pre>"},{"location":"development/evaluations/running-evals/#debugging-failed-tests","title":"Debugging Failed Tests","text":"<p>When tests fail, use these techniques to investigate:</p> <p>CLI Flags for Debugging:</p> <ul> <li><code>--skip-setup</code>: Skip <code>before_test</code> commands (useful when resources already exist)</li> <li><code>--skip-cleanup</code>: Skip <code>after_test</code> commands (useful for inspecting resources after test)</li> <li><code>--only-setup</code>: Only run <code>before_test</code> commands, skip test execution</li> <li><code>--only-cleanup</code>: Only run <code>after_test</code> commands, skip setup and test execution</li> </ul> <pre><code># 1. Verbose output to see details\nRUN_LIVE=true pytest -vv -s tests/llm/test_ask_holmes.py -k \"failing_test\"\n\n# 2. Keep resources after test for inspection\nRUN_LIVE=true pytest -k \"test\" --skip-cleanup\n\n# 3. Iterate quickly without setup/cleanup\nRUN_LIVE=true pytest -k \"test\" --skip-setup --skip-cleanup\n\n# 4. Clean up when done debugging\nRUN_LIVE=true pytest -k \"test\" --skip-setup\n\n# 5. Or just run cleanup without the test\nRUN_LIVE=true pytest -k \"test\" --only-cleanup\n\n# 6. Test only setup commands without running the actual test\nRUN_LIVE=true pytest -k \"test\" --only-setup\n</code></pre>"},{"location":"development/evaluations/running-evals/#model-comparison-workflow","title":"Model Comparison Workflow","text":""},{"location":"development/evaluations/running-evals/#recommended-multi-model-testing-single-run","title":"Recommended: Multi-Model Testing (Single Run)","text":"<p>Use the <code>MODEL</code> environment variable to test multiple models in a single run:</p> <pre><code># Compare multiple models simultaneously - RECOMMENDED approach\nRUN_LIVE=true ITERATIONS=10 \\\n  MODEL=gpt-4.1,anthropic/claude-sonnet-4-20250514 \\\n  CLASSIFIER_MODEL=gpt-4.1 \\\n  poetry run pytest -m 'llm and easy' -n 10\n\n# This will generate a comparison table showing:\n# - Side-by-side pass rates for each model\n# - Execution time comparisons\n# - Cost comparisons\n# - Best performing models summary\n</code></pre>"},{"location":"development/evaluations/running-evals/#alternative-single-model-testing-separate-runs","title":"Alternative: Single-Model Testing (Separate Runs)","text":"<p>For cases where you need separate experiments or different configurations per model:</p> <pre><code># Run separate experiments for each model\n# Useful when you need different settings or want to track experiments separately\n\n# 1. Baseline with GPT-4\nRUN_LIVE=true ITERATIONS=10 EXPERIMENT_ID=baseline_gpt4.1 MODEL=gpt-4.1 pytest -n 10 tests/llm/\n\n# 2. Compare with Claude (using GPT-4 as classifier since Anthropic models can't classify)\nRUN_LIVE=true ITERATIONS=10 EXPERIMENT_ID=claude4 MODEL=anthropic/claude-sonnet-4-20250514 CLASSIFIER_MODEL=gpt-4.1 pytest -n 10 tests/llm/\n</code></pre>"},{"location":"development/evaluations/running-evals/#braintrust-integration","title":"Braintrust Integration","text":"<p>Results are automatically tracked if Braintrust is configured:</p> <pre><code># Set these once in your environment\nexport BRAINTRUST_API_KEY=your-key\nexport BRAINTRUST_ORG=your-org\n\n# Then run any evaluation command - results will be tracked automatically\nRUN_LIVE=true MODEL=gpt-4o,anthropic/claude-sonnet-4-20250514 pytest -m 'llm and easy'\n</code></pre>"},{"location":"development/evaluations/history/","title":"Historical Evaluation Results","text":"<p>Browse through our past benchmark runs to track performance trends over time.</p>"},{"location":"development/evaluations/history/#weekly-results","title":"Weekly Results","text":"<p>Regular weekly benchmark runs that track model performance over time.</p>"},{"location":"development/evaluations/history/#extended-comparisons","title":"Extended Comparisons","text":"<p>Special benchmark runs comparing multiple models and configurations.</p>"},{"location":"development/evaluations/history/custom_claude_results_20250930_153753/","title":"Claude 4.0 vs 4.5 (n=5)","text":"<p>Generated: 2025-09-30 15:37 UTC</p> <p>Total Duration: 6h 16m 42s</p> <p>Iterations: 5</p> <p>Judge (classifier) model: gpt-4o</p>"},{"location":"development/evaluations/history/custom_claude_results_20250930_153753/#about-this-benchmark","title":"About this Benchmark","text":"<p>HolmesGPT is continuously evaluated against real-world Kubernetes and cloud troubleshooting scenarios.</p> <p>If you find scenarios that HolmesGPT does not perform well on, please consider adding them as evals to the benchmark.</p>"},{"location":"development/evaluations/history/custom_claude_results_20250930_153753/#model-accuracy-comparison","title":"Model Accuracy Comparison","text":"Model Pass Fail Skip/Error Total Success Rate gpt-4o 295 174 56 525 \ud83d\udfe1 63% (295/469) gpt-4.1 346 122 57 525 \ud83d\udfe1 74% (346/468) gpt-5 360 104 61 525 \ud83d\udfe1 78% (360/464) sonnet-4-20250514 419 51 55 525 \ud83d\udfe1 89% (419/470) sonnet-4-5-20250929 420 50 55 525 \ud83d\udfe1 89% (420/470)"},{"location":"development/evaluations/history/custom_claude_results_20250930_153753/#model-cost-comparison","title":"Model Cost Comparison","text":"Model Tests Avg Cost Min Cost Max Cost Total Cost gpt-4o 468 $0.14 $0.01 $0.85 $64.90 gpt-4.1 468 $0.11 $0.02 $1.07 $52.00 gpt-5 464 $0.13 $0.02 $0.58 $61.76 sonnet-4-20250514 468 $0.17 $0.06 $1.05 $80.54 sonnet-4-5-20250929 467 $0.16 $0.06 $0.64 $75.56"},{"location":"development/evaluations/history/custom_claude_results_20250930_153753/#model-latency-comparison","title":"Model Latency Comparison","text":"Model Avg (s) Min (s) Max (s) P50 (s) P95 (s) gpt-4o 49.0 8.9 278.2 43.5 94.7 gpt-4.1 53.8 5.2 236.8 48.2 109.3 gpt-5 190.3 22.5 1136.0 158.1 442.5 sonnet-4-20250514 89.6 10.4 879.7 64.8 231.5 sonnet-4-5-20250929 73.0 10.6 663.3 60.0 154.6"},{"location":"development/evaluations/history/custom_claude_results_20250930_153753/#performance-by-tag","title":"Performance by Tag","text":"<p>Success rate by test category and models:</p> Tag gpt-4o gpt-4.1 gpt-5 sonnet-4-20250514 sonnet-4-5-20250929 Warnings chain-of-causation \ud83d\udd34 0% (0/30) \ud83d\udfe1 3% (1/30) \ud83d\udfe1 40% (12/30) \ud83d\udfe1 63% (19/30) \ud83d\udfe1 70% (21/30) \u26a0\ufe0f 50 skipped context_window \ud83d\udfe1 57% (20/35) \ud83d\udfe1 77% (27/35) \ud83d\udfe1 83% (29/35) \ud83d\udfe1 86% (30/35) \ud83d\udfe1 77% (27/35) counting \ud83d\udfe2 100% (20/20) \ud83d\udfe2 100% (20/20) \ud83d\udfe1 95% (19/20) \ud83d\udfe2 100% (20/20) \ud83d\udfe2 100% (20/20) database \ud83d\udd34 0% (0/5) \ud83d\udfe1 60% (\u2157) \ud83d\udfe2 100% (5/5) \ud83d\udfe2 100% (5/5) \ud83d\udfe2 100% (5/5) \u26a0\ufe0f 75 skipped datadog \ud83d\udfe1 75% (15/20) \ud83d\udfe1 80% (16/20) \ud83d\udfe1 95% (18/19) \ud83d\udfe2 100% (20/20) \ud83d\udfe2 100% (20/20) \u26a0\ufe0f 1 skipped datetime \ud83d\udfe1 65% (13/20) \ud83d\udfe1 65% (13/20) \ud83d\udfe1 95% (19/20) \ud83d\udfe1 75% (15/20) \ud83d\udfe1 85% (17/20) \u26a0\ufe0f 50 skipped easy \ud83d\udfe1 97% (175/180) \ud83d\udfe1 96% (173/180) \ud83d\udfe1 80% (144/179) \ud83d\udfe1 97% (174/180) \ud83d\udfe1 96% (172/180) \u26a0\ufe0f 1 skipped hard \ud83d\udfe1 11% (8/70) \ud83d\udfe1 29% (20/70) \ud83d\udfe1 57% (40/70) \ud83d\udfe1 77% (54/70) \ud83d\udfe1 80% (56/70) \u26a0\ufe0f 150 skipped kafka \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26a0\ufe0f 50 skipped kubernetes \ud83d\udfe1 55% (129/235) \ud83d\udfe1 71% (168/235) \ud83d\udfe1 69% (163/235) \ud83d\udfe1 89% (208/235) \ud83d\udfe1 87% (205/235) \u26a0\ufe0f 25 skipped logs \ud83d\udfe1 62% (80/130) \ud83d\udfe1 67% (87/129) \ud83d\udfe1 77% (100/130) \ud83d\udfe1 75% (98/130) \ud83d\udfe1 82% (106/130) \u26a0\ufe0f 176 skipped medium \ud83d\udfe1 51% (112/219) \ud83d\udfe1 70% (153/218) \ud83d\udfe1 82% (176/215) \ud83d\udfe1 87% (191/220) \ud83d\udfe1 87% (192/220) \u26a0\ufe0f 133 skipped network \ud83d\udfe1 45% (9/20) \ud83d\udfe1 60% (12/20) \ud83d\udfe1 85% (17/20) \ud83d\udfe2 100% (20/20) \ud83d\udfe2 100% (20/20) numerical \ud83d\udfe2 100% (5/5) \ud83d\udfe2 100% (5/5) \ud83d\udfe2 100% (5/5) \ud83d\udfe2 100% (5/5) \ud83d\udfe2 100% (5/5) port-forward \ud83d\udfe1 29% (13/45) \ud83d\udfe1 44% (20/45) \ud83d\udfe1 53% (24/45) \ud83d\udfe1 49% (22/45) \ud83d\udfe1 42% (19/45) prometheus \ud83d\udfe1 65% (13/20) \ud83d\udfe1 95% (19/20) \ud83d\udfe2 100% (20/20) \ud83d\udfe2 100% (20/20) \ud83d\udfe1 80% (16/20) question-answer \ud83d\udfe2 100% (20/20) \ud83d\udfe2 100% (20/20) \ud83d\udfe1 95% (19/20) \ud83d\udfe2 100% (20/20) \ud83d\udfe2 100% (20/20) runbooks \ud83d\udfe1 73% (22/30) \ud83d\udfe1 73% (22/30) \ud83d\udfe1 93% (28/30) \ud83d\udfe2 100% (30/30) \ud83d\udfe1 97% (29/30) \u26a0\ufe0f 25 skipped slackbot \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26a0\ufe0f 25 skipped traces \ud83d\udd34 0% (0/25) \ud83d\udfe1 4% (1/25) \ud83d\udfe1 40% (10/25) \ud83d\udfe1 56% (14/25) \ud83d\udfe1 64% (16/25) transparency \ud83d\udfe1 71% (50/70) \ud83d\udfe1 71% (50/70) \ud83d\udfe1 84% (59/70) \ud83d\udfe1 81% (57/70) \ud83d\udfe1 84% (59/70) \u26a0\ufe0f 25 skipped Overall \ud83d\udfe1 63% (295/469) \ud83d\udfe1 74% (346/468) \ud83d\udfe1 78% (360/464) \ud83d\udfe1 89% (419/470) \ud83d\udfe1 89% (420/470) \u26a0\ufe0f 284 skipped"},{"location":"development/evaluations/history/custom_claude_results_20250930_153753/#raw-results","title":"Raw Results","text":"<p>Status of all evaluations across models. Color coding:</p> <ul> <li>\ud83d\udfe2 Passing 100% (stable)</li> <li>\ud83d\udfe1 Passing 1-99%</li> <li>\ud83d\udd34 Passing 0% (failing)</li> <li>\ud83d\udd27 Mock data failure (missing or invalid test data)</li> <li>\u26a0\ufe0f Setup failure (environment/infrastructure issue)</li> <li>\u23f1\ufe0f Timeout or rate limit error</li> <li>\u23ed\ufe0f Test skipped (e.g., known issue or precondition not met)</li> </ul> Eval ID gpt-4o gpt-4.1 gpt-5 sonnet-4-20250514 sonnet-4-5-20250929 01_how_many_pods \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 02_what_is_wrong_with_pod \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 03_what_is_the_command_to_port_forward \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 04_related_k8s_events \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe1 \ud83d\udfe2 \ud83d\udfe2 05_image_version \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe1 \ud83d\udfe2 \ud83d\udfe2 09_crashpod \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe1 \ud83d\udfe2 \ud83d\udfe2 100a_historical_logs \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 100b_historical_logs_nonstandard_label \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 101_historical_logs_pod_deleted \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 103_logs_transparency_default_limit \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 104a_postgres_root_issue \ud83d\udd17 \ud83d\udd34 \ud83d\udfe1 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 107_log_filter_http_status_code \ud83d\udd17 \ud83d\udfe1 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 108_logs_nearby_lines \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe1 \ud83d\udfe1 \ud83d\udd34 109_logs_transparency_not_found \ud83d\udd17 \ud83d\udfe1 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 10_image_pull_backoff \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe1 \ud83d\udfe2 \ud83d\udfe2 110_k8s_events_image_pull \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 111_disabled_datadog_traces \ud83d\udd17 \ud83d\udd34 \ud83d\udfe1 \ud83d\udfe1 \ud83d\udfe2 \ud83d\udfe2 111_pod_names_contain_service \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe1 \ud83d\udfe2 \ud83d\udfe2 112_find_pvcs_by_uuid \ud83d\udd17 \ud83d\udd34 \ud83d\udfe1 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 114_checkout_latency_tracing_rebuild[0] \ud83d\udd17 \ud83d\udd34 \ud83d\udfe1 \ud83d\udfe1 \ud83d\udfe1 \ud83d\udfe1 115_checkout_errors_tracing[0] \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe1 \ud83d\udfe1 \ud83d\udfe1 11_init_containers \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe1 \ud83d\udfe2 \ud83d\udfe2 121_new_relic_checkout_errors_tracing[0] \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe1 \ud83d\udfe1 \ud83d\udfe1 122_new_relic_checkout_latency_tracing_rebuild[0] \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe1 \ud83d\udfe2 \ud83d\udfe2 123_new_relic_checkout_errors_tracing[0] \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe1 \ud83d\udfe2 \ud83d\udfe2 12_job_crashing \ud83d\udd17 \ud83d\udfe1 \ud83d\udfe2 \ud83d\udfe1 \ud83d\udfe2 \ud83d\udfe2 13a_pending_node_selector_basic \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe1 \ud83d\udfe2 \ud83d\udfe1 13b_pending_node_selector_detailed \ud83d\udd17 \ud83d\udd34 \ud83d\udfe1 \ud83d\udfe1 \ud83d\udfe2 \ud83d\udfe2 14_pending_resources \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe1 \ud83d\udfe2 \ud83d\udfe2 159_prometheus_high_cardinality_cpu[0] \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 159_prometheus_high_cardinality_cpu[1] \ud83d\udd17 \ud83d\udfe1 \ud83d\udfe1 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 159_prometheus_high_cardinality_cpu[2] \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe1 15_failed_readiness_probe \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe1 \ud83d\udfe2 \ud83d\udfe2 16_failed_no_toolset_found \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe1 \ud83d\udd34 17_oom_kill \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe1 \ud83d\udfe2 \ud83d\udfe2 19_detect_missing_app_details \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe1 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 20_long_log_file_search \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 21_job_fail_curl_no_svc_account \ud83d\udd17 \ud83d\udfe1 \ud83d\udfe2 \ud83d\udfe1 \ud83d\udfe2 \ud83d\udfe2 23_app_error_in_current_logs \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe1 \ud83d\udfe2 24_misconfigured_pvc \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 24a_misconfigured_pvc_basic \ud83d\udd17 \ud83d\udfe1 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 24b_misconfigured_pvc_detailed \ud83d\udd17 \ud83d\udd34 \ud83d\udfe1 \ud83d\udfe1 \ud83d\udfe2 \ud83d\udfe2 25_misconfigured_ingress_class \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe1 \ud83d\udfe2 \ud83d\udfe2 26_page_render_times \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 27a_multi_container_logs \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 27b_multi_container_logs \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe1 \ud83d\udfe1 \ud83d\udfe2 \ud83d\udfe2 28_permissions_error \ud83d\udd17 \ud83d\udfe1 \ud83d\udfe1 \ud83d\udfe1 \ud83d\udd34 \ud83d\udd34 33_cpu_metrics_discovery \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 39_failed_toolset \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe1 \ud83d\udfe1 \ud83d\udfe1 \ud83d\udfe2 41_setup_argo \ud83d\udd17 \ud83d\udfe1 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 42_dns_issues_result_new_tools_no_runbook \ud83d\udd17 \ud83d\udfe1 \ud83d\udfe1 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 42_dns_issues_steps_new_tools \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 43_current_datetime_from_prompt \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 45_fetch_deployment_logs_simple \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 50a_logs_since_last_specific_month \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 51_logs_summarize_errors \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 52_logs_login_issues \ud83d\udd17 \ud83d\udfe1 \ud83d\udfe2 \ud83d\udfe1 \ud83d\udfe2 \ud83d\udfe2 53_logs_find_term \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 54_not_truncated_when_getting_pods \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe1 \ud83d\udfe2 \ud83d\udfe1 57_wrong_namespace \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe1 \ud83d\udfe2 59_label_based_counting \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 60_count_less_than \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe1 \ud83d\udfe2 \ud83d\udfe2 61_exact_match_counting \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 62_fetch_error_logs_with_errors \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe1 \ud83d\udfe2 \ud83d\udfe2 63_fetch_error_logs_no_errors \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe1 \ud83d\udfe2 \ud83d\udfe1 64_keda_vs_hpa_confusion \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe1 \ud83d\udfe2 \ud83d\udfe2 65_health_check_followup \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe1 \ud83d\udfe2 \ud83d\udfe2 71_connection_pool_starvation \ud83d\udd17 \ud83d\udfe1 \ud83d\udfe2 \ud83d\udfe1 \ud83d\udfe2 \ud83d\udfe2 73a_time_window_anomaly \ud83d\udd17 \ud83d\udd34 \ud83d\udfe1 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe1 73b_time_window_anomaly \ud83d\udd17 \ud83d\udfe1 \ud83d\udfe1 \ud83d\udfe1 \ud83d\udfe2 \ud83d\udfe2 76_service_discovery_issue \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 77_liveness_probe_misconfiguration \ud83d\udd17 \ud83d\udfe1 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 78a_missing_cpu_limits \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 78b_cpu_quota_exceeded \ud83d\udd17 \ud83d\udd34 \ud83d\udfe1 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 79_configmap_mount_issue \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 80_pvc_storage_class_mismatch \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 81_service_account_permission_denied \ud83d\udd17 \ud83d\udfe1 \ud83d\udfe1 \ud83d\udfe1 \ud83d\udfe2 \ud83d\udfe2 82_pod_anti_affinity_conflict \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 83_secret_not_found \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 84_network_policy_blocking_traffic \ud83d\udd17 \ud83d\udfe1 \ud83d\udfe1 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 85_hpa_not_scaling \ud83d\udd17 \ud83d\udd34 \ud83d\udfe1 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 86_configmap_like_but_secret \ud83d\udd17 \ud83d\udfe1 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 89_runbook_missing_cloudwatch \ud83d\udd17 \ud83d\udfe1 \ud83d\udfe1 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 90_runbook_basic_selection \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe1 91f_datadog_logs_historical_pod \ud83d\udd17 \ud83d\udd34 \ud83d\udfe1 \ud83d\udfe1 \ud83d\udfe2 \ud83d\udfe2 93_calling_datadog[0] \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 93_calling_datadog[1] \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 94_runbook_transparency \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 96_no_matching_runbook \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe1 \ud83d\udfe2 \ud83d\udfe2 97_logs_clarification_needed \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 99_logs_transparency_custom_time \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 50_logs_since_specific_date \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 93_calling_datadog[2] \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 93_events_since_specific_date \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd27 \ud83d\udfe2 \ud83d\udfe2 44_slack_statefulset_logs \ud83d\udd17 \ud83d\udd27 \ud83d\udd27 \ud83d\udd27 \ud83d\udd27 \ud83d\udd27 48_logs_since_thursday \ud83d\udd17 \ud83d\udd27 \ud83d\udd27 \ud83d\udd27 \ud83d\udd27 \ud83d\udd27 22_high_latency_dbi_down \ud83d\udd17 \u26a0\ufe0f \u26a0\ufe0f \u26a0\ufe0f \u26a0\ufe0f \u26a0\ufe0f 08_sock_shop_frontend \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 104b_postgres_missing_index_pgstat \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 104c_postgres_minimal_missing_index \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 105_redis_wrong_data_structure \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 156_kafka_opensearch_latency \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 43_slack_deployment_logs \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 55_kafka_runbook \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 98_logs_transparency_default_time \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f SUMMARY \ud83d\udfe1 63% (295/469) \ud83d\udfe1 74% (346/468) \ud83d\udfe1 78% (360/464) \ud83d\udfe1 89% (419/470) \ud83d\udfe1 89% (420/470)"},{"location":"development/evaluations/history/custom_claude_results_20250930_153753/#detailed-raw-results","title":"Detailed Raw Results","text":"Eval ID gpt-4o gpt-4.1 gpt-5 sonnet-4-20250514 sonnet-4-5-20250929 01_how_many_pods \ud83d\udd17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 31.3s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 33.2s / \ud83d\udcb0 $0.05 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 43.4s / \ud83d\udcb0 $0.04 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 34.3s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 33.6s / \ud83d\udcb0 $0.08 02_what_is_wrong_with_pod \ud83d\udd17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 42.9s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 38.7s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 123.9s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 53.5s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 67.5s / \ud83d\udcb0 $0.10 03_what_is_the_command_to_port_forward \ud83d\udd17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 61.2s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 53.7s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 68.9s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 43.0s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 51.9s / \ud83d\udcb0 $0.09 04_related_k8s_events \ud83d\udd17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 39.4s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 38.7s / \ud83d\udcb0 $0.06 \ud83d\udfe1 80% (\u2158) / \u23f1\ufe0f 69.1s / \ud83d\udcb0 $0.05 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 58.8s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 62.4s / \ud83d\udcb0 $0.09 05_image_version \ud83d\udd17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 43.6s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 56.3s / \ud83d\udcb0 $0.07 \ud83d\udfe1 80% (\u2158) / \u23f1\ufe0f 73.8s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 37.0s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 38.1s / \ud83d\udcb0 $0.09 09_crashpod \ud83d\udd17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 43.0s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 37.3s / \ud83d\udcb0 $0.06 \ud83d\udfe1 80% (\u2158) / \u23f1\ufe0f 92.4s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 73.0s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 64.8s / \ud83d\udcb0 $0.14 100a_historical_logs \ud83d\udd17 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 52.3s / \ud83d\udcb0 $0.12 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 54.8s / \ud83d\udcb0 $0.07 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 500.6s / \ud83d\udcb0 $0.29 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 116.2s / \ud83d\udcb0 $0.27 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 98.0s / \ud83d\udcb0 $0.19 100b_historical_logs_nonstandard_label \ud83d\udd17 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 50.9s / \ud83d\udcb0 $0.11 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 57.5s / \ud83d\udcb0 $0.07 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 363.3s / \ud83d\udcb0 $0.22 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 157.0s / \ud83d\udcb0 $0.18 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 102.9s / \ud83d\udcb0 $0.17 101_historical_logs_pod_deleted \ud83d\udd17 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 53.2s / \ud83d\udcb0 $0.12 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 53.8s / \ud83d\udcb0 $0.08 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 268.6s / \ud83d\udcb0 $0.16 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 97.5s / \ud83d\udcb0 $0.16 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 85.9s / \ud83d\udcb0 $0.15 103_logs_transparency_default_limit \ud83d\udd17 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 63.1s / \ud83d\udcb0 $0.15 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 105.8s / \ud83d\udcb0 $0.39 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 137.1s / \ud83d\udcb0 $0.09 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 81.0s / \ud83d\udcb0 $0.41 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 74.6s / \ud83d\udcb0 $0.12 104a_postgres_root_issue \ud83d\udd17 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 48.3s / \ud83d\udcb0 $0.18 \ud83d\udfe1 60% (\u2157) / \u23f1\ufe0f 85.6s / \ud83d\udcb0 $0.35 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 233.2s / \ud83d\udcb0 $0.21 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 71.9s / \ud83d\udcb0 $0.19 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 106.0s / \ud83d\udcb0 $0.24 107_log_filter_http_status_code \ud83d\udd17 \ud83d\udfe1 40% (\u2156) / \u23f1\ufe0f 54.0s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 57.4s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 472.2s / \ud83d\udcb0 $0.30 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 127.5s / \ud83d\udcb0 $0.22 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 100.3s / \ud83d\udcb0 $0.24 108_logs_nearby_lines \ud83d\udd17 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 64.2s / \ud83d\udcb0 $0.17 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 57.6s / \ud83d\udcb0 $0.23 \ud83d\udfe1 40% (\u2156) / \u23f1\ufe0f 345.4s / \ud83d\udcb0 $0.26 \ud83d\udfe1 20% (\u2155) / \u23f1\ufe0f 111.3s / \ud83d\udcb0 $0.36 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 89.7s / \ud83d\udcb0 $0.22 109_logs_transparency_not_found \ud83d\udd17 \ud83d\udfe1 80% (\u2158) / \u23f1\ufe0f 47.2s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 44.5s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 135.7s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 44.4s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 48.1s / \ud83d\udcb0 $0.10 10_image_pull_backoff \ud83d\udd17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 47.3s / \ud83d\udcb0 $0.18 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 55.9s / \ud83d\udcb0 $0.10 \ud83d\udfe1 60% (\u2157) / \u23f1\ufe0f 99.9s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 59.4s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 60.0s / \ud83d\udcb0 $0.13 110_k8s_events_image_pull \ud83d\udd17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 34.7s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 42.4s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 100.1s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 72.1s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 53.4s / \ud83d\udcb0 $0.10 111_disabled_datadog_traces \ud83d\udd17 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 40.5s / \ud83d\udcb0 $0.03 \ud83d\udfe1 60% (\u2157) / \u23f1\ufe0f 39.6s / \ud83d\udcb0 $0.03 \ud83d\udfe1 80% (\u2158) / \u23f1\ufe0f 235.0s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 87.4s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 44.8s / \ud83d\udcb0 $0.06 111_pod_names_contain_service \ud83d\udd17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 71.3s / \ud83d\udcb0 $0.16 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 68.3s / \ud83d\udcb0 $0.10 \ud83d\udfe1 40% (\u2156) / \u23f1\ufe0f 210.5s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 77.3s / \ud83d\udcb0 $0.20 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 66.9s / \ud83d\udcb0 $0.16 112_find_pvcs_by_uuid \ud83d\udd17 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 45.8s / \ud83d\udcb0 $0.12 \ud83d\udfe1 20% (\u2155) / \u23f1\ufe0f 58.2s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 147.8s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 67.5s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 88.6s / \ud83d\udcb0 $0.13 114_checkout_latency_tracing_rebuild[0] \ud83d\udd17 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 69.7s / \ud83d\udcb0 $0.20 \ud83d\udfe1 20% (\u2155) / \u23f1\ufe0f 89.3s / \ud83d\udcb0 $0.16 \ud83d\udfe1 40% (\u2156) / \u23f1\ufe0f 377.2s / \ud83d\udcb0 $0.34 \ud83d\udfe1 20% (\u2155) / \u23f1\ufe0f 148.2s / \ud83d\udcb0 $0.31 \ud83d\udfe1 40% (\u2156) / \u23f1\ufe0f 173.2s / \ud83d\udcb0 $0.52 115_checkout_errors_tracing[0] \ud83d\udd17 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 87.3s / \ud83d\udcb0 $0.22 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 93.8s / \ud83d\udcb0 $0.21 \ud83d\udfe1 40% (\u2156) / \u23f1\ufe0f 265.8s / \ud83d\udcb0 $0.20 \ud83d\udfe1 20% (\u2155) / \u23f1\ufe0f 136.2s / \ud83d\udcb0 $0.30 \ud83d\udfe1 20% (\u2155) / \u23f1\ufe0f 255.3s / \ud83d\udcb0 $0.51 11_init_containers \ud83d\udd17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 45.3s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 54.0s / \ud83d\udcb0 $0.07 \ud83d\udfe1 80% (\u2158) / \u23f1\ufe0f 139.5s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 65.4s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 73.8s / \ud83d\udcb0 $0.11 121_new_relic_checkout_errors_tracing[0] \ud83d\udd17 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 35.5s / \ud83d\udcb0 $0.10 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 40.7s / \ud83d\udcb0 $0.05 \ud83d\udfe1 60% (\u2157) / \u23f1\ufe0f 530.6s / \ud83d\udcb0 $0.41 \ud83d\udfe1 40% (\u2156) / \u23f1\ufe0f 189.5s / \ud83d\udcb0 $0.48 \ud83d\udfe1 60% (\u2157) / \u23f1\ufe0f 145.3s / \ud83d\udcb0 $0.41 122_new_relic_checkout_latency_tracing_rebuild[0] \ud83d\udd17 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 42.6s / \ud83d\udcb0 $0.20 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 65.4s / \ud83d\udcb0 $0.25 \ud83d\udfe1 40% (\u2156) / \u23f1\ufe0f 583.9s / \ud83d\udcb0 $0.36 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 293.4s / \ud83d\udcb0 $0.41 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 156.6s / \ud83d\udcb0 $0.39 123_new_relic_checkout_errors_tracing[0] \ud83d\udd17 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 63.9s / \ud83d\udcb0 $0.11 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 50.6s / \ud83d\udcb0 $0.06 \ud83d\udfe1 20% (\u2155) / \u23f1\ufe0f 343.2s / \ud83d\udcb0 $0.31 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 155.5s / \ud83d\udcb0 $0.44 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 124.7s / \ud83d\udcb0 $0.37 12_job_crashing \ud83d\udd17 \ud83d\udfe1 60% (\u2157) / \u23f1\ufe0f 49.7s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 41.9s / \ud83d\udcb0 $0.08 \ud83d\udfe1 80% (\u2158) / \u23f1\ufe0f 184.2s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 92.1s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 65.8s / \ud83d\udcb0 $0.14 13a_pending_node_selector_basic \ud83d\udd17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 52.8s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 52.0s / \ud83d\udcb0 $0.10 \ud83d\udfe1 20% (\u2155) / \u23f1\ufe0f 84.3s / \ud83d\udcb0 $0.04 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 119.2s / \ud83d\udcb0 $0.14 \ud83d\udfe1 80% (\u2158) / \u23f1\ufe0f 54.6s / \ud83d\udcb0 $0.11 13b_pending_node_selector_detailed \ud83d\udd17 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 42.9s / \ud83d\udcb0 $0.13 \ud83d\udfe1 80% (\u2158) / \u23f1\ufe0f 45.4s / \ud83d\udcb0 $0.09 \ud83d\udfe1 40% (\u2156) / \u23f1\ufe0f 110.8s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 66.7s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 63.6s / \ud83d\udcb0 $0.14 14_pending_resources \ud83d\udd17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 58.7s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 70.5s / \ud83d\udcb0 $0.10 \ud83d\udfe1 20% (\u2155) / \u23f1\ufe0f 70.4s / \ud83d\udcb0 $0.04 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 114.5s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 80.2s / \ud83d\udcb0 $0.13 159_prometheus_high_cardinality_cpu[0] \ud83d\udd17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 39.3s / \ud83d\udcb0 $0.16 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 51.0s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 231.2s / \ud83d\udcb0 $0.20 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 66.9s / \ud83d\udcb0 $0.17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 59.8s / \ud83d\udcb0 $0.16 159_prometheus_high_cardinality_cpu[1] \ud83d\udd17 \ud83d\udfe1 60% (\u2157) / \u23f1\ufe0f 43.7s / \ud83d\udcb0 $0.20 \ud83d\udfe1 80% (\u2158) / \u23f1\ufe0f 46.6s / \ud83d\udcb0 $0.16 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 154.2s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 84.9s / \ud83d\udcb0 $0.22 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 82.1s / \ud83d\udcb0 $0.19 159_prometheus_high_cardinality_cpu[2] \ud83d\udd17 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 35.1s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 50.6s / \ud83d\udcb0 $0.16 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 130.8s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 155.1s / \ud83d\udcb0 $0.22 \ud83d\udfe1 20% (\u2155) / \u23f1\ufe0f 53.2s / \ud83d\udcb0 $0.19 15_failed_readiness_probe \ud83d\udd17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 42.9s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 45.5s / \ud83d\udcb0 $0.09 \ud83d\udfe1 80% (\u2158) / \u23f1\ufe0f 141.4s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 88.2s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 52.1s / \ud83d\udcb0 $0.14 16_failed_no_toolset_found \ud83d\udd17 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 46.5s / \ud83d\udcb0 $0.09 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 38.1s / \ud83d\udcb0 $0.03 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 64.5s / \ud83d\udcb0 $0.02 \ud83d\udfe1 60% (\u2157) / \u23f1\ufe0f 38.1s / \ud83d\udcb0 $0.06 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 32.5s / \ud83d\udcb0 $0.06 17_oom_kill \ud83d\udd17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 55.6s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 59.1s / \ud83d\udcb0 $0.08 \ud83d\udfe1 60% (\u2157) / \u23f1\ufe0f 116.0s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 71.5s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 61.3s / \ud83d\udcb0 $0.12 19_detect_missing_app_details \ud83d\udd17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 78.8s / \ud83d\udcb0 $0.44 \ud83d\udfe1 80% (\u2158) / \u23f1\ufe0f 66.1s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 267.1s / \ud83d\udcb0 $0.18 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 102.3s / \ud83d\udcb0 $0.21 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 95.1s / \ud83d\udcb0 $0.16 20_long_log_file_search \ud83d\udd17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 56.0s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 57.5s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 126.4s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 123.3s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 84.4s / \ud83d\udcb0 $0.11 21_job_fail_curl_no_svc_account \ud83d\udd17 \ud83d\udfe1 80% (\u2158) / \u23f1\ufe0f 51.1s / \ud83d\udcb0 $0.25 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 79.9s / \ud83d\udcb0 $0.16 \ud83d\udfe1 80% (\u2158) / \u23f1\ufe0f 174.0s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 74.5s / \ud83d\udcb0 $0.21 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 66.5s / \ud83d\udcb0 $0.19 23_app_error_in_current_logs \ud83d\udd17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 82.7s / \ud83d\udcb0 $0.19 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 91.4s / \ud83d\udcb0 $0.30 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 249.1s / \ud83d\udcb0 $0.19 \ud83d\udfe1 80% (\u2158) / \u23f1\ufe0f 78.8s / \ud83d\udcb0 $0.25 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 76.9s / \ud83d\udcb0 $0.17 24_misconfigured_pvc \ud83d\udd17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 60.4s / \ud83d\udcb0 $0.17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 89.5s / \ud83d\udcb0 $0.13 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 58.4s / \ud83d\udcb0 $0.02 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 88.4s / \ud83d\udcb0 $0.16 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 112.6s / \ud83d\udcb0 $0.17 24a_misconfigured_pvc_basic \ud83d\udd17 \ud83d\udfe1 80% (\u2158) / \u23f1\ufe0f 51.4s / \ud83d\udcb0 $0.19 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 72.4s / \ud83d\udcb0 $0.10 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 30.1s / \ud83d\udcb0 $0.02 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 75.8s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 68.9s / \ud83d\udcb0 $0.16 24b_misconfigured_pvc_detailed \ud83d\udd17 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 55.8s / \ud83d\udcb0 $0.18 \ud83d\udfe1 20% (\u2155) / \u23f1\ufe0f 59.5s / \ud83d\udcb0 $0.12 \ud83d\udfe1 20% (\u2155) / \u23f1\ufe0f 93.6s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 89.7s / \ud83d\udcb0 $0.17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 195.9s / \ud83d\udcb0 $0.17 25_misconfigured_ingress_class \ud83d\udd17 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 48.5s / \ud83d\udcb0 $0.13 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 62.6s / \ud83d\udcb0 $0.14 \ud83d\udfe1 40% (\u2156) / \u23f1\ufe0f 187.9s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 121.1s / \ud83d\udcb0 $0.26 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 100.2s / \ud83d\udcb0 $0.35 26_page_render_times \ud83d\udd17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 41.5s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 42.0s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 347.0s / \ud83d\udcb0 $0.26 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 73.5s / \ud83d\udcb0 $0.16 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 48.4s / \ud83d\udcb0 $0.16 27a_multi_container_logs \ud83d\udd17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 44.7s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 53.5s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 197.6s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 75.2s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 47.2s / \ud83d\udcb0 $0.12 27b_multi_container_logs \ud83d\udd17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 56.3s / \ud83d\udcb0 $0.14 \ud83d\udfe1 80% (\u2158) / \u23f1\ufe0f 64.4s / \ud83d\udcb0 $0.08 \ud83d\udfe1 80% (\u2158) / \u23f1\ufe0f 124.0s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 55.0s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 63.9s / \ud83d\udcb0 $0.11 28_permissions_error \ud83d\udd17 \ud83d\udfe1 60% (\u2157) / \u23f1\ufe0f 22.3s / \ud83d\udcb0 $0.04 \ud83d\udfe1 40% (\u2156) / \u23f1\ufe0f 26.9s / \ud83d\udcb0 $0.05 \ud83d\udfe1 40% (\u2156) / \u23f1\ufe0f 138.5s / \ud83d\udcb0 $0.09 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 32.5s / \ud83d\udcb0 $0.07 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 27.3s / \ud83d\udcb0 $0.07 33_cpu_metrics_discovery \ud83d\udd17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 46.7s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 58.9s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 266.9s / \ud83d\udcb0 $0.22 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 76.5s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 59.9s / \ud83d\udcb0 $0.13 39_failed_toolset \ud83d\udd17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 27.2s / \ud83d\udcb0 $0.04 \ud83d\udfe1 40% (\u2156) / \u23f1\ufe0f 40.8s / \ud83d\udcb0 $0.07 \ud83d\udfe1 80% (\u2158) / \u23f1\ufe0f 251.5s / \ud83d\udcb0 $0.19 \ud83d\udfe1 80% (\u2158) / \u23f1\ufe0f 169.5s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 56.9s / \ud83d\udcb0 $0.11 41_setup_argo \ud83d\udd17 \ud83d\udfe1 80% (\u2158) / \u23f1\ufe0f 49.1s / \ud83d\udcb0 $0.03 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 35.2s / \ud83d\udcb0 $0.02 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 171.0s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 29.1s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 30.0s / \ud83d\udcb0 $0.06 42_dns_issues_result_new_tools_no_runbook \ud83d\udd17 \ud83d\udfe1 60% (\u2157) / \u23f1\ufe0f 55.0s / \ud83d\udcb0 $0.22 \ud83d\udfe1 60% (\u2157) / \u23f1\ufe0f 80.6s / \ud83d\udcb0 $0.18 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 291.8s / \ud83d\udcb0 $0.23 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 163.9s / \ud83d\udcb0 $0.36 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 109.7s / \ud83d\udcb0 $0.26 42_dns_issues_steps_new_tools \ud83d\udd17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 56.5s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 62.4s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 471.2s / \ud83d\udcb0 $0.23 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 165.8s / \ud83d\udcb0 $0.26 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 157.3s / \ud83d\udcb0 $0.31 43_current_datetime_from_prompt \ud83d\udd17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 32.6s / \ud83d\udcb0 $0.02 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 42.0s / \ud83d\udcb0 $0.04 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 66.7s / \ud83d\udcb0 $0.03 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 23.5s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 23.4s / \ud83d\udcb0 $0.06 45_fetch_deployment_logs_simple \ud83d\udd17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 37.8s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 46.1s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 100.0s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 41.4s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 50.7s / \ud83d\udcb0 $0.11 50a_logs_since_last_specific_month \ud83d\udd17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 41.9s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 51.0s / \ud83d\udcb0 $0.05 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 314.7s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 54.4s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 47.2s / \ud83d\udcb0 $0.09 51_logs_summarize_errors \ud83d\udd17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 45.9s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 46.7s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 133.0s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 159.3s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 55.1s / \ud83d\udcb0 $0.10 52_logs_login_issues \ud83d\udd17 \ud83d\udfe1 40% (\u2156) / \u23f1\ufe0f 84.3s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 78.5s / \ud83d\udcb0 $0.38 \ud83d\udfe1 60% (\u2157) / \u23f1\ufe0f 152.1s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 69.7s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 61.7s / \ud83d\udcb0 $0.11 53_logs_find_term \ud83d\udd17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 37.7s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 46.7s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 107.3s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 50.9s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 53.2s / \ud83d\udcb0 $0.13 54_not_truncated_when_getting_pods \ud83d\udd17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 58.6s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 69.7s / \ud83d\udcb0 $0.11 \ud83d\udfe1 80% (\u2158) / \u23f1\ufe0f 196.2s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 142.2s / \ud83d\udcb0 $0.15 \ud83d\udfe1 80% (\u2158) / \u23f1\ufe0f 65.7s / \ud83d\udcb0 $0.11 57_wrong_namespace \ud83d\udd17 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 40.6s / \ud83d\udcb0 $0.10 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 47.2s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 145.2s / \ud83d\udcb0 $0.08 \ud83d\udfe1 60% (\u2157) / \u23f1\ufe0f 77.4s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 91.7s / \ud83d\udcb0 $0.10 59_label_based_counting \ud83d\udd17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 33.8s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 32.9s / \ud83d\udcb0 $0.05 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 77.8s / \ud83d\udcb0 $0.03 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 51.4s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 34.9s / \ud83d\udcb0 $0.08 60_count_less_than \ud83d\udd17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 85.4s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 56.3s / \ud83d\udcb0 $0.06 \ud83d\udfe1 80% (\u2158) / \u23f1\ufe0f 88.5s / \ud83d\udcb0 $0.05 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 37.1s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 36.5s / \ud83d\udcb0 $0.09 61_exact_match_counting \ud83d\udd17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 33.9s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 34.0s / \ud83d\udcb0 $0.05 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 60.9s / \ud83d\udcb0 $0.04 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 32.2s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 36.0s / \ud83d\udcb0 $0.08 62_fetch_error_logs_with_errors \ud83d\udd17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 60.6s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 50.9s / \ud83d\udcb0 $0.07 \ud83d\udfe1 80% (\u2158) / \u23f1\ufe0f 102.9s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 46.9s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 43.3s / \ud83d\udcb0 $0.09 63_fetch_error_logs_no_errors \ud83d\udd17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 39.9s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 45.1s / \ud83d\udcb0 $0.07 \ud83d\udfe1 60% (\u2157) / \u23f1\ufe0f 138.8s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 46.6s / \ud83d\udcb0 $0.09 \ud83d\udfe1 80% (\u2158) / \u23f1\ufe0f 39.6s / \ud83d\udcb0 $0.07 64_keda_vs_hpa_confusion \ud83d\udd17 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 71.8s / \ud83d\udcb0 $0.42 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 51.2s / \ud83d\udcb0 $0.08 \ud83d\udfe1 80% (\u2158) / \u23f1\ufe0f 191.3s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 112.3s / \ud83d\udcb0 $0.20 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 93.1s / \ud83d\udcb0 $0.20 65_health_check_followup \ud83d\udd17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 50.3s / \ud83d\udcb0 $0.18 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 69.6s / \ud83d\udcb0 $0.22 \ud83d\udfe1 80% (\u2158) / \u23f1\ufe0f 277.0s / \ud83d\udcb0 $0.20 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 328.5s / \ud83d\udcb0 $0.24 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 94.4s / \ud83d\udcb0 $0.27 71_connection_pool_starvation \ud83d\udd17 \ud83d\udfe1 80% (\u2158) / \u23f1\ufe0f 47.1s / \ud83d\udcb0 $0.17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 49.2s / \ud83d\udcb0 $0.10 \ud83d\udfe1 20% (\u2155) / \u23f1\ufe0f 152.5s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 59.9s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 65.3s / \ud83d\udcb0 $0.17 73a_time_window_anomaly \ud83d\udd17 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 48.7s / \ud83d\udcb0 $0.15 \ud83d\udfe1 20% (\u2155) / \u23f1\ufe0f 58.6s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 187.9s / \ud83d\udcb0 $0.13 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 84.2s / \ud83d\udcb0 $0.13 \ud83d\udfe1 40% (\u2156) / \u23f1\ufe0f 81.8s / \ud83d\udcb0 $0.15 73b_time_window_anomaly \ud83d\udd17 \ud83d\udfe1 60% (\u2157) / \u23f1\ufe0f 56.0s / \ud83d\udcb0 $0.16 \ud83d\udfe1 40% (\u2156) / \u23f1\ufe0f 68.9s / \ud83d\udcb0 $0.08 \ud83d\udfe1 80% (\u2158) / \u23f1\ufe0f 165.5s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 189.3s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 67.7s / \ud83d\udcb0 $0.14 76_service_discovery_issue \ud83d\udd17 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 45.5s / \ud83d\udcb0 $0.20 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 66.1s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 205.8s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 67.4s / \ud83d\udcb0 $0.22 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 65.1s / \ud83d\udcb0 $0.16 77_liveness_probe_misconfiguration \ud83d\udd17 \ud83d\udfe1 40% (\u2156) / \u23f1\ufe0f 42.7s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 58.6s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 182.8s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 69.0s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 54.0s / \ud83d\udcb0 $0.13 78a_missing_cpu_limits \ud83d\udd17 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 49.4s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 59.7s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 206.0s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 72.8s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 65.1s / \ud83d\udcb0 $0.14 78b_cpu_quota_exceeded \ud83d\udd17 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 55.1s / \ud83d\udcb0 $0.18 \ud83d\udfe1 20% (\u2155) / \u23f1\ufe0f 49.1s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 152.7s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 73.5s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 61.6s / \ud83d\udcb0 $0.14 79_configmap_mount_issue \ud83d\udd17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 42.6s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 47.1s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 197.3s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 61.4s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 69.9s / \ud83d\udcb0 $0.12 80_pvc_storage_class_mismatch \ud83d\udd17 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 76.1s / \ud83d\udcb0 $0.12 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 64.0s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 191.5s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 89.4s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 72.9s / \ud83d\udcb0 $0.14 81_service_account_permission_denied \ud83d\udd17 \ud83d\udfe1 20% (\u2155) / \u23f1\ufe0f 47.2s / \ud83d\udcb0 $0.14 \ud83d\udfe1 80% (\u2158) / \u23f1\ufe0f 56.2s / \ud83d\udcb0 $0.11 \ud83d\udfe1 80% (\u2158) / \u23f1\ufe0f 198.0s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 103.5s / \ud83d\udcb0 $0.21 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 73.0s / \ud83d\udcb0 $0.17 82_pod_anti_affinity_conflict \ud83d\udd17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 55.6s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 61.8s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 173.8s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 77.3s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 108.8s / \ud83d\udcb0 $0.14 83_secret_not_found \ud83d\udd17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 44.7s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 44.8s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 185.9s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 81.7s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 85.1s / \ud83d\udcb0 $0.12 84_network_policy_blocking_traffic \ud83d\udd17 \ud83d\udfe1 20% (\u2155) / \u23f1\ufe0f 47.4s / \ud83d\udcb0 $0.18 \ud83d\udfe1 80% (\u2158) / \u23f1\ufe0f 58.1s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 226.9s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 131.7s / \ud83d\udcb0 $0.24 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 85.7s / \ud83d\udcb0 $0.23 85_hpa_not_scaling \ud83d\udd17 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 42.0s / \ud83d\udcb0 $0.11 \ud83d\udfe1 80% (\u2158) / \u23f1\ufe0f 60.3s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 183.9s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 67.2s / \ud83d\udcb0 $0.16 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 68.2s / \ud83d\udcb0 $0.17 86_configmap_like_but_secret \ud83d\udd17 \ud83d\udfe1 80% (\u2158) / \u23f1\ufe0f 50.8s / \ud83d\udcb0 $0.18 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 58.3s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 227.5s / \ud83d\udcb0 $0.17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 76.0s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 158.1s / \ud83d\udcb0 $0.15 89_runbook_missing_cloudwatch \ud83d\udd17 \ud83d\udfe1 80% (\u2158) / \u23f1\ufe0f 44.0s / \ud83d\udcb0 $0.07 \ud83d\udfe1 80% (\u2158) / \u23f1\ufe0f 31.9s / \ud83d\udcb0 $0.04 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 258.4s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 55.3s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 47.5s / \ud83d\udcb0 $0.11 90_runbook_basic_selection \ud83d\udd17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 58.0s / \ud83d\udcb0 $0.20 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 71.2s / \ud83d\udcb0 $0.16 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 365.1s / \ud83d\udcb0 $0.29 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 216.9s / \ud83d\udcb0 $0.49 \ud83d\udfe1 80% (\u2158) / \u23f1\ufe0f 138.6s / \ud83d\udcb0 $0.47 91f_datadog_logs_historical_pod \ud83d\udd17 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 46.0s / \ud83d\udcb0 $0.16 \ud83d\udfe1 20% (\u2155) / \u23f1\ufe0f 64.1s / \ud83d\udcb0 $0.14 \ud83d\udfe1 80% (\u2158) / \u23f1\ufe0f 302.2s / \ud83d\udcb0 $0.19 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 74.8s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 67.1s / \ud83d\udcb0 $0.14 93_calling_datadog[0] \ud83d\udd17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 61.2s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 15.6s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 54.2s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 13.7s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 12.5s / \ud83d\udcb0 $0.15 93_calling_datadog[1] \ud83d\udd17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 73.2s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 12.9s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 63.4s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 20.4s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 11.8s / \ud83d\udcb0 $0.15 94_runbook_transparency \ud83d\udd17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 60.9s / \ud83d\udcb0 $0.25 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 85.7s / \ud83d\udcb0 $0.20 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 309.8s / \ud83d\udcb0 $0.25 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 116.3s / \ud83d\udcb0 $0.23 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 94.6s / \ud83d\udcb0 $0.24 96_no_matching_runbook \ud83d\udd17 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 56.5s / \ud83d\udcb0 $0.22 \ud83d\udd34 0% (0/5) / \u23f1\ufe0f 128.6s / \ud83d\udcb0 $0.55 \ud83d\udfe1 60% (\u2157) / \u23f1\ufe0f 304.2s / \ud83d\udcb0 $0.20 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 203.2s / \ud83d\udcb0 $0.57 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 119.7s / \ud83d\udcb0 $0.27 97_logs_clarification_needed \ud83d\udd17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 18.7s / \ud83d\udcb0 $0.03 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 30.9s / \ud83d\udcb0 $0.03 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 32.2s / \ud83d\udcb0 $0.02 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 95.0s / \ud83d\udcb0 $0.19 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 21.8s / \ud83d\udcb0 $0.06 99_logs_transparency_custom_time \ud83d\udd17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 38.0s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 46.2s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 99.7s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 89.6s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 95.6s / \ud83d\udcb0 $0.11 50_logs_since_specific_date \ud83d\udd17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 20.3s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (4/4) / \u23f1\ufe0f 25.4s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 105.6s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 35.3s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 28.8s / \ud83d\udcb0 $0.10 93_calling_datadog[2] \ud83d\udd17 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 57.6s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 15.2s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (4/4) / \u23f1\ufe0f 72.4s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 13.1s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 11.9s / \ud83d\udcb0 $0.15 93_events_since_specific_date \ud83d\udd17 \ud83d\udfe2 100% (4/4) / \u23f1\ufe0f 20.2s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (4/4) / \u23f1\ufe0f 19.0s / \ud83d\udcb0 $0.06 \u26aa\ufe0f - \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 24.3s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (5/5) / \u23f1\ufe0f 21.0s / \ud83d\udcb0 $0.10 44_slack_statefulset_logs \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 48_logs_since_thursday \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 22_high_latency_dbi_down \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 08_sock_shop_frontend \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 104b_postgres_missing_index_pgstat \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 104c_postgres_minimal_missing_index \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 105_redis_wrong_data_structure \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 156_kafka_opensearch_latency \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 43_slack_deployment_logs \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 55_kafka_runbook \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 98_logs_transparency_default_time \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - <p>Results are automatically generated and updated weekly. View full traces and detailed analysis in Braintrust experiment: local-benchmark-20250930-092035.</p>"},{"location":"development/evaluations/history/custom_self_hosted_results_20251008_053744/","title":"Self-Hosted Models v1","text":"<p>Generated: 2025-10-08 05:37 UTC</p> <p>Total Duration: 5h 38m 14s</p> <p>Iterations: 1</p> <p>Judge (classifier) model: gpt-4o</p>"},{"location":"development/evaluations/history/custom_self_hosted_results_20251008_053744/#about-this-benchmark","title":"About this Benchmark","text":"<p>HolmesGPT is continuously evaluated against real-world Kubernetes and cloud troubleshooting scenarios.</p> <p>If you find scenarios that HolmesGPT does not perform well on, please consider adding them as evals to the benchmark.</p>"},{"location":"development/evaluations/history/custom_self_hosted_results_20251008_053744/#model-accuracy-comparison","title":"Model Accuracy Comparison","text":"Model Pass Fail Skip/Error Total Success Rate gpt-4.1 59 30 16 105 \ud83d\udfe1 66% (59/89) novita/deepseek/deepseek-v3.1-terminus 73 14 18 105 \ud83d\udfe1 84% (73/87) novita/deepseek/deepseek-v3.2-exp 44 44 17 105 \ud83d\udfe1 50% (44/88) novita/meta-llama/llama-4-maverick-17b-128e-instruct-fp8 0 89 16 105 \ud83d\udd34 0% (0/89) novita/zai-org/glm-4.6 2 87 16 105 \ud83d\udfe1 2% (2/89) sonnet-4-20250514 74 13 18 105 \ud83d\udfe1 85% (74/87)"},{"location":"development/evaluations/history/custom_self_hosted_results_20251008_053744/#model-cost-comparison","title":"Model Cost Comparison","text":"Model Tests Avg Cost Min Cost Max Cost Total Cost gpt-4.1 81 $0.13 $0.02 $0.57 $10.50 sonnet-4-20250514 84 $0.19 $0.06 $0.84 $16.12"},{"location":"development/evaluations/history/custom_self_hosted_results_20251008_053744/#model-latency-comparison","title":"Model Latency Comparison","text":"Model Avg (s) Min (s) Max (s) P50 (s) P95 (s) gpt-4.1 43.6 0.9 346.5 41.0 81.4 novita/deepseek/deepseek-v3.1-terminus 69.4 12.6 673.4 59.7 106.1 novita/deepseek/deepseek-v3.2-exp 80.0 12.3 635.0 53.9 189.4 novita/meta-llama/llama-4-maverick-17b-128e-instruct-fp8 12.4 12.4 12.4 12.4 12.4 novita/zai-org/glm-4.6 19.4 6.4 34.1 19.5 26.2 sonnet-4-20250514 52.9 12.5 118.7 50.5 99.9 <p>\u26a0\ufe0f Note: 90 test(s) excluded from latency calculations due to throttling/timeout errors (novita/meta-llama/llama-4-maverick-17b-128e-instruct-fp8: 88, sonnet-4-20250514: 2)</p>"},{"location":"development/evaluations/history/custom_self_hosted_results_20251008_053744/#performance-by-tag","title":"Performance by Tag","text":"<p>Success rate by test category and model:</p> Tag gpt-4.1 novita/deepseek/deepseek-v3.1-terminus novita/deepseek/deepseek-v3.2-exp novita/meta-llama/llama-4-maverick-17b-128e-instruct-fp8 novita/zai-org/glm-4.6 sonnet-4-20250514 Warnings chain-of-causation \ud83d\udfe1 25% (\u00bc) \ud83d\udfe1 25% (\u00bc) \ud83d\udd34 0% (0/4) \ud83d\udd34 0% (0/4) \ud83d\udd34 0% (0/4) \ud83d\udfe1 50% (2/4) \u26a0\ufe0f 24 skipped context_window \ud83d\udfe1 50% (3/6) \ud83d\udfe1 67% (4/6) \ud83d\udfe1 50% (3/6) \ud83d\udd34 0% (0/6) \ud83d\udd34 0% (0/6) \ud83d\udfe1 50% (3/6) \u26a0\ufe0f 6 skipped counting \ud83d\udfe2 100% (4/4) \ud83d\udfe1 75% (\u00be) \ud83d\udfe1 75% (\u00be) \ud83d\udd34 0% (0/4) \ud83d\udd34 0% (0/4) \ud83d\udfe2 100% (4/4) database \ud83d\udd34 0% (0/1) \ud83d\udfe2 100% (1/1) \ud83d\udd34 0% (0/1) \ud83d\udd34 0% (0/1) \ud83d\udd34 0% (0/1) \ud83d\udfe2 100% (1/1) \u26a0\ufe0f 18 skipped datadog \ud83d\udd34 0% (0/4) \ud83d\udfe1 75% (\u00be) \ud83d\udfe1 75% (\u00be) \ud83d\udd34 0% (0/4) \ud83d\udd34 0% (0/4) \ud83d\udfe1 75% (\u00be) datetime \ud83d\udfe1 40% (\u2156) \ud83d\udfe1 75% (\u00be) \ud83d\udfe1 60% (\u2157) \ud83d\udd34 0% (0/5) \ud83d\udfe1 20% (\u2155) \ud83d\udfe1 50% (2/4) \u26a0\ufe0f 8 skipped easy \ud83d\udfe1 86% (30/35) \ud83d\udfe1 97% (34/35) \ud83d\udfe1 66% (23/35) \ud83d\udd34 0% (0/35) \ud83d\udfe1 3% (1/35) \ud83d\udfe1 97% (34/35) \u26a0\ufe0f 6 skipped hard \ud83d\udfe1 27% (3/11) \ud83d\udfe1 64% (7/11) \ud83d\udfe1 18% (2/11) \ud83d\udd34 0% (0/11) \ud83d\udd34 0% (0/11) \ud83d\udfe1 73% (8/11) \u26a0\ufe0f 54 skipped kafka \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26a0\ufe0f 12 skipped kubernetes \ud83d\udfe1 78% (32/41) \ud83d\udfe1 85% (35/41) \ud83d\udfe1 49% (20/41) \ud83d\udd34 0% (0/41) \ud83d\udd34 0% (0/41) \ud83d\udfe1 88% (36/41) \u26a0\ufe0f 42 skipped logs \ud83d\udfe1 67% (16/24) \ud83d\udfe1 83% (19/23) \ud83d\udfe1 46% (11/24) \ud83d\udd34 0% (0/24) \ud83d\udfe1 4% (1/24) \ud83d\udfe1 78% (18/23) \u26a0\ufe0f 56 skipped medium \ud83d\udfe1 60% (26/43) \ud83d\udfe1 78% (32/41) \ud83d\udfe1 45% (19/42) \ud83d\udd34 0% (0/43) \ud83d\udfe1 2% (1/43) \ud83d\udfe1 78% (32/41) \u26a0\ufe0f 41 skipped network \ud83d\udfe1 50% (2/4) \ud83d\udfe2 100% (4/4) \ud83d\udfe1 50% (2/4) \ud83d\udd34 0% (0/4) \ud83d\udd34 0% (0/4) \ud83d\udfe2 100% (4/4) no-cicd \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26a0\ufe0f 6 skipped numerical \ud83d\udfe2 100% (1/1) \ud83d\udfe2 100% (1/1) \ud83d\udd34 0% (0/1) \ud83d\udd34 0% (0/1) \ud83d\udd34 0% (0/1) \ud83d\udfe2 100% (1/1) port-forward \ud83d\udfe1 50% (\u00bd) \ud83d\udfe1 50% (\u00bd) \ud83d\udfe1 50% (\u00bd) \ud83d\udd34 0% (0/2) \ud83d\udd34 0% (0/2) \ud83d\udfe1 50% (\u00bd) \u26a0\ufe0f 42 skipped prometheus \ud83d\udfe1 50% (\u00bd) \ud83d\udfe1 50% (\u00bd) \ud83d\udfe1 50% (\u00bd) \ud83d\udd34 0% (0/2) \ud83d\udd34 0% (0/2) \ud83d\udfe1 50% (\u00bd) \u26a0\ufe0f 12 skipped question-answer \ud83d\udfe2 100% (4/4) \ud83d\udfe1 75% (\u00be) \ud83d\udfe1 25% (\u00bc) \ud83d\udd34 0% (0/4) \ud83d\udd34 0% (0/4) \ud83d\udfe2 100% (4/4) runbooks \ud83d\udfe1 67% (4/6) \ud83d\udfe1 83% (\u215a) \ud83d\udfe1 33% (2/6) \ud83d\udd34 0% (0/6) \ud83d\udd34 0% (0/6) \ud83d\udfe2 100% (6/6) \u26a0\ufe0f 6 skipped slackbot \ud83d\udd34 0% (0/1) \u26aa\ufe0f - \u26aa\ufe0f - \ud83d\udd34 0% (0/1) \ud83d\udd34 0% (0/1) \u26aa\ufe0f - \u26a0\ufe0f 3 skipped traces \ud83d\udd34 0% (0/3) \ud83d\udd34 0% (0/3) \ud83d\udd34 0% (0/3) \ud83d\udd34 0% (0/3) \ud83d\udd34 0% (0/3) \ud83d\udfe1 33% (\u2153) \u26a0\ufe0f 12 skipped transparency \ud83d\udfe1 64% (9/14) \ud83d\udfe1 71% (10/14) \ud83d\udfe1 43% (6/14) \ud83d\udd34 0% (0/14) \ud83d\udfe1 7% (1/14) \ud83d\udfe1 64% (9/14) \u26a0\ufe0f 6 skipped Overall \ud83d\udfe1 66% (59/89) \ud83d\udfe1 84% (73/87) \ud83d\udfe1 50% (44/88) \ud83d\udd34 0% (0/89) \ud83d\udfe1 2% (2/89) \ud83d\udfe1 85% (74/87) \u26a0\ufe0f 101 skipped"},{"location":"development/evaluations/history/custom_self_hosted_results_20251008_053744/#raw-results","title":"Raw Results","text":"<p>Status of all evaluations across models. Color coding:</p> <ul> <li>\ud83d\udfe2 Passing 100% (stable)</li> <li>\ud83d\udfe1 Passing 1-99%</li> <li>\ud83d\udd34 Passing 0% (failing)</li> <li>\ud83d\udd27 Mock data failure (missing or invalid test data)</li> <li>\u26a0\ufe0f Setup failure (environment/infrastructure issue)</li> <li>\u23f1\ufe0f Timeout or rate limit error</li> <li>\u23ed\ufe0f Test skipped (e.g., known issue or precondition not met)</li> </ul> Eval ID gpt-4.1 novita/deepseek/deepseek-v3.1-terminus novita/deepseek/deepseek-v3.2-exp novita/meta-llama/llama-4-maverick-17b-128e-instruct-fp8 novita/zai-org/glm-4.6 sonnet-4-20250514 01_how_many_pods \ud83d\udd17 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 02_what_is_wrong_with_pod \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 03_what_is_the_command_to_port_forward \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 04_related_k8s_events \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 05_image_version \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 08_sock_shop_frontend \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 09_crashpod \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 100a_historical_logs \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 100b_historical_logs_nonstandard_label \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 101_historical_logs_pod_deleted \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 103_logs_transparency_default_limit \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \u23f1\ufe0f \ud83d\udd34 \ud83d\udd34 104a_postgres_root_issue \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 104b_postgres_missing_index_pgstat \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 104c_postgres_minimal_missing_index \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 105_redis_wrong_data_structure \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 107_log_filter_http_status_code \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 108_logs_nearby_lines \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 109_logs_transparency_not_found \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 10_image_pull_backoff \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 110_k8s_events_image_pull \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 111_disabled_datadog_traces \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \u23f1\ufe0f \ud83d\udd34 \ud83d\udd34 111_pod_names_contain_service \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 112_find_pvcs_by_uuid \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 114_checkout_latency_tracing_rebuild[0] \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 115_checkout_errors_tracing[0] \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 11_init_containers \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 121_new_relic_checkout_errors_tracing[0] \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \u23f1\ufe0f \ud83d\udd34 \ud83d\udd34 122_new_relic_checkout_latency_tracing_rebuild[0] \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 123_new_relic_checkout_errors_tracing[0] \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \u23f1\ufe0f \ud83d\udd34 \ud83d\udd34 12_job_crashing \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 13a_pending_node_selector_basic \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 13b_pending_node_selector_detailed \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 14_pending_resources \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 156_kafka_opensearch_latency \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 159_prometheus_high_cardinality_cpu[0] \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 159_prometheus_high_cardinality_cpu[1] \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 159_prometheus_high_cardinality_cpu[2] \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \u23f1\ufe0f \ud83d\udd34 \ud83d\udd34 15_failed_readiness_probe \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 16_failed_no_toolset_found \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \u23f1\ufe0f \ud83d\udd34 \ud83d\udd34 17_oom_kill \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 19_detect_missing_app_details \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 20_long_log_file_search \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 21_job_fail_curl_no_svc_account \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 22_high_latency_dbi_down \ud83d\udd17 \u26a0\ufe0f \u26a0\ufe0f \u26a0\ufe0f \u26a0\ufe0f \u26a0\ufe0f \u26a0\ufe0f 23_app_error_in_current_logs \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \u23f1\ufe0f \ud83d\udd34 \ud83d\udd34 24_misconfigured_pvc \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 24a_misconfigured_pvc_basic \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 24b_misconfigured_pvc_detailed \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 25_misconfigured_ingress_class \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 26_page_render_times \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 27a_multi_container_logs \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 27b_multi_container_logs \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 28_permissions_error \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \u23f1\ufe0f \ud83d\udd34 \ud83d\udd34 33_cpu_metrics_discovery \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 39_failed_toolset \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 41_setup_argo \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 42_dns_issues_result_new_tools_no_runbook \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 42_dns_issues_steps_new_tools \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 43_current_datetime_from_prompt \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \u23f1\ufe0f \ud83d\udfe2 \ud83d\udfe2 43_slack_deployment_logs \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 44_slack_statefulset_logs \ud83d\udd17 \ud83d\udd34 \ud83d\udd27 \ud83d\udd27 \u23f1\ufe0f \ud83d\udd34 \ud83d\udd27 45_fetch_deployment_logs_simple \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 48_logs_since_thursday \ud83d\udd17 \ud83d\udd34 \ud83d\udd27 \ud83d\udd34 \u23f1\ufe0f \ud83d\udd34 \ud83d\udd27 50_logs_since_specific_date \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 50a_logs_since_last_specific_month \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 51_logs_summarize_errors \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 52_logs_login_issues \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 53_logs_find_term \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 54_not_truncated_when_getting_pods \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 55_kafka_runbook \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 57_wrong_namespace \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 59_label_based_counting \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 60_count_less_than \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 61_exact_match_counting \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 62_fetch_error_logs_with_errors \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 63_fetch_error_logs_no_errors \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 64_keda_vs_hpa_confusion \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 65_health_check_followup \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \u23f1\ufe0f \ud83d\udd34 \ud83d\udd34 71_connection_pool_starvation \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 73a_time_window_anomaly \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \u23f1\ufe0f \ud83d\udd34 \ud83d\udd34 73b_time_window_anomaly \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \u23f1\ufe0f \ud83d\udd34 \ud83d\udd34 76_service_discovery_issue \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \u23f1\ufe0f \ud83d\udd34 \u23f1\ufe0f 77_liveness_probe_misconfiguration \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 78a_missing_cpu_limits \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 78b_cpu_quota_exceeded \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 79_configmap_mount_issue \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 80_pvc_storage_class_mismatch \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 81_service_account_permission_denied \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 82_pod_anti_affinity_conflict \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 83_secret_not_found \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 84_network_policy_blocking_traffic \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 85_hpa_not_scaling \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 86_configmap_like_but_secret \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 89_runbook_missing_cloudwatch \ud83d\udd17 \ud83d\udfe2 \ud83d\udd34 \ud83d\udd34 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 90_runbook_basic_selection \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 91f_datadog_logs_historical_pod \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 93_calling_datadog[0] \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 93_calling_datadog[1] \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 93_calling_datadog[2] \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 93_events_since_specific_date \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 94_runbook_transparency \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 96_no_matching_runbook \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 97_logs_clarification_needed \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \u23f1\ufe0f \ud83d\udfe2 \ud83d\udfe2 98_logs_transparency_default_time \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 99_logs_transparency_custom_time \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \u23f1\ufe0f \ud83d\udd34 \ud83d\udfe2 SUMMARY \ud83d\udfe1 66% (59/89) \ud83d\udfe1 84% (73/87) \ud83d\udfe1 50% (44/88) \ud83d\udd34 0% (0/89) \ud83d\udfe1 2% (2/89) \ud83d\udfe1 85% (74/87)"},{"location":"development/evaluations/history/custom_self_hosted_results_20251008_053744/#detailed-raw-results","title":"Detailed Raw Results","text":"Eval ID gpt-4.1 novita/deepseek/deepseek-v3.1-terminus novita/deepseek/deepseek-v3.2-exp novita/meta-llama/llama-4-maverick-17b-128e-instruct-fp8 novita/zai-org/glm-4.6 sonnet-4-20250514 01_how_many_pods \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 41.5s / \ud83d\udcb0 $0.05 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 30.0s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 35.6s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1395.5s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 17.9s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 27.9s / \ud83d\udcb0 $0.08 02_what_is_wrong_with_pod \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 37.2s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 59.8s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 24.5s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1393.4s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 21.9s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 43.3s / \ud83d\udcb0 $0.11 03_what_is_the_command_to_port_forward \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 42.4s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 673.4s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 24.0s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1465.4s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 19.0s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 38.0s / \ud83d\udcb0 $0.12 04_related_k8s_events \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 44.6s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 40.4s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 22.3s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1392.1s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 17.8s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 38.9s / \ud83d\udcb0 $0.09 05_image_version \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 28.8s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 39.9s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 22.3s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1391.5s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 17.0s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 36.4s / \ud83d\udcb0 $0.09 08_sock_shop_frontend \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 09_crashpod \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 35.3s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 57.9s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 67.9s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1395.4s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 26.2s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 49.4s / \ud83d\udcb0 $0.13 100a_historical_logs \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 100b_historical_logs_nonstandard_label \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 101_historical_logs_pod_deleted \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 103_logs_transparency_default_limit \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 54.8s / \ud83d\udcb0 $0.40 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 68.7s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 23.8s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1393.1s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 17.0s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 51.3s / \ud83d\udcb0 $0.41 104a_postgres_root_issue \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 58.1s / \ud83d\udcb0 $0.16 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 78.3s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 27.1s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1392.6s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 18.8s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 99.9s / \ud83d\udcb0 $0.44 104b_postgres_missing_index_pgstat \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 104c_postgres_minimal_missing_index \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 105_redis_wrong_data_structure \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 107_log_filter_http_status_code \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 46.2s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 126.5s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 31.2s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1393.0s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 19.6s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 74.1s / \ud83d\udcb0 $0.20 108_logs_nearby_lines \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 41.6s / \ud83d\udcb0 $0.14 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 100.2s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 25.5s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1397.4s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 22.8s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 83.5s / \ud83d\udcb0 $0.26 109_logs_transparency_not_found \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 72.1s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 58.8s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 23.7s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1398.7s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 19.1s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 36.2s / \ud83d\udcb0 $0.09 10_image_pull_backoff \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 34.9s / \ud83d\udcb0 $0.05 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 55.0s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 24.3s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1466.6s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 19.9s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 58.9s / \ud83d\udcb0 $0.12 110_k8s_events_image_pull \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 27.8s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 56.4s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 47.0s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1392.6s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 18.5s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 38.2s / \ud83d\udcb0 $0.10 111_disabled_datadog_traces \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 31.0s / \ud83d\udcb0 $0.03 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 74.7s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 208.5s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1393.3s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 19.2s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 68.2s / \ud83d\udcb0 $0.14 111_pod_names_contain_service \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 66.5s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 83.6s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 99.4s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1391.8s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 19.2s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 85.8s / \ud83d\udcb0 $0.19 112_find_pvcs_by_uuid \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 47.2s / \ud83d\udcb0 $0.07 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 54.4s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 111.5s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1393.4s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 18.0s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 43.4s / \ud83d\udcb0 $0.13 114_checkout_latency_tracing_rebuild[0] \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 115_checkout_errors_tracing[0] \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 11_init_containers \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 40.8s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 68.4s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 91.3s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1397.4s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 20.1s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 38.6s / \ud83d\udcb0 $0.10 121_new_relic_checkout_errors_tracing[0] \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 24.9s / \ud83d\udcb0 $0.04 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 42.4s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 170.1s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1394.2s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 20.0s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 68.8s / \ud83d\udcb0 $0.20 122_new_relic_checkout_latency_tracing_rebuild[0] \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 39.1s / \ud83d\udcb0 $0.10 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 78.3s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 22.5s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1392.7s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 19.0s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 90.3s / \ud83d\udcb0 $0.47 123_new_relic_checkout_errors_tracing[0] \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 20.0s / \ud83d\udcb0 $0.03 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 52.3s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 54.4s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1392.7s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 18.1s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 98.5s / \ud83d\udcb0 $0.33 12_job_crashing \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 42.2s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 58.2s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 24.5s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1395.1s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 19.6s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 54.2s / \ud83d\udcb0 $0.14 13a_pending_node_selector_basic \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 41.5s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 67.7s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 105.1s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1393.6s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 20.0s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 55.5s / \ud83d\udcb0 $0.13 13b_pending_node_selector_detailed \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 37.4s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 64.9s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 23.0s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1394.3s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 20.6s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 50.2s / \ud83d\udcb0 $0.13 14_pending_resources \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 41.4s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 62.0s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 117.1s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1390.6s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 28.8s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 51.5s / \ud83d\udcb0 $0.13 156_kafka_opensearch_latency \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 159_prometheus_high_cardinality_cpu[0] \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 159_prometheus_high_cardinality_cpu[1] \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 36.8s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 74.3s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 132.5s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1397.6s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 18.6s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 51.8s / \ud83d\udcb0 $0.29 159_prometheus_high_cardinality_cpu[2] \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 47.4s / \ud83d\udcb0 $0.14 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 40.7s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 68.1s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1398.1s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 20.1s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 37.9s / \ud83d\udcb0 $0.14 15_failed_readiness_probe \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 31.5s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 70.2s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 123.3s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1399.9s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 19.2s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 57.9s / \ud83d\udcb0 $0.14 16_failed_no_toolset_found \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 21.6s / \ud83d\udcb0 $0.03 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 60.4s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 46.5s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1393.7s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 20.1s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 22.8s / \ud83d\udcb0 $0.06 17_oom_kill \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 43.2s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 53.2s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 97.3s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1398.8s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 34.1s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 54.8s / \ud83d\udcb0 $0.16 19_detect_missing_app_details \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 83.0s / \ud83d\udcb0 $0.16 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 102.0s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 126.1s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1393.3s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 18.5s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 101.3s / \ud83d\udcb0 $0.14 20_long_log_file_search \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 43.8s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 103.5s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 81.3s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1390.3s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 19.3s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 54.7s / \ud83d\udcb0 $0.11 21_job_fail_curl_no_svc_account \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 346.5s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 77.7s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 24.1s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1429.3s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 19.6s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 54.5s / \ud83d\udcb0 $0.18 22_high_latency_dbi_down \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 23_app_error_in_current_logs \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 58.9s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 88.5s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 292.4s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1393.5s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 22.0s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 36.7s 24_misconfigured_pvc \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 46.4s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 84.8s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 96.2s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1394.3s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 19.4s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 61.7s / \ud83d\udcb0 $0.15 24a_misconfigured_pvc_basic \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 55.9s / \ud83d\udcb0 $0.17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 74.0s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 168.4s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1398.9s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 20.4s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 58.7s / \ud83d\udcb0 $0.17 24b_misconfigured_pvc_detailed \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 45.6s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 82.0s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 159.2s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1434.6s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 19.7s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 63.3s / \ud83d\udcb0 $0.15 25_misconfigured_ingress_class \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 63.0s / \ud83d\udcb0 $0.23 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 106.1s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 189.4s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1398.6s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 23.8s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 104.3s / \ud83d\udcb0 $0.30 26_page_render_times \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 35.3s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 63.2s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 46.5s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1397.4s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 22.8s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 57.8s / \ud83d\udcb0 $0.15 27a_multi_container_logs \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 50.0s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 59.7s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 74.6s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1394.1s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 18.9s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 50.5s / \ud83d\udcb0 $0.11 27b_multi_container_logs \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 37.8s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 39.0s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 24.2s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1392.3s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 18.6s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 37.3s / \ud83d\udcb0 $0.11 28_permissions_error \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 22.0s / \ud83d\udcb0 $0.05 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 31.2s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 37.2s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1389.7s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 17.0s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 25.6s / \ud83d\udcb0 $0.07 33_cpu_metrics_discovery \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 39_failed_toolset \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 39.3s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 77.7s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 157.3s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1400.6s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 29.5s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 48.6s / \ud83d\udcb0 $0.10 41_setup_argo \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 25.0s / \ud83d\udcb0 $0.02 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 29.7s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 165.8s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1395.3s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 19.2s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 20.3s / \ud83d\udcb0 $0.06 42_dns_issues_result_new_tools_no_runbook \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 97.8s / \ud83d\udcb0 $0.57 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 93.5s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 130.6s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1388.7s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 18.4s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 92.7s / \ud83d\udcb0 $0.22 42_dns_issues_steps_new_tools \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 81.4s / \ud83d\udcb0 $0.38 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 144.0s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 29.7s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1390.7s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 21.1s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 108.7s / \ud83d\udcb0 $0.35 43_current_datetime_from_prompt \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 32.0s / \ud83d\udcb0 $0.04 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 24.3s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 19.7s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1393.6s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 18.7s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 39.1s / \ud83d\udcb0 $0.06 43_slack_deployment_logs \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 44_slack_statefulset_logs \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 0.9s \u26aa\ufe0f - \u26aa\ufe0f - \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1346.7s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 9.0s \u26aa\ufe0f - 45_fetch_deployment_logs_simple \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 39.5s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 57.4s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 22.1s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1394.5s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 19.8s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 42.7s / \ud83d\udcb0 $0.10 48_logs_since_thursday \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 0.9s \u26aa\ufe0f - \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 28.1s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1347.4s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 6.4s \u26aa\ufe0f - 50_logs_since_specific_date \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 1.0s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 32.8s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 36.2s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1345.5s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 23.3s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 26.9s / \ud83d\udcb0 $0.13 50a_logs_since_last_specific_month \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 30.1s / \ud83d\udcb0 $0.05 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 38.3s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 71.2s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1395.0s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 21.2s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 40.4s / \ud83d\udcb0 $0.10 51_logs_summarize_errors \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 37.3s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 46.3s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 45.3s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1394.7s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 22.1s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 126.6s / \ud83d\udcb0 $0.10 52_logs_login_issues \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 45.2s / \ud83d\udcb0 $0.55 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 66.5s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 24.4s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1391.3s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 18.7s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 56.6s / \ud83d\udcb0 $0.79 53_logs_find_term \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 30.3s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 46.9s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 53.9s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1395.6s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 18.7s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 44.4s / \ud83d\udcb0 $0.14 54_not_truncated_when_getting_pods \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 39.0s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 55.7s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 140.6s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1391.5s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 20.0s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 46.3s / \ud83d\udcb0 $0.12 55_kafka_runbook \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 57_wrong_namespace \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 32.9s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 57.6s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 58.3s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1392.9s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 17.2s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 40.6s / \ud83d\udcb0 $0.10 59_label_based_counting \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 32.1s / \ud83d\udcb0 $0.05 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 32.8s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 21.2s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1392.1s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 18.1s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 30.6s / \ud83d\udcb0 $0.08 60_count_less_than \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 28.3s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 46.1s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 56.3s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1397.0s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 19.5s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 36.1s / \ud83d\udcb0 $0.09 61_exact_match_counting \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 37.2s / \ud83d\udcb0 $0.05 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 33.8s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 74.3s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1393.3s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 18.2s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 28.4s / \ud83d\udcb0 $0.08 62_fetch_error_logs_with_errors \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 43.9s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 41.8s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 45.4s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1392.0s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 17.8s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 34.3s / \ud83d\udcb0 $0.09 63_fetch_error_logs_no_errors \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 32.9s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 49.0s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 22.1s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1398.8s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 17.5s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 44.2s / \ud83d\udcb0 $0.11 64_keda_vs_hpa_confusion \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 41.0s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 67.0s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 133.7s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1394.2s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 18.3s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 77.6s / \ud83d\udcb0 $0.22 65_health_check_followup \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 51.3s / \ud83d\udcb0 $0.20 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 61.0s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 27.2s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1398.0s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 19.8s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 78.0s / \ud83d\udcb0 $0.20 71_connection_pool_starvation \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 43.0s / \ud83d\udcb0 $0.55 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 61.2s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 352.6s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1397.0s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 19.5s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 69.9s / \ud83d\udcb0 $0.84 73a_time_window_anomaly \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 38.9s / \ud83d\udcb0 $0.57 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 58.3s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 65.3s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1397.7s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 18.9s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 72.9s / \ud83d\udcb0 $0.74 73b_time_window_anomaly \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 42.9s / \ud83d\udcb0 $0.57 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 54.0s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 23.5s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1397.3s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 22.5s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 57.0s / \ud83d\udcb0 $0.78 76_service_discovery_issue \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 52.3s / \ud83d\udcb0 $0.26 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 73.2s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 86.3s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1427.9s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 19.9s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 763.4s 77_liveness_probe_misconfiguration \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 45.9s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 61.2s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 104.2s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1395.1s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 20.4s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 50.5s / \ud83d\udcb0 $0.14 78a_missing_cpu_limits \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 47.5s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 75.1s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 30.3s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1397.5s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 20.5s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 53.8s / \ud83d\udcb0 $0.14 78b_cpu_quota_exceeded \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 43.2s / \ud83d\udcb0 $0.08 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 60.6s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 68.5s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1393.9s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 18.6s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 52.8s / \ud83d\udcb0 $0.12 79_configmap_mount_issue \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 40.8s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 46.0s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 98.8s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1395.8s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 19.4s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 47.6s / \ud83d\udcb0 $0.11 80_pvc_storage_class_mismatch \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 41.3s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 69.7s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 28.1s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1406.2s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 29.7s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 46.2s / \ud83d\udcb0 $0.12 81_service_account_permission_denied \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 61.1s / \ud83d\udcb0 $0.21 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 63.2s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 25.0s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1391.6s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 19.5s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 56.2s / \ud83d\udcb0 $0.20 82_pod_anti_affinity_conflict \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 34.2s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 59.2s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 78.9s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1393.5s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 21.0s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 55.5s / \ud83d\udcb0 $0.15 83_secret_not_found \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 44.6s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 68.8s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 23.6s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1396.1s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 21.0s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 43.1s / \ud83d\udcb0 $0.11 84_network_policy_blocking_traffic \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 65.7s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 73.9s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 100.6s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1396.9s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 20.8s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 71.7s / \ud83d\udcb0 $0.22 85_hpa_not_scaling \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 59.9s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 67.8s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 132.1s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1393.8s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 19.0s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 54.3s / \ud83d\udcb0 $0.17 86_configmap_like_but_secret \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 39.3s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 56.3s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 81.1s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1395.1s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 20.1s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 50.8s / \ud83d\udcb0 $0.12 89_runbook_missing_cloudwatch \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 26.9s / \ud83d\udcb0 $0.05 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 35.3s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 23.7s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1385.0s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 15.2s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 40.1s / \ud83d\udcb0 $0.09 90_runbook_basic_selection \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 81.5s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 261.4s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 177.6s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1391.7s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 23.8s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 118.7s / \ud83d\udcb0 $0.35 91f_datadog_logs_historical_pod \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 12.5s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 12.6s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 12.3s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 12.4s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 13.3s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 12.5s 93_calling_datadog[0] \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 1.0s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 21.1s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 18.7s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1347.3s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 21.1s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 29.5s / \ud83d\udcb0 $0.16 93_calling_datadog[1] \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 1.1s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 44.2s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 13.0s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1347.2s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 8.2s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 12.6s / \ud83d\udcb0 $0.16 93_calling_datadog[2] \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 1.0s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 23.9s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 104.7s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1347.5s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 8.4s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 12.5s / \ud83d\udcb0 $0.16 93_events_since_specific_date \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 1.0s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 25.9s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 20.7s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1346.5s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 6.4s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 17.2s / \ud83d\udcb0 $0.11 94_runbook_transparency \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 80.9s / \ud83d\udcb0 $0.18 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 103.5s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 129.4s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1396.6s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 21.8s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 90.6s / \ud83d\udcb0 $0.24 96_no_matching_runbook \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 44.6s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 80.3s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 635.0s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1403.3s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 20.9s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 92.7s / \ud83d\udcb0 $0.60 97_logs_clarification_needed \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 19.3s / \ud83d\udcb0 $0.03 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 24.7s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 20.4s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1399.3s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 17.8s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 45.2s / \ud83d\udcb0 $0.19 98_logs_transparency_default_time \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 99_logs_transparency_custom_time \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 44.9s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 58.0s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 51.1s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 1396.9s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 19.6s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 49.3s / \ud83d\udcb0 $0.10 <p>Results are automatically generated and updated weekly. View full traces and detailed analysis in Braintrust experiment: local-benchmark-20251007-235918.</p>"},{"location":"development/evaluations/history/results_20250928_001434/","title":"September 28, 2025","text":"<p>Generated: 2025-09-29 10:49 UTC</p> <p>Total Duration: 1h 4m 41s</p> <p>Iterations: 1</p> <p>Judge (classifier) model: gpt-4.1</p>"},{"location":"development/evaluations/history/results_20250928_001434/#about-this-benchmark","title":"About this Benchmark","text":"<p>HolmesGPT is continuously evaluated against real-world Kubernetes and cloud troubleshooting scenarios.</p> <p>If you find scenarios that HolmesGPT does not perform well on, please consider adding them as evals to the benchmark.</p>"},{"location":"development/evaluations/history/results_20250928_001434/#model-accuracy-comparison","title":"Model Accuracy Comparison","text":"Model Pass Fail Skip/Error Total Success Rate gpt-4o 58 35 12 105 \ud83d\udfe1 62% (58/93) gpt-4.1 72 22 11 105 \ud83d\udfe1 77% (72/94) gpt-5 76 17 12 105 \ud83d\udfe1 82% (76/93) sonnet-4-20250514 88 6 11 105 \ud83d\udfe1 94% (88/94)"},{"location":"development/evaluations/history/results_20250928_001434/#model-cost-comparison","title":"Model Cost Comparison","text":"Model Tests Avg Cost Min Cost Max Cost Total Cost gpt-4o 93 $0.14 $0.03 $0.27 $12.83 gpt-4.1 94 $0.09 $0.03 $0.41 $8.69 gpt-5 93 $0.13 $0.02 $0.39 $12.35 sonnet-4-20250514 94 $0.16 $0.06 $0.50 $15.47"},{"location":"development/evaluations/history/results_20250928_001434/#model-latency-comparison","title":"Model Latency Comparison","text":"Model Avg (s) Min (s) Max (s) P50 (s) P95 (s) gpt-4o 35.1 9.7 84.7 35.2 48.6 gpt-4.1 35.0 7.0 80.4 34.6 58.5 gpt-5 189.5 24.1 677.8 159.7 464.0 sonnet-4-20250514 67.6 10.7 210.1 55.2 150.5"},{"location":"development/evaluations/history/results_20250928_001434/#performance-by-tag","title":"Performance by Tag","text":"<p>Success rate by test category and model:</p> Tag gpt-4o gpt-4.1 gpt-5 sonnet-4-20250514 Warnings chain-of-causation \ud83d\udd34 0% (0/6) \ud83d\udd34 0% (0/6) \ud83d\udfe1 67% (4/6) \ud83d\udfe1 83% (\u215a) \u26a0\ufe0f 8 skipped context_window \ud83d\udfe1 57% (4/7) \ud83d\udfe1 71% (5/7) \ud83d\udfe2 100% (7/7) \ud83d\udfe1 86% (6/7) counting \ud83d\udfe2 100% (4/4) \ud83d\udfe2 100% (4/4) \ud83d\udfe2 100% (4/4) \ud83d\udfe2 100% (4/4) database \ud83d\udd34 0% (0/1) \ud83d\udd34 0% (0/1) \ud83d\udfe2 100% (1/1) \ud83d\udfe2 100% (1/1) \u26a0\ufe0f 12 skipped datadog \ud83d\udfe1 75% (\u00be) \ud83d\udfe2 100% (4/4) \ud83d\udfe1 75% (\u00be) \ud83d\udfe2 100% (4/4) datetime \ud83d\udfe1 75% (\u00be) \ud83d\udfe1 50% (2/4) \ud83d\udfe2 100% (4/4) \ud83d\udfe1 75% (\u00be) \u26a0\ufe0f 8 skipped easy \ud83d\udfe1 94% (34/36) \ud83d\udfe1 97% (35/36) \ud83d\udfe1 78% (28/36) \ud83d\udfe2 100% (36/36) hard \ud83d\udfe1 14% (2/14) \ud83d\udfe1 29% (4/14) \ud83d\udfe1 57% (8/14) \ud83d\udfe1 86% (12/14) \u26a0\ufe0f 24 skipped kafka \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26a0\ufe0f 8 skipped kubernetes \ud83d\udfe1 55% (26/47) \ud83d\udfe1 77% (36/47) \ud83d\udfe1 81% (38/47) \ud83d\udfe1 94% (44/47) \u26a0\ufe0f 4 skipped logs \ud83d\udfe1 65% (17/26) \ud83d\udfe1 73% (19/26) \ud83d\udfe1 85% (22/26) \ud83d\udfe1 85% (22/26) \u26a0\ufe0f 28 skipped medium \ud83d\udfe1 51% (22/43) \ud83d\udfe1 75% (33/44) \ud83d\udfe1 93% (40/43) \ud83d\udfe1 91% (40/44) \u26a0\ufe0f 22 skipped network \ud83d\udfe1 25% (\u00bc) \ud83d\udfe1 75% (\u00be) \ud83d\udfe2 100% (4/4) \ud83d\udfe2 100% (4/4) numerical \ud83d\udfe2 100% (1/1) \ud83d\udfe2 100% (1/1) \ud83d\udfe2 100% (1/1) \ud83d\udfe2 100% (1/1) port-forward \ud83d\udfe1 33% (3/9) \ud83d\udfe1 56% (5/9) \ud83d\udfe1 78% (7/9) \ud83d\udfe1 78% (7/9) prometheus \ud83d\udfe1 50% (2/4) \ud83d\udfe2 100% (4/4) \ud83d\udfe2 100% (4/4) \ud83d\udfe2 100% (4/4) question-answer \ud83d\udfe2 100% (4/4) \ud83d\udfe2 100% (4/4) \ud83d\udfe2 100% (4/4) \ud83d\udfe2 100% (4/4) runbooks \ud83d\udfe1 33% (2/6) \ud83d\udfe1 83% (\u215a) \ud83d\udfe2 100% (6/6) \ud83d\udfe2 100% (6/6) \u26a0\ufe0f 4 skipped slackbot \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26a0\ufe0f 4 skipped traces \ud83d\udd34 0% (0/5) \ud83d\udd34 0% (0/5) \ud83d\udfe1 60% (\u2157) \ud83d\udfe1 80% (\u2158) transparency \ud83d\udfe1 50% (7/14) \ud83d\udfe1 71% (10/14) \ud83d\udfe1 86% (12/14) \ud83d\udfe1 86% (12/14) \u26a0\ufe0f 4 skipped Overall \ud83d\udfe1 62% (58/93) \ud83d\udfe1 77% (72/94) \ud83d\udfe1 82% (76/93) \ud83d\udfe1 94% (88/94) \u26a0\ufe0f 46 skipped"},{"location":"development/evaluations/history/results_20250928_001434/#raw-results","title":"Raw Results","text":"<p>Status of all evaluations across models. Color coding:</p> <ul> <li>\ud83d\udfe2 Passing 100% (stable)</li> <li>\ud83d\udfe1 Passing 1-99%</li> <li>\ud83d\udd34 Passing 0% (failing)</li> <li>\ud83d\udd27 Mock data failure (missing or invalid test data)</li> <li>\u26a0\ufe0f Setup failure (environment/infrastructure issue)</li> <li>\u23f1\ufe0f Timeout or rate limit error</li> <li>\u23ed\ufe0f Test skipped (e.g., known issue or precondition not met)</li> </ul> Eval ID gpt-4o gpt-4.1 gpt-5 sonnet-4-20250514 01_how_many_pods \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 02_what_is_wrong_with_pod \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 03_what_is_the_command_to_port_forward \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 04_related_k8s_events \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 05_image_version \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 09_crashpod \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 100a_historical_logs \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 100b_historical_logs_nonstandard_label \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 101_historical_logs_pod_deleted \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 103_logs_transparency_default_limit \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 104a_postgres_root_issue \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 107_log_filter_http_status_code \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 108_logs_nearby_lines \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 109_logs_transparency_not_found \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 10_image_pull_backoff \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 110_k8s_events_image_pull \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 111_disabled_datadog_traces \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 111_pod_names_contain_service \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 112_find_pvcs_by_uuid \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 114_checkout_latency_tracing_rebuild[0] \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 115_checkout_errors_tracing[0] \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 11_init_containers \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 121_new_relic_checkout_errors_tracing[0] \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 122_new_relic_checkout_latency_tracing_rebuild[0] \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 123_new_relic_checkout_errors_tracing[0] \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 12_job_crashing \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 13a_pending_node_selector_basic \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 13b_pending_node_selector_detailed \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 14_pending_resources \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 159_prometheus_high_cardinality_cpu[0] \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 159_prometheus_high_cardinality_cpu[1] \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 159_prometheus_high_cardinality_cpu[2] \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 15_failed_readiness_probe \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 16_failed_no_toolset_found \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 17_oom_kill \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 19_detect_missing_app_details \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 20_long_log_file_search \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 21_job_fail_curl_no_svc_account \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 23_app_error_in_current_logs \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 24_misconfigured_pvc \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 24a_misconfigured_pvc_basic \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 24b_misconfigured_pvc_detailed \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 25_misconfigured_ingress_class \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 26_page_render_times \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 27a_multi_container_logs \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 27b_multi_container_logs \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 28_permissions_error \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 33_cpu_metrics_discovery \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 39_failed_toolset \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 41_setup_argo \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 42_dns_issues_result_new_tools_no_runbook \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 42_dns_issues_steps_new_tools \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 43_current_datetime_from_prompt \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 45_fetch_deployment_logs_simple \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 50_logs_since_specific_date \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 50a_logs_since_last_specific_month \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 51_logs_summarize_errors \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 52_logs_login_issues \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 53_logs_find_term \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 54_not_truncated_when_getting_pods \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 57_wrong_namespace \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 59_label_based_counting \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 60_count_less_than \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 61_exact_match_counting \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 62_fetch_error_logs_with_errors \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 63_fetch_error_logs_no_errors \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 64_keda_vs_hpa_confusion \ud83d\udd17 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 65_health_check_followup \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 71_connection_pool_starvation \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 73a_time_window_anomaly \ud83d\udd17 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 73b_time_window_anomaly \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 76_service_discovery_issue \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 77_liveness_probe_misconfiguration \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 78a_missing_cpu_limits \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 78b_cpu_quota_exceeded \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 79_configmap_mount_issue \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 80_pvc_storage_class_mismatch \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 81_service_account_permission_denied \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 82_pod_anti_affinity_conflict \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 83_secret_not_found \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 84_network_policy_blocking_traffic \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 85_hpa_not_scaling \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 86_configmap_like_but_secret \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 89_runbook_missing_cloudwatch \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 90_runbook_basic_selection \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 91f_datadog_logs_historical_pod \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 93_calling_datadog[0] \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 93_calling_datadog[1] \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 93_calling_datadog[2] \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 94_runbook_transparency \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 96_no_matching_runbook \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 97_logs_clarification_needed \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 99_logs_transparency_custom_time \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 93_events_since_specific_date \ud83d\udd17 \ud83d\udd27 \ud83d\udfe2 \ud83d\udd27 \ud83d\udfe2 44_slack_statefulset_logs \ud83d\udd17 \ud83d\udd27 \ud83d\udd27 \ud83d\udd27 \ud83d\udd27 48_logs_since_thursday \ud83d\udd17 \ud83d\udd27 \ud83d\udd27 \ud83d\udd27 \ud83d\udd27 22_high_latency_dbi_down \ud83d\udd17 \u26a0\ufe0f \u26a0\ufe0f \u26a0\ufe0f \u26a0\ufe0f 08_sock_shop_frontend \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 104b_postgres_missing_index_pgstat \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 104c_postgres_minimal_missing_index \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 105_redis_wrong_data_structure \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 156_kafka_opensearch_latency \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 43_slack_deployment_logs \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 55_kafka_runbook \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 98_logs_transparency_default_time \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f SUMMARY \ud83d\udfe1 62% (58/93) \ud83d\udfe1 77% (72/94) \ud83d\udfe1 82% (76/93) \ud83d\udfe1 94% (88/94)"},{"location":"development/evaluations/history/results_20250928_001434/#detailed-raw-results","title":"Detailed Raw Results","text":"Eval ID gpt-4o gpt-4.1 gpt-5 sonnet-4-20250514 01_how_many_pods \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 28.8s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 27.1s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 39.1s / \ud83d\udcb0 $0.03 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 26.5s / \ud83d\udcb0 $0.08 02_what_is_wrong_with_pod \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 27.1s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 28.3s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 179.2s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 44.1s / \ud83d\udcb0 $0.11 03_what_is_the_command_to_port_forward \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 33.5s / \ud83d\udcb0 $0.16 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 31.0s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 119.7s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 38.3s / \ud83d\udcb0 $0.12 04_related_k8s_events \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 31.1s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 29.7s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 84.5s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 44.0s / \ud83d\udcb0 $0.09 05_image_version \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 27.2s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 23.0s / \ud83d\udcb0 $0.05 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 65.4s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 32.1s / \ud83d\udcb0 $0.09 09_crashpod \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 32.3s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 31.5s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 74.4s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 54.8s / \ud83d\udcb0 $0.16 100a_historical_logs \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 44.8s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 40.6s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 388.1s / \ud83d\udcb0 $0.29 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 130.5s / \ud83d\udcb0 $0.28 100b_historical_logs_nonstandard_label \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 36.1s / \ud83d\udcb0 $0.15 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 34.6s / \ud83d\udcb0 $0.07 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 354.2s / \ud83d\udcb0 $0.16 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 151.0s / \ud83d\udcb0 $0.23 101_historical_logs_pod_deleted \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 40.2s / \ud83d\udcb0 $0.12 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 31.4s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 453.0s / \ud83d\udcb0 $0.33 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 139.6s / \ud83d\udcb0 $0.46 103_logs_transparency_default_limit \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 33.4s / \ud83d\udcb0 $0.14 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 46.9s / \ud83d\udcb0 $0.41 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 76.1s / \ud83d\udcb0 $0.07 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 54.3s / \ud83d\udcb0 $0.41 104a_postgres_root_issue \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 36.3s / \ud83d\udcb0 $0.17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 55.4s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 243.1s / \ud83d\udcb0 $0.23 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 92.4s / \ud83d\udcb0 $0.21 107_log_filter_http_status_code \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 37.0s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 38.2s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 304.7s / \ud83d\udcb0 $0.26 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 80.1s / \ud83d\udcb0 $0.19 108_logs_nearby_lines \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 38.9s / \ud83d\udcb0 $0.15 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 41.4s / \ud83d\udcb0 $0.14 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 417.1s / \ud83d\udcb0 $0.22 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 77.5s / \ud83d\udcb0 $0.22 109_logs_transparency_not_found \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 27.7s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 31.6s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 121.1s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 36.3s / \ud83d\udcb0 $0.09 10_image_pull_backoff \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 40.8s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 28.4s / \ud83d\udcb0 $0.05 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 45.5s / \ud83d\udcb0 $0.02 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 50.0s / \ud83d\udcb0 $0.11 110_k8s_events_image_pull \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 32.6s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 34.6s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 55.4s / \ud83d\udcb0 $0.05 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 43.9s / \ud83d\udcb0 $0.11 111_disabled_datadog_traces \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 28.8s / \ud83d\udcb0 $0.03 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 20.1s / \ud83d\udcb0 $0.03 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 161.4s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 78.5s / \ud83d\udcb0 $0.21 111_pod_names_contain_service \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 34.3s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 38.4s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 207.8s / \ud83d\udcb0 $0.18 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 71.3s / \ud83d\udcb0 $0.21 112_find_pvcs_by_uuid \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 30.2s / \ud83d\udcb0 $0.11 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 39.4s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 100.6s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 49.9s / \ud83d\udcb0 $0.14 114_checkout_latency_tracing_rebuild[0] \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 40.2s / \ud83d\udcb0 $0.25 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 44.6s / \ud83d\udcb0 $0.17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 443.6s / \ud83d\udcb0 $0.36 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 120.6s / \ud83d\udcb0 $0.36 115_checkout_errors_tracing[0] \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 43.1s / \ud83d\udcb0 $0.25 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 64.1s / \ud83d\udcb0 $0.17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 193.9s / \ud83d\udcb0 $0.20 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 109.7s / \ud83d\udcb0 $0.35 11_init_containers \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 32.7s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 33.6s / \ud83d\udcb0 $0.07 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 26.2s / \ud83d\udcb0 $0.02 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 56.7s / \ud83d\udcb0 $0.13 121_new_relic_checkout_errors_tracing[0] \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 29.9s / \ud83d\udcb0 $0.11 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 25.9s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 565.1s / \ud83d\udcb0 $0.31 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 141.8s / \ud83d\udcb0 $0.28 122_new_relic_checkout_latency_tracing_rebuild[0] \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 36.9s / \ud83d\udcb0 $0.20 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 40.9s / \ud83d\udcb0 $0.12 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 677.8s / \ud83d\udcb0 $0.39 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 118.7s / \ud83d\udcb0 $0.33 123_new_relic_checkout_errors_tracing[0] \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 32.5s / \ud83d\udcb0 $0.13 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 22.5s / \ud83d\udcb0 $0.03 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 577.4s / \ud83d\udcb0 $0.32 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 97.5s / \ud83d\udcb0 $0.29 12_job_crashing \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 36.6s / \ud83d\udcb0 $0.18 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 33.3s / \ud83d\udcb0 $0.07 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 54.3s / \ud83d\udcb0 $0.05 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 55.2s / \ud83d\udcb0 $0.12 13a_pending_node_selector_basic \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 35.2s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 50.5s / \ud83d\udcb0 $0.08 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 27.4s / \ud83d\udcb0 $0.02 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 51.6s / \ud83d\udcb0 $0.13 13b_pending_node_selector_detailed \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 33.6s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 36.3s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 314.9s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 50.0s / \ud83d\udcb0 $0.13 14_pending_resources \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 37.6s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 37.6s / \ud83d\udcb0 $0.09 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 39.8s / \ud83d\udcb0 $0.02 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 56.2s / \ud83d\udcb0 $0.12 159_prometheus_high_cardinality_cpu[0] \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 30.4s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 58.5s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 304.1s / \ud83d\udcb0 $0.22 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 55.1s / \ud83d\udcb0 $0.18 159_prometheus_high_cardinality_cpu[1] \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 48.6s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 34.3s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 358.2s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 135.5s / \ud83d\udcb0 $0.21 159_prometheus_high_cardinality_cpu[2] \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 38.4s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 51.4s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 119.6s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 69.2s / \ud83d\udcb0 $0.21 15_failed_readiness_probe \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 44.0s / \ud83d\udcb0 $0.18 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 32.3s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 236.9s / \ud83d\udcb0 $0.18 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 132.8s / \ud83d\udcb0 $0.15 16_failed_no_toolset_found \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 24.4s / \ud83d\udcb0 $0.06 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 23.7s / \ud83d\udcb0 $0.04 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 36.9s / \ud83d\udcb0 $0.02 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 22.3s / \ud83d\udcb0 $0.06 17_oom_kill \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 38.3s / \ud83d\udcb0 $0.18 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 31.4s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 78.0s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 55.1s / \ud83d\udcb0 $0.12 19_detect_missing_app_details \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 50.5s / \ud83d\udcb0 $0.22 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 43.3s / \ud83d\udcb0 $0.07 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 264.1s / \ud83d\udcb0 $0.21 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 95.7s / \ud83d\udcb0 $0.16 20_long_log_file_search \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 39.1s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 42.0s / \ud83d\udcb0 $0.05 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 97.6s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 77.2s / \ud83d\udcb0 $0.12 21_job_fail_curl_no_svc_account \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 43.9s / \ud83d\udcb0 $0.27 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 38.2s / \ud83d\udcb0 $0.14 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 26.8s / \ud83d\udcb0 $0.02 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 54.3s / \ud83d\udcb0 $0.22 23_app_error_in_current_logs \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 40.1s / \ud83d\udcb0 $0.26 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 36.2s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 283.2s / \ud83d\udcb0 $0.19 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 72.4s / \ud83d\udcb0 $0.50 24_misconfigured_pvc \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 39.7s / \ud83d\udcb0 $0.23 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 40.9s / \ud83d\udcb0 $0.09 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 24.1s / \ud83d\udcb0 $0.02 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 61.0s / \ud83d\udcb0 $0.16 24a_misconfigured_pvc_basic \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 40.4s / \ud83d\udcb0 $0.18 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 67.0s / \ud83d\udcb0 $0.23 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 29.4s / \ud83d\udcb0 $0.02 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 79.2s / \ud83d\udcb0 $0.15 24b_misconfigured_pvc_detailed \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 40.3s / \ud83d\udcb0 $0.17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 37.2s / \ud83d\udcb0 $0.11 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 29.3s / \ud83d\udcb0 $0.02 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 64.2s / \ud83d\udcb0 $0.14 25_misconfigured_ingress_class \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 39.2s / \ud83d\udcb0 $0.14 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 45.1s / \ud83d\udcb0 $0.19 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 296.2s / \ud83d\udcb0 $0.20 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 117.6s / \ud83d\udcb0 $0.31 26_page_render_times \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 30.2s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 30.7s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 227.4s / \ud83d\udcb0 $0.20 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 57.6s / \ud83d\udcb0 $0.15 27a_multi_container_logs \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 35.0s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 36.3s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 201.3s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 43.9s / \ud83d\udcb0 $0.13 27b_multi_container_logs \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 32.5s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 39.0s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 154.3s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 37.8s / \ud83d\udcb0 $0.11 28_permissions_error \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 21.2s / \ud83d\udcb0 $0.04 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 23.9s / \ud83d\udcb0 $0.05 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 124.6s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 25.7s / \ud83d\udcb0 $0.07 33_cpu_metrics_discovery \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 27.6s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 37.9s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 246.8s / \ud83d\udcb0 $0.20 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 48.4s / \ud83d\udcb0 $0.13 39_failed_toolset \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 27.7s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 26.9s / \ud83d\udcb0 $0.04 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 222.1s / \ud83d\udcb0 $0.16 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 191.5s / \ud83d\udcb0 $0.12 41_setup_argo \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 19.4s / \ud83d\udcb0 $0.03 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 31.5s / \ud83d\udcb0 $0.04 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 170.7s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 19.0s / \ud83d\udcb0 $0.06 42_dns_issues_result_new_tools_no_runbook \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 34.9s / \ud83d\udcb0 $0.24 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 35.3s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 564.4s / \ud83d\udcb0 $0.25 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 140.3s / \ud83d\udcb0 $0.20 42_dns_issues_steps_new_tools \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 84.7s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 37.1s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 464.0s / \ud83d\udcb0 $0.24 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 210.1s / \ud83d\udcb0 $0.31 43_current_datetime_from_prompt \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 28.4s / \ud83d\udcb0 $0.03 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 20.9s / \ud83d\udcb0 $0.04 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 91.9s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 18.1s / \ud83d\udcb0 $0.06 45_fetch_deployment_logs_simple \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 29.5s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 32.5s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 108.3s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 35.9s / \ud83d\udcb0 $0.09 50_logs_since_specific_date \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 16.6s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 19.6s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 136.4s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 27.8s / \ud83d\udcb0 $0.11 50a_logs_since_last_specific_month \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 29.5s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 28.1s / \ud83d\udcb0 $0.05 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 110.7s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 41.4s / \ud83d\udcb0 $0.10 51_logs_summarize_errors \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 29.4s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 32.8s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 89.4s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 42.8s / \ud83d\udcb0 $0.10 52_logs_login_issues \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 33.6s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 48.1s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 339.9s / \ud83d\udcb0 $0.19 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 75.4s / \ud83d\udcb0 $0.12 53_logs_find_term \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 30.7s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 40.7s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 81.5s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 46.2s / \ud83d\udcb0 $0.13 54_not_truncated_when_getting_pods \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 36.5s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 40.5s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 188.7s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 69.8s / \ud83d\udcb0 $0.16 57_wrong_namespace \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 27.1s / \ud83d\udcb0 $0.10 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 27.8s / \ud83d\udcb0 $0.05 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 111.4s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 41.5s / \ud83d\udcb0 $0.10 59_label_based_counting \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 26.1s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 27.1s / \ud83d\udcb0 $0.05 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 47.0s / \ud83d\udcb0 $0.03 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 166.8s / \ud83d\udcb0 $0.08 60_count_less_than \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 23.3s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 23.4s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 53.1s / \ud83d\udcb0 $0.04 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 26.2s / \ud83d\udcb0 $0.08 61_exact_match_counting \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 36.2s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 25.4s / \ud83d\udcb0 $0.05 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 55.7s / \ud83d\udcb0 $0.04 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 29.5s / \ud83d\udcb0 $0.07 62_fetch_error_logs_with_errors \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 29.9s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 29.7s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 96.1s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 39.3s / \ud83d\udcb0 $0.09 63_fetch_error_logs_no_errors \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 38.5s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 29.9s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 100.5s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 37.1s / \ud83d\udcb0 $0.09 64_keda_vs_hpa_confusion \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 55.0s / \ud83d\udcb0 $0.27 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 31.9s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 241.5s / \ud83d\udcb0 $0.20 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 72.1s / \ud83d\udcb0 $0.25 65_health_check_followup \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 35.2s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 40.6s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 224.3s / \ud83d\udcb0 $0.17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 76.3s / \ud83d\udcb0 $0.24 71_connection_pool_starvation \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 28.6s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 37.1s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 161.5s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 57.2s / \ud83d\udcb0 $0.15 73a_time_window_anomaly \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 47.4s / \ud83d\udcb0 $0.21 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 27.6s / \ud83d\udcb0 $0.05 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 113.4s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 60.6s / \ud83d\udcb0 $0.14 73b_time_window_anomaly \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 40.6s / \ud83d\udcb0 $0.17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 43.6s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 136.4s / \ud83d\udcb0 $0.08 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 55.1s / \ud83d\udcb0 $0.13 76_service_discovery_issue \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 34.5s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 45.6s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 231.2s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 68.2s / \ud83d\udcb0 $0.20 77_liveness_probe_misconfiguration \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 43.4s / \ud83d\udcb0 $0.19 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 30.3s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 101.5s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 48.1s / \ud83d\udcb0 $0.13 78a_missing_cpu_limits \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 42.2s / \ud83d\udcb0 $0.18 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 34.6s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 260.0s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 55.1s / \ud83d\udcb0 $0.13 78b_cpu_quota_exceeded \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 42.7s / \ud83d\udcb0 $0.20 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 46.1s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 171.3s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 72.2s / \ud83d\udcb0 $0.13 79_configmap_mount_issue \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 28.6s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 32.6s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 153.7s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 49.2s / \ud83d\udcb0 $0.12 80_pvc_storage_class_mismatch \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 29.7s / \ud83d\udcb0 $0.11 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 37.9s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 159.7s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 51.8s / \ud83d\udcb0 $0.12 81_service_account_permission_denied \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 35.8s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 43.6s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 165.4s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 67.1s / \ud83d\udcb0 $0.20 82_pod_anti_affinity_conflict \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 35.9s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 35.0s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 191.3s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 59.3s / \ud83d\udcb0 $0.14 83_secret_not_found \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 32.0s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 37.5s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 132.9s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 52.2s / \ud83d\udcb0 $0.11 84_network_policy_blocking_traffic \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 35.2s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 39.6s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 157.9s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 84.8s / \ud83d\udcb0 $0.22 85_hpa_not_scaling \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 34.6s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 42.6s / \ud83d\udcb0 $0.16 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 195.0s / \ud83d\udcb0 $0.19 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 62.4s / \ud83d\udcb0 $0.17 86_configmap_like_but_secret \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 44.9s / \ud83d\udcb0 $0.17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 43.9s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 184.3s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 46.7s / \ud83d\udcb0 $0.12 89_runbook_missing_cloudwatch \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 30.8s / \ud83d\udcb0 $0.16 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 22.3s / \ud83d\udcb0 $0.05 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 315.4s / \ud83d\udcb0 $0.19 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 42.8s / \ud83d\udcb0 $0.10 90_runbook_basic_selection \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 47.0s / \ud83d\udcb0 $0.26 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 46.1s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 383.5s / \ud83d\udcb0 $0.32 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 150.5s / \ud83d\udcb0 $0.13 91f_datadog_logs_historical_pod \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 38.9s / \ud83d\udcb0 $0.17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 80.4s / \ud83d\udcb0 $0.36 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 434.8s / \ud83d\udcb0 $0.31 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 69.6s / \ud83d\udcb0 $0.15 93_calling_datadog[0] \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 48.5s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 10.8s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 102.7s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 10.9s / \ud83d\udcb0 $0.15 93_calling_datadog[1] \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 45.3s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 8.7s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 40.1s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 10.7s / \ud83d\udcb0 $0.15 93_calling_datadog[2] \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 47.0s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 9.8s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 42.7s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 15.2s / \ud83d\udcb0 $0.15 94_runbook_transparency \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 52.7s / \ud83d\udcb0 $0.18 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 35.5s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 359.0s / \ud83d\udcb0 $0.26 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 83.1s / \ud83d\udcb0 $0.23 96_no_matching_runbook \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 36.3s / \ud83d\udcb0 $0.16 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 60.8s / \ud83d\udcb0 $0.17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 383.2s / \ud83d\udcb0 $0.26 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 90.1s / \ud83d\udcb0 $0.26 97_logs_clarification_needed \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 15.2s / \ud83d\udcb0 $0.03 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 19.3s / \ud83d\udcb0 $0.03 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 26.8s / \ud83d\udcb0 $0.02 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 131.5s / \ud83d\udcb0 $0.19 99_logs_transparency_custom_time \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 45.3s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 33.6s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 67.9s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 43.0s / \ud83d\udcb0 $0.10 93_events_since_specific_date \ud83d\udd17 \u26aa\ufe0f - \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 13.2s / \ud83d\udcb0 $0.07 \u26aa\ufe0f - \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 16.3s / \ud83d\udcb0 $0.10 44_slack_statefulset_logs \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 48_logs_since_thursday \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 22_high_latency_dbi_down \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 08_sock_shop_frontend \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 104b_postgres_missing_index_pgstat \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 104c_postgres_minimal_missing_index \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 105_redis_wrong_data_structure \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 156_kafka_opensearch_latency \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 43_slack_deployment_logs \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 55_kafka_runbook \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 98_logs_transparency_default_time \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - <p>Results are automatically generated and updated weekly. View full traces and detailed analysis in Braintrust experiment: local-benchmark-20250927-230943.</p>"},{"location":"development/evaluations/history/results_20250930_085923/","title":"September 30, 2025","text":"<p>Generated: 2025-09-30 08:59 UTC</p> <p>Total Duration: 1h 36m 3s</p> <p>Iterations: 1</p> <p>Judge (classifier) model: gpt-4o</p>"},{"location":"development/evaluations/history/results_20250930_085923/#about-this-benchmark","title":"About this Benchmark","text":"<p>HolmesGPT is continuously evaluated against real-world Kubernetes and cloud troubleshooting scenarios.</p> <p>If you find scenarios that HolmesGPT does not perform well on, please consider adding them as evals to the benchmark.</p>"},{"location":"development/evaluations/history/results_20250930_085923/#model-accuracy-comparison","title":"Model Accuracy Comparison","text":"Model Pass Fail Skip/Error Total Success Rate gpt-4o 65 29 11 105 \ud83d\udfe1 69% (65/94) gpt-4.1 70 24 11 105 \ud83d\udfe1 74% (70/94) gpt-5 74 19 12 105 \ud83d\udfe1 80% (74/93) sonnet-4-20250514 91 3 11 105 \ud83d\udfe1 97% (91/94) sonnet-4-5-20250929 87 7 11 105 \ud83d\udfe1 93% (87/94)"},{"location":"development/evaluations/history/results_20250930_085923/#model-cost-comparison","title":"Model Cost Comparison","text":"Model Tests Avg Cost Min Cost Max Cost Total Cost gpt-4o 94 $0.13 $0.03 $0.43 $12.59 gpt-4.1 94 $0.11 $0.02 $0.46 $9.99 gpt-5 93 $0.13 $0.02 $0.47 $12.12 sonnet-4-20250514 94 $0.17 $0.06 $0.58 $15.66 sonnet-4-5-20250929 92 $0.16 $0.06 $0.58 $14.88"},{"location":"development/evaluations/history/results_20250930_085923/#model-latency-comparison","title":"Model Latency Comparison","text":"Model Avg (s) Min (s) Max (s) P50 (s) P95 (s) gpt-4o 36.7 9.4 85.6 36.1 56.5 gpt-4.1 51.9 11.7 641.0 43.3 79.0 gpt-5 170.2 24.3 697.1 144.3 391.2 sonnet-4-20250514 73.2 11.6 654.9 55.7 160.2 sonnet-4-5-20250929 69.5 10.3 694.5 53.5 152.7"},{"location":"development/evaluations/history/results_20250930_085923/#performance-by-tag","title":"Performance by Tag","text":"<p>Success rate by test category and model:</p> Tag gpt-4o gpt-4.1 gpt-5 sonnet-4-20250514 sonnet-4-5-20250929 Warnings chain-of-causation \ud83d\udd34 0% (0/6) \ud83d\udd34 0% (0/6) \ud83d\udfe1 33% (2/6) \ud83d\udfe2 100% (6/6) \ud83d\udfe2 100% (6/6) \u26a0\ufe0f 10 skipped context_window \ud83d\udfe1 86% (6/7) \ud83d\udfe1 43% (3/7) \ud83d\udfe2 100% (7/7) \ud83d\udfe2 100% (7/7) \ud83d\udfe1 86% (6/7) counting \ud83d\udfe2 100% (4/4) \ud83d\udfe2 100% (4/4) \ud83d\udfe2 100% (4/4) \ud83d\udfe2 100% (4/4) \ud83d\udfe2 100% (4/4) database \ud83d\udd34 0% (0/1) \ud83d\udfe2 100% (1/1) \ud83d\udfe2 100% (1/1) \ud83d\udfe2 100% (1/1) \ud83d\udfe2 100% (1/1) \u26a0\ufe0f 15 skipped datadog \ud83d\udfe1 75% (\u00be) \ud83d\udfe2 100% (4/4) \ud83d\udfe1 75% (\u00be) \ud83d\udfe2 100% (4/4) \ud83d\udfe2 100% (4/4) datetime \ud83d\udfe2 100% (4/4) \ud83d\udfe1 50% (2/4) \ud83d\udfe2 100% (4/4) \ud83d\udfe2 100% (4/4) \ud83d\udfe2 100% (4/4) \u26a0\ufe0f 10 skipped easy \ud83d\udfe1 97% (35/36) \ud83d\udfe2 100% (36/36) \ud83d\udfe1 83% (30/36) \ud83d\udfe2 100% (36/36) \ud83d\udfe1 97% (35/36) hard \ud83d\udfe1 14% (2/14) \ud83d\udfe1 36% (5/14) \ud83d\udfe1 50% (7/14) \ud83d\udfe2 100% (14/14) \ud83d\udfe1 93% (13/14) \u26a0\ufe0f 30 skipped kafka \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26a0\ufe0f 10 skipped kubernetes \ud83d\udfe1 60% (28/47) \ud83d\udfe1 70% (33/47) \ud83d\udfe1 72% (34/47) \ud83d\udfe1 98% (46/47) \ud83d\udfe1 91% (43/47) \u26a0\ufe0f 5 skipped logs \ud83d\udfe1 69% (18/26) \ud83d\udfe1 69% (18/26) \ud83d\udfe1 85% (22/26) \ud83d\udfe1 92% (24/26) \ud83d\udfe1 88% (23/26) \u26a0\ufe0f 35 skipped medium \ud83d\udfe1 64% (28/44) \ud83d\udfe1 66% (29/44) \ud83d\udfe1 86% (37/43) \ud83d\udfe1 93% (41/44) \ud83d\udfe1 89% (39/44) \u26a0\ufe0f 26 skipped network \ud83d\udfe1 75% (\u00be) \ud83d\udfe1 25% (\u00bc) \ud83d\udfe2 100% (4/4) \ud83d\udfe2 100% (4/4) \ud83d\udfe1 75% (\u00be) numerical \ud83d\udfe2 100% (1/1) \ud83d\udfe2 100% (1/1) \ud83d\udfe2 100% (1/1) \ud83d\udfe2 100% (1/1) \ud83d\udfe2 100% (1/1) port-forward \ud83d\udfe1 44% (4/9) \ud83d\udfe1 44% (4/9) \ud83d\udfe1 78% (7/9) \ud83d\udfe1 89% (8/9) \ud83d\udfe1 67% (6/9) prometheus \ud83d\udfe1 75% (\u00be) \ud83d\udfe1 75% (\u00be) \ud83d\udfe2 100% (4/4) \ud83d\udfe2 100% (4/4) \ud83d\udfe1 75% (\u00be) question-answer \ud83d\udfe2 100% (4/4) \ud83d\udfe2 100% (4/4) \ud83d\udfe2 100% (4/4) \ud83d\udfe2 100% (4/4) \ud83d\udfe2 100% (4/4) runbooks \ud83d\udfe1 83% (\u215a) \ud83d\udfe1 67% (4/6) \ud83d\udfe1 83% (\u215a) \ud83d\udfe2 100% (6/6) \ud83d\udfe1 83% (\u215a) \u26a0\ufe0f 5 skipped slackbot \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26a0\ufe0f 5 skipped traces \ud83d\udd34 0% (0/5) \ud83d\udd34 0% (0/5) \ud83d\udfe1 20% (\u2155) \ud83d\udfe2 100% (5/5) \ud83d\udfe2 100% (5/5) transparency \ud83d\udfe1 71% (10/14) \ud83d\udfe1 86% (12/14) \ud83d\udfe1 93% (13/14) \ud83d\udfe1 86% (12/14) \ud83d\udfe1 93% (13/14) \u26a0\ufe0f 5 skipped Overall \ud83d\udfe1 69% (65/94) \ud83d\udfe1 74% (70/94) \ud83d\udfe1 80% (74/93) \ud83d\udfe1 97% (91/94) \ud83d\udfe1 93% (87/94) \u26a0\ufe0f 56 skipped"},{"location":"development/evaluations/history/results_20250930_085923/#raw-results","title":"Raw Results","text":"<p>Status of all evaluations across models. Color coding:</p> <ul> <li>\ud83d\udfe2 Passing 100% (stable)</li> <li>\ud83d\udfe1 Passing 1-99%</li> <li>\ud83d\udd34 Passing 0% (failing)</li> <li>\ud83d\udd27 Mock data failure (missing or invalid test data)</li> <li>\u26a0\ufe0f Setup failure (environment/infrastructure issue)</li> <li>\u23f1\ufe0f Timeout or rate limit error</li> <li>\u23ed\ufe0f Test skipped (e.g., known issue or precondition not met)</li> </ul> Eval ID gpt-4o gpt-4.1 gpt-5 sonnet-4-20250514 sonnet-4-5-20250929 01_how_many_pods \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 02_what_is_wrong_with_pod \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 03_what_is_the_command_to_port_forward \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 04_related_k8s_events \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 05_image_version \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 09_crashpod \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 100a_historical_logs \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 100b_historical_logs_nonstandard_label \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 101_historical_logs_pod_deleted \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 103_logs_transparency_default_limit \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 104a_postgres_root_issue \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 107_log_filter_http_status_code \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 108_logs_nearby_lines \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 109_logs_transparency_not_found \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 10_image_pull_backoff \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 110_k8s_events_image_pull \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 111_disabled_datadog_traces \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 111_pod_names_contain_service \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 112_find_pvcs_by_uuid \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 114_checkout_latency_tracing_rebuild[0] \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 115_checkout_errors_tracing[0] \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 11_init_containers \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 121_new_relic_checkout_errors_tracing[0] \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 122_new_relic_checkout_latency_tracing_rebuild[0] \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 123_new_relic_checkout_errors_tracing[0] \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 12_job_crashing \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 13a_pending_node_selector_basic \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 13b_pending_node_selector_detailed \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 14_pending_resources \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 159_prometheus_high_cardinality_cpu[0] \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 159_prometheus_high_cardinality_cpu[1] \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 159_prometheus_high_cardinality_cpu[2] \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 15_failed_readiness_probe \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 16_failed_no_toolset_found \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 17_oom_kill \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 19_detect_missing_app_details \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 20_long_log_file_search \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 21_job_fail_curl_no_svc_account \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 23_app_error_in_current_logs \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 24_misconfigured_pvc \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 24a_misconfigured_pvc_basic \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 24b_misconfigured_pvc_detailed \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 25_misconfigured_ingress_class \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 26_page_render_times \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 27a_multi_container_logs \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 27b_multi_container_logs \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 28_permissions_error \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 33_cpu_metrics_discovery \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 39_failed_toolset \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 41_setup_argo \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 42_dns_issues_result_new_tools_no_runbook \ud83d\udd17 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 42_dns_issues_steps_new_tools \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \u23f1\ufe0f 43_current_datetime_from_prompt \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 45_fetch_deployment_logs_simple \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 50_logs_since_specific_date \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 50a_logs_since_last_specific_month \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 51_logs_summarize_errors \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 52_logs_login_issues \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 53_logs_find_term \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 54_not_truncated_when_getting_pods \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 57_wrong_namespace \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 59_label_based_counting \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 60_count_less_than \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 61_exact_match_counting \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 62_fetch_error_logs_with_errors \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 63_fetch_error_logs_no_errors \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 64_keda_vs_hpa_confusion \ud83d\udd17 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 65_health_check_followup \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 71_connection_pool_starvation \ud83d\udd17 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 73a_time_window_anomaly \ud83d\udd17 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 73b_time_window_anomaly \ud83d\udd17 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 76_service_discovery_issue \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \u23f1\ufe0f 77_liveness_probe_misconfiguration \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 78a_missing_cpu_limits \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 78b_cpu_quota_exceeded \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 79_configmap_mount_issue \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 80_pvc_storage_class_mismatch \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 81_service_account_permission_denied \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 82_pod_anti_affinity_conflict \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 83_secret_not_found \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 84_network_policy_blocking_traffic \ud83d\udd17 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 85_hpa_not_scaling \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 86_configmap_like_but_secret \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 89_runbook_missing_cloudwatch \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 90_runbook_basic_selection \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 91f_datadog_logs_historical_pod \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 93_calling_datadog[0] \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 93_calling_datadog[1] \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 93_calling_datadog[2] \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 94_runbook_transparency \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 96_no_matching_runbook \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 97_logs_clarification_needed \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 99_logs_transparency_custom_time \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 93_events_since_specific_date \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd27 \ud83d\udfe2 \ud83d\udfe2 44_slack_statefulset_logs \ud83d\udd17 \ud83d\udd27 \ud83d\udd27 \ud83d\udd27 \ud83d\udd27 \ud83d\udd27 48_logs_since_thursday \ud83d\udd17 \ud83d\udd27 \ud83d\udd27 \ud83d\udd27 \ud83d\udd27 \ud83d\udd27 22_high_latency_dbi_down \ud83d\udd17 \u26a0\ufe0f \u26a0\ufe0f \u26a0\ufe0f \u26a0\ufe0f \u26a0\ufe0f 08_sock_shop_frontend \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 104b_postgres_missing_index_pgstat \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 104c_postgres_minimal_missing_index \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 105_redis_wrong_data_structure \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 156_kafka_opensearch_latency \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 43_slack_deployment_logs \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 55_kafka_runbook \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 98_logs_transparency_default_time \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f SUMMARY \ud83d\udfe1 69% (65/94) \ud83d\udfe1 74% (70/94) \ud83d\udfe1 80% (74/93) \ud83d\udfe1 97% (91/94) \ud83d\udfe1 93% (87/94)"},{"location":"development/evaluations/history/results_20250930_085923/#detailed-raw-results","title":"Detailed Raw Results","text":"Eval ID gpt-4o gpt-4.1 gpt-5 sonnet-4-20250514 sonnet-4-5-20250929 01_how_many_pods \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 27.3s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 30.7s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 50.6s / \ud83d\udcb0 $0.03 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 26.7s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 27.1s / \ud83d\udcb0 $0.08 02_what_is_wrong_with_pod \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 27.0s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 40.0s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 137.4s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 43.1s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 34.7s / \ud83d\udcb0 $0.09 03_what_is_the_command_to_port_forward \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 27.5s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 41.1s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 231.3s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 35.4s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 36.3s / \ud83d\udcb0 $0.09 04_related_k8s_events \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 33.5s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 37.2s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 64.7s / \ud83d\udcb0 $0.04 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 36.1s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 36.1s / \ud83d\udcb0 $0.09 05_image_version \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 39.1s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 34.7s / \ud83d\udcb0 $0.07 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 29.8s / \ud83d\udcb0 $0.02 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 36.7s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 32.0s / \ud83d\udcb0 $0.09 09_crashpod \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 42.2s / \ud83d\udcb0 $0.16 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 39.2s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 137.1s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 160.2s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 55.0s / \ud83d\udcb0 $0.14 100a_historical_logs \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 46.8s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 45.0s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 462.7s / \ud83d\udcb0 $0.31 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 78.2s / \ud83d\udcb0 $0.17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 154.9s / \ud83d\udcb0 $0.23 100b_historical_logs_nonstandard_label \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 38.8s / \ud83d\udcb0 $0.16 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 39.7s / \ud83d\udcb0 $0.08 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 398.3s / \ud83d\udcb0 $0.29 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 136.4s / \ud83d\udcb0 $0.27 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 88.3s / \ud83d\udcb0 $0.19 101_historical_logs_pod_deleted \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 35.9s / \ud83d\udcb0 $0.13 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 73.8s / \ud83d\udcb0 $0.20 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 333.2s / \ud83d\udcb0 $0.20 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 140.9s / \ud83d\udcb0 $0.20 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 71.9s / \ud83d\udcb0 $0.15 103_logs_transparency_default_limit \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 36.7s / \ud83d\udcb0 $0.14 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 80.7s / \ud83d\udcb0 $0.29 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 98.6s / \ud83d\udcb0 $0.11 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 67.0s / \ud83d\udcb0 $0.41 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 50.8s / \ud83d\udcb0 $0.12 104a_postgres_root_issue \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 39.5s / \ud83d\udcb0 $0.17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 68.6s / \ud83d\udcb0 $0.18 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 190.6s / \ud83d\udcb0 $0.18 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 71.7s / \ud83d\udcb0 $0.19 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 60.3s / \ud83d\udcb0 $0.20 107_log_filter_http_status_code \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 45.5s / \ud83d\udcb0 $0.17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 45.8s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 235.8s / \ud83d\udcb0 $0.17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 69.1s / \ud83d\udcb0 $0.19 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 72.7s / \ud83d\udcb0 $0.27 108_logs_nearby_lines \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 36.5s / \ud83d\udcb0 $0.15 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 62.5s / \ud83d\udcb0 $0.11 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 293.6s / \ud83d\udcb0 $0.24 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 72.8s / \ud83d\udcb0 $0.21 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 88.1s / \ud83d\udcb0 $0.29 109_logs_transparency_not_found \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 85.6s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 34.3s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 140.1s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 347.6s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 51.1s / \ud83d\udcb0 $0.10 10_image_pull_backoff \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 38.3s / \ud83d\udcb0 $0.16 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 47.0s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 185.1s / \ud83d\udcb0 $0.16 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 50.2s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 50.3s / \ud83d\udcb0 $0.13 110_k8s_events_image_pull \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 31.9s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 37.7s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 102.5s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 40.0s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 44.7s / \ud83d\udcb0 $0.10 111_disabled_datadog_traces \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 16.9s / \ud83d\udcb0 $0.03 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 29.5s / \ud83d\udcb0 $0.04 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 181.3s / \ud83d\udcb0 $0.10 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 93.1s / \ud83d\udcb0 $0.20 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 23.0s / \ud83d\udcb0 $0.06 111_pod_names_contain_service \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 42.2s / \ud83d\udcb0 $0.17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 66.6s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 253.0s / \ud83d\udcb0 $0.17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 72.3s / \ud83d\udcb0 $0.22 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 63.9s / \ud83d\udcb0 $0.21 112_find_pvcs_by_uuid \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 38.6s / \ud83d\udcb0 $0.16 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 50.8s / \ud83d\udcb0 $0.28 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 143.2s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 43.5s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 42.5s / \ud83d\udcb0 $0.11 114_checkout_latency_tracing_rebuild[0] \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 38.7s / \ud83d\udcb0 $0.17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 59.3s / \ud83d\udcb0 $0.20 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 273.2s / \ud83d\udcb0 $0.25 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 99.8s / \ud83d\udcb0 $0.33 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 80.0s / \ud83d\udcb0 $0.32 115_checkout_errors_tracing[0] \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 37.4s / \ud83d\udcb0 $0.20 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 56.2s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 218.9s / \ud83d\udcb0 $0.29 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 101.9s / \ud83d\udcb0 $0.33 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 142.6s / \ud83d\udcb0 $0.49 11_init_containers \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 31.2s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 67.3s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 127.5s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 50.4s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 40.5s / \ud83d\udcb0 $0.11 121_new_relic_checkout_errors_tracing[0] \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 29.5s / \ud83d\udcb0 $0.11 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 43.0s / \ud83d\udcb0 $0.09 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 433.5s / \ud83d\udcb0 $0.24 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 256.7s / \ud83d\udcb0 $0.29 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 98.2s / \ud83d\udcb0 $0.31 122_new_relic_checkout_latency_tracing_rebuild[0] \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 38.3s / \ud83d\udcb0 $0.19 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 51.3s / \ud83d\udcb0 $0.15 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 697.1s / \ud83d\udcb0 $0.47 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 87.7s / \ud83d\udcb0 $0.42 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 152.7s / \ud83d\udcb0 $0.51 123_new_relic_checkout_errors_tracing[0] \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 47.9s / \ud83d\udcb0 $0.26 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 39.3s / \ud83d\udcb0 $0.09 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 341.5s / \ud83d\udcb0 $0.26 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 102.7s / \ud83d\udcb0 $0.32 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 133.6s / \ud83d\udcb0 $0.58 12_job_crashing \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 27.7s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 35.1s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 116.1s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 55.7s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 57.8s / \ud83d\udcb0 $0.18 13a_pending_node_selector_basic \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 31.7s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 42.6s / \ud83d\udcb0 $0.10 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 27.6s / \ud83d\udcb0 $0.02 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 49.6s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 52.5s / \ud83d\udcb0 $0.13 13b_pending_node_selector_detailed \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 35.1s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 58.2s / \ud83d\udcb0 $0.09 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 24.4s / \ud83d\udcb0 $0.02 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 53.6s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 55.4s / \ud83d\udcb0 $0.15 14_pending_resources \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 31.5s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 44.9s / \ud83d\udcb0 $0.09 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 30.9s / \ud83d\udcb0 $0.02 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 124.7s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 49.2s / \ud83d\udcb0 $0.12 159_prometheus_high_cardinality_cpu[0] \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 30.5s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 48.4s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 192.6s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 64.2s / \ud83d\udcb0 $0.21 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 50.3s / \ud83d\udcb0 $0.17 159_prometheus_high_cardinality_cpu[1] \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 41.3s / \ud83d\udcb0 $0.24 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 42.4s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 143.2s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 56.7s / \ud83d\udcb0 $0.20 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 41.4s / \ud83d\udcb0 $0.17 159_prometheus_high_cardinality_cpu[2] \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 29.2s / \ud83d\udcb0 $0.09 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 41.3s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 134.7s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 68.5s / \ud83d\udcb0 $0.23 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 43.0s / \ud83d\udcb0 $0.17 15_failed_readiness_probe \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 39.0s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 37.5s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 203.4s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 72.6s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 46.1s / \ud83d\udcb0 $0.12 16_failed_no_toolset_found \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 54.1s / \ud83d\udcb0 $0.14 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 25.2s / \ud83d\udcb0 $0.04 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 47.6s / \ud83d\udcb0 $0.03 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 25.5s / \ud83d\udcb0 $0.06 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 23.8s / \ud83d\udcb0 $0.06 17_oom_kill \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 34.5s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 61.6s / \ud83d\udcb0 $0.09 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 35.5s / \ud83d\udcb0 $0.02 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 56.5s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 42.4s / \ud83d\udcb0 $0.11 19_detect_missing_app_details \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 48.2s / \ud83d\udcb0 $0.43 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 39.3s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 242.9s / \ud83d\udcb0 $0.20 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 96.4s / \ud83d\udcb0 $0.25 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 54.5s / \ud83d\udcb0 $0.11 20_long_log_file_search \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 41.1s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 46.0s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 91.8s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 55.6s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 70.1s / \ud83d\udcb0 $0.11 21_job_fail_curl_no_svc_account \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 50.1s / \ud83d\udcb0 $0.27 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 641.0s / \ud83d\udcb0 $0.11 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 58.1s / \ud83d\udcb0 $0.02 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 56.9s / \ud83d\udcb0 $0.17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 54.0s / \ud83d\udcb0 $0.24 23_app_error_in_current_logs \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 48.1s / \ud83d\udcb0 $0.18 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 64.6s / \ud83d\udcb0 $0.18 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 206.2s / \ud83d\udcb0 $0.18 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 76.0s / \ud83d\udcb0 $0.58 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 73.5s / \ud83d\udcb0 $0.35 24_misconfigured_pvc \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 36.0s / \ud83d\udcb0 $0.16 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 52.8s / \ud83d\udcb0 $0.12 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 24.3s / \ud83d\udcb0 $0.02 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 70.9s / \ud83d\udcb0 $0.17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 61.6s / \ud83d\udcb0 $0.16 24a_misconfigured_pvc_basic \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 30.9s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 47.7s / \ud83d\udcb0 $0.12 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 30.9s / \ud83d\udcb0 $0.02 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 55.3s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 66.7s / \ud83d\udcb0 $0.16 24b_misconfigured_pvc_detailed \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 44.2s / \ud83d\udcb0 $0.20 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 74.3s / \ud83d\udcb0 $0.18 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 26.1s / \ud83d\udcb0 $0.02 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 58.7s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 156.8s / \ud83d\udcb0 $0.16 25_misconfigured_ingress_class \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 51.2s / \ud83d\udcb0 $0.11 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 51.1s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 285.5s / \ud83d\udcb0 $0.17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 83.6s / \ud83d\udcb0 $0.23 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 78.5s / \ud83d\udcb0 $0.30 26_page_render_times \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 29.7s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 48.6s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 241.1s / \ud83d\udcb0 $0.21 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 54.3s / \ud83d\udcb0 $0.17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 55.2s / \ud83d\udcb0 $0.16 27a_multi_container_logs \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 32.8s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 48.5s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 105.7s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 49.8s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 37.8s / \ud83d\udcb0 $0.12 27b_multi_container_logs \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 30.5s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 48.2s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 132.3s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 44.1s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 37.9s / \ud83d\udcb0 $0.11 28_permissions_error \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 19.7s / \ud83d\udcb0 $0.04 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 25.0s / \ud83d\udcb0 $0.05 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 92.0s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 27.6s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 23.9s / \ud83d\udcb0 $0.07 33_cpu_metrics_discovery \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 26.3s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 35.5s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 121.8s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 79.7s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 45.4s / \ud83d\udcb0 $0.13 39_failed_toolset \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 23.3s / \ud83d\udcb0 $0.03 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 41.7s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 203.3s / \ud83d\udcb0 $0.16 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 47.6s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 52.3s / \ud83d\udcb0 $0.11 41_setup_argo \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 21.3s / \ud83d\udcb0 $0.03 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 18.5s / \ud83d\udcb0 $0.02 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 170.6s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 20.0s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 21.2s / \ud83d\udcb0 $0.06 42_dns_issues_result_new_tools_no_runbook \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 42.7s / \ud83d\udcb0 $0.15 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 68.1s / \ud83d\udcb0 $0.21 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 267.0s / \ud83d\udcb0 $0.25 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 84.0s / \ud83d\udcb0 $0.18 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 119.2s / \ud83d\udcb0 $0.40 42_dns_issues_steps_new_tools \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 49.8s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 55.2s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 391.2s / \ud83d\udcb0 $0.24 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 94.6s / \ud83d\udcb0 $0.27 \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 694.5s 43_current_datetime_from_prompt \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 17.2s / \ud83d\udcb0 $0.03 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 38.3s / \ud83d\udcb0 $0.04 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 65.1s / \ud83d\udcb0 $0.04 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 18.8s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 17.7s / \ud83d\udcb0 $0.06 45_fetch_deployment_logs_simple \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 31.7s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 51.7s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 103.1s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 37.6s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 43.1s / \ud83d\udcb0 $0.11 50_logs_since_specific_date \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 13.9s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 18.5s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 144.3s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 32.2s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 25.1s / \ud83d\udcb0 $0.10 50a_logs_since_last_specific_month \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 28.6s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 34.0s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 113.9s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 50.0s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 33.8s / \ud83d\udcb0 $0.08 51_logs_summarize_errors \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 31.8s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 31.3s / \ud83d\udcb0 $0.04 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 105.5s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 40.7s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 44.0s / \ud83d\udcb0 $0.10 52_logs_login_issues \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 39.7s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 104.7s / \ud83d\udcb0 $0.44 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 47.5s / \ud83d\udcb0 $0.02 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 65.8s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 59.9s / \ud83d\udcb0 $0.11 53_logs_find_term \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 32.3s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 53.1s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 73.0s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 41.2s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 42.5s / \ud83d\udcb0 $0.14 54_not_truncated_when_getting_pods \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 33.7s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 39.0s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 237.9s / \ud83d\udcb0 $0.18 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 55.1s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 66.3s / \ud83d\udcb0 $0.13 57_wrong_namespace \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 30.9s / \ud83d\udcb0 $0.10 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 43.3s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 129.6s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 45.7s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 43.5s / \ud83d\udcb0 $0.10 59_label_based_counting \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 27.3s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 31.2s / \ud83d\udcb0 $0.05 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 98.3s / \ud83d\udcb0 $0.05 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 27.3s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 26.9s / \ud83d\udcb0 $0.08 60_count_less_than \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 35.3s / \ud83d\udcb0 $0.16 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 28.5s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 167.5s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 35.0s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 38.2s / \ud83d\udcb0 $0.09 61_exact_match_counting \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 40.3s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 31.9s / \ud83d\udcb0 $0.05 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 65.3s / \ud83d\udcb0 $0.05 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 26.6s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 26.3s / \ud83d\udcb0 $0.08 62_fetch_error_logs_with_errors \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 31.7s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 42.8s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 121.2s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 38.1s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 39.2s / \ud83d\udcb0 $0.09 63_fetch_error_logs_no_errors \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 30.6s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 33.6s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 79.7s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 35.8s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 35.4s / \ud83d\udcb0 $0.09 64_keda_vs_hpa_confusion \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 63.2s / \ud83d\udcb0 $0.22 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 54.1s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 184.6s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 117.7s / \ud83d\udcb0 $0.19 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 66.7s / \ud83d\udcb0 $0.17 65_health_check_followup \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 44.5s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 49.3s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 263.4s / \ud83d\udcb0 $0.17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 69.0s / \ud83d\udcb0 $0.21 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 70.5s / \ud83d\udcb0 $0.26 71_connection_pool_starvation \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 38.7s / \ud83d\udcb0 $0.13 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 58.8s / \ud83d\udcb0 $0.17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 161.8s / \ud83d\udcb0 $0.19 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 57.2s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 56.8s / \ud83d\udcb0 $0.17 73a_time_window_anomaly \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 42.0s / \ud83d\udcb0 $0.17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 34.0s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 157.5s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 63.5s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 64.9s / \ud83d\udcb0 $0.18 73b_time_window_anomaly \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 44.2s / \ud83d\udcb0 $0.17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 29.7s / \ud83d\udcb0 $0.05 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 91.4s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 57.3s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 62.6s / \ud83d\udcb0 $0.14 76_service_discovery_issue \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 40.5s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 60.8s / \ud83d\udcb0 $0.21 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 190.0s / \ud83d\udcb0 $0.21 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 654.9s / \ud83d\udcb0 $0.14 \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 648.9s 77_liveness_probe_misconfiguration \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 40.1s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 41.7s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 185.6s / \ud83d\udcb0 $0.19 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 48.8s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 53.5s / \ud83d\udcb0 $0.13 78a_missing_cpu_limits \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 25.9s / \ud83d\udcb0 $0.07 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 30.9s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 217.1s / \ud83d\udcb0 $0.18 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 54.7s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 58.8s / \ud83d\udcb0 $0.14 78b_cpu_quota_exceeded \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 51.1s / \ud83d\udcb0 $0.24 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 44.6s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 81.1s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 53.5s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 52.6s / \ud83d\udcb0 $0.14 79_configmap_mount_issue \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 31.2s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 43.4s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 193.0s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 46.3s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 63.1s / \ud83d\udcb0 $0.12 80_pvc_storage_class_mismatch \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 32.4s / \ud83d\udcb0 $0.11 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 49.5s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 95.6s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 81.8s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 57.5s / \ud83d\udcb0 $0.15 81_service_account_permission_denied \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 38.1s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 58.2s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 260.8s / \ud83d\udcb0 $0.17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 99.1s / \ud83d\udcb0 $0.23 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 71.0s / \ud83d\udcb0 $0.17 82_pod_anti_affinity_conflict \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 37.4s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 45.9s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 201.0s / \ud83d\udcb0 $0.23 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 61.9s / \ud83d\udcb0 $0.16 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 63.0s / \ud83d\udcb0 $0.17 83_secret_not_found \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 36.1s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 50.2s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 125.2s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 44.2s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 49.3s / \ud83d\udcb0 $0.13 84_network_policy_blocking_traffic \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 38.2s / \ud83d\udcb0 $0.17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 79.0s / \ud83d\udcb0 $0.18 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 238.0s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 99.6s / \ud83d\udcb0 $0.21 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 59.7s / \ud83d\udcb0 $0.15 85_hpa_not_scaling \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 34.6s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 42.1s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 327.4s / \ud83d\udcb0 $0.25 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 58.7s / \ud83d\udcb0 $0.17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 56.9s / \ud83d\udcb0 $0.17 86_configmap_like_but_secret \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 48.2s / \ud83d\udcb0 $0.22 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 45.2s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 334.3s / \ud83d\udcb0 $0.22 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 50.8s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 61.6s / \ud83d\udcb0 $0.16 89_runbook_missing_cloudwatch \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 30.0s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 27.4s / \ud83d\udcb0 $0.04 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 179.6s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 40.7s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 46.0s / \ud83d\udcb0 $0.10 90_runbook_basic_selection \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 52.0s / \ud83d\udcb0 $0.26 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 72.9s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 275.4s / \ud83d\udcb0 $0.20 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 202.4s / \ud83d\udcb0 $0.51 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 127.9s / \ud83d\udcb0 $0.32 91f_datadog_logs_historical_pod \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 29.0s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 40.1s / \ud83d\udcb0 $0.09 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 159.1s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 80.2s / \ud83d\udcb0 $0.22 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 67.5s / \ud83d\udcb0 $0.15 93_calling_datadog[0] \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 61.7s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 11.7s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 41.3s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 13.4s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 10.3s / \ud83d\udcb0 $0.15 93_calling_datadog[1] \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 56.5s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 12.2s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 89.5s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 11.8s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 10.4s / \ud83d\udcb0 $0.15 93_calling_datadog[2] \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 70.1s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 13.2s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 42.1s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 11.6s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 11.1s / \ud83d\udcb0 $0.15 94_runbook_transparency \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 45.4s / \ud83d\udcb0 $0.17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 63.4s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 368.3s / \ud83d\udcb0 $0.28 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 119.5s / \ud83d\udcb0 $0.29 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 79.7s / \ud83d\udcb0 $0.20 96_no_matching_runbook \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 54.3s / \ud83d\udcb0 $0.32 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 158.5s / \ud83d\udcb0 $0.46 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 326.2s / \ud83d\udcb0 $0.28 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 106.8s / \ud83d\udcb0 $0.38 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 122.3s / \ud83d\udcb0 $0.35 97_logs_clarification_needed \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 15.5s / \ud83d\udcb0 $0.03 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 21.5s / \ud83d\udcb0 $0.04 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 27.1s / \ud83d\udcb0 $0.02 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 50.5s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 19.7s / \ud83d\udcb0 $0.06 99_logs_transparency_custom_time \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 32.8s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 39.6s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 88.3s / \ud83d\udcb0 $0.05 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 51.1s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 56.5s / \ud83d\udcb0 $0.10 93_events_since_specific_date \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 9.4s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 16.3s / \ud83d\udcb0 $0.07 \u26aa\ufe0f - \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 17.8s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 14.6s / \ud83d\udcb0 $0.09 44_slack_statefulset_logs \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 48_logs_since_thursday \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 22_high_latency_dbi_down \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 08_sock_shop_frontend \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 104b_postgres_missing_index_pgstat \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 104c_postgres_minimal_missing_index \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 105_redis_wrong_data_structure \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 156_kafka_opensearch_latency \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 43_slack_deployment_logs \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 55_kafka_runbook \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 98_logs_transparency_default_time \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - <p>Results are automatically generated and updated weekly. View full traces and detailed analysis in Braintrust experiment: local-benchmark-20250930-072258.</p>"},{"location":"development/evaluations/history/results_20251012_170303/","title":"October 12, 2025","text":"<p>Generated: 2025-10-12 17:03 UTC</p> <p>Total Duration: 1h 48m 23s</p> <p>Iterations: 1</p> <p>Judge (classifier) model: azure/gpt-4.1</p>"},{"location":"development/evaluations/history/results_20251012_170303/#about-this-benchmark","title":"About this Benchmark","text":"<p>HolmesGPT is continuously evaluated against real-world Kubernetes and cloud troubleshooting scenarios.</p> <p>If you find scenarios that HolmesGPT does not perform well on, please consider adding them as evals to the benchmark.</p>"},{"location":"development/evaluations/history/results_20251012_170303/#model-accuracy-comparison","title":"Model Accuracy Comparison","text":"Model Pass Fail Skip/Error Total Success Rate gpt-4o 52 41 12 105 \ud83d\udfe1 56% (52/93) eu.anthropic.claude-sonnet-4-20250514-v1:0 82 13 10 105 \ud83d\udfe1 86% (82/95) gpt-4.1 67 27 11 105 \ud83d\udfe1 71% (67/94) gpt-5 74 20 11 105 \ud83d\udfe1 79% (74/94) novita/deepseek/deepseek-v3.1-terminus 75 20 10 105 \ud83d\udfe1 79% (75/95) novita/qwen/qwen3-next-80b-a3b-instruct 55 40 10 105 \ud83d\udfe1 58% (55/95)"},{"location":"development/evaluations/history/results_20251012_170303/#model-cost-comparison","title":"Model Cost Comparison","text":"Model Tests Avg Cost Min Cost Max Cost Total Cost gpt-4o 93 $0.18 $0.03 $1.00 $16.67 eu.anthropic.claude-sonnet-4-20250514-v1:0 93 $0.25 $0.06 $1.01 $22.85 gpt-4.1 94 $0.11 $0.02 $0.66 $10.68 gpt-5 94 $0.19 $0.02 $0.59 $17.43"},{"location":"development/evaluations/history/results_20251012_170303/#model-latency-comparison","title":"Model Latency Comparison","text":"Model Avg (s) Min (s) Max (s) P50 (s) P95 (s) gpt-4o 26.6 8.0 67.1 25.9 55.3 eu.anthropic.claude-sonnet-4-20250514-v1:0 48.9 9.8 263.9 43.4 100.8 gpt-4.1 40.7 5.5 645.1 25.4 51.7 gpt-5 138.5 17.4 859.1 81.6 752.3 novita/deepseek/deepseek-v3.1-terminus 75.5 21.1 221.1 71.1 142.2 novita/qwen/qwen3-next-80b-a3b-instruct 82.8 12.0 1100.6 34.8 296.6 <p>\u26a0\ufe0f Note: 7 test(s) excluded from latency calculations due to throttling/timeout errors (eu.anthropic.claude-sonnet-4-20250514-v1:0: 2, novita/qwen/qwen3-next-80b-a3b-instruct: 5)</p>"},{"location":"development/evaluations/history/results_20251012_170303/#performance-by-tag","title":"Performance by Tag","text":"<p>Success rate by test category and model:</p> Tag gpt-4o eu.anthropic.claude-sonnet-4-20250514-v1:0 gpt-4.1 gpt-5 novita/deepseek/deepseek-v3.1-terminus novita/qwen/qwen3-next-80b-a3b-instruct Warnings chain-of-causation \ud83d\udd34 0% (0/7) \ud83d\udfe1 71% (5/7) \ud83d\udd34 0% (0/7) \ud83d\udfe1 57% (4/7) \ud83d\udfe1 29% (2/7) \ud83d\udfe1 14% (1/7) \u26a0\ufe0f 6 skipped context_window \ud83d\udfe1 14% (1/7) \ud83d\udfe1 57% (4/7) \ud83d\udfe1 57% (4/7) \ud83d\udfe1 86% (6/7) \ud83d\udfe1 57% (4/7) \ud83d\udfe1 29% (2/7) counting \ud83d\udfe2 100% (4/4) \ud83d\udfe2 100% (4/4) \ud83d\udfe2 100% (4/4) \ud83d\udfe1 75% (\u00be) \ud83d\udfe2 100% (4/4) \ud83d\udfe2 100% (4/4) database \ud83d\udd34 0% (0/1) \ud83d\udfe2 100% (1/1) \ud83d\udd34 0% (0/1) \ud83d\udfe2 100% (1/1) \ud83d\udfe2 100% (1/1) \ud83d\udfe2 100% (1/1) \u26a0\ufe0f 18 skipped datadog \ud83d\udfe1 67% (\u2154) \ud83d\udfe1 75% (\u00be) \ud83d\udfe1 75% (\u00be) \ud83d\udfe1 75% (\u00be) \ud83d\udfe1 75% (\u00be) \ud83d\udfe1 75% (\u00be) \u26a0\ufe0f 1 skipped datetime \ud83d\udfe1 50% (2/4) \ud83d\udfe1 50% (2/4) \ud83d\udfe1 50% (2/4) \ud83d\udfe2 100% (4/4) \ud83d\udfe1 75% (\u00be) \ud83d\udfe1 50% (2/4) \u26a0\ufe0f 12 skipped easy \ud83d\udfe1 91% (32/35) \ud83d\udfe1 92% (33/36) \ud83d\udfe1 97% (35/36) \ud83d\udfe1 83% (30/36) \ud83d\udfe1 94% (34/36) \ud83d\udfe1 86% (31/36) \u26a0\ufe0f 1 skipped hard \ud83d\udfe1 20% (3/15) \ud83d\udfe1 80% (12/15) \ud83d\udfe1 20% (3/15) \ud83d\udfe1 47% (7/15) \ud83d\udfe1 47% (7/15) \ud83d\udfe1 40% (6/15) \u26a0\ufe0f 30 skipped kafka \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26a0\ufe0f 12 skipped kubernetes \ud83d\udfe1 49% (23/47) \ud83d\udfe1 85% (40/47) \ud83d\udfe1 66% (31/47) \ud83d\udfe1 79% (37/47) \ud83d\udfe1 72% (34/47) \ud83d\udfe1 55% (26/47) \u26a0\ufe0f 6 skipped logs \ud83d\udfe1 46% (12/26) \ud83d\udfe1 78% (21/27) \ud83d\udfe1 62% (16/26) \ud83d\udfe1 74% (20/27) \ud83d\udfe1 74% (20/27) \ud83d\udfe1 44% (12/27) \u26a0\ufe0f 38 skipped medium \ud83d\udfe1 40% (17/43) \ud83d\udfe1 84% (37/44) \ud83d\udfe1 67% (29/43) \ud83d\udfe1 86% (37/43) \ud83d\udfe1 77% (34/44) \ud83d\udfe1 41% (18/44) \u26a0\ufe0f 33 skipped network \ud83d\udfe1 75% (\u00be) \ud83d\udfe2 100% (4/4) \ud83d\udfe1 75% (\u00be) \ud83d\udfe1 75% (\u00be) \ud83d\udfe2 100% (4/4) \ud83d\udfe2 100% (4/4) no-cicd \ud83d\udfe2 100% (1/1) \ud83d\udd34 0% (0/1) \ud83d\udfe2 100% (1/1) \ud83d\udfe2 100% (1/1) \ud83d\udfe2 100% (1/1) \ud83d\udfe2 100% (1/1) numerical \ud83d\udfe2 100% (1/1) \ud83d\udfe2 100% (1/1) \ud83d\udfe2 100% (1/1) \ud83d\udfe2 100% (1/1) \ud83d\udfe2 100% (1/1) \ud83d\udfe2 100% (1/1) port-forward \ud83d\udfe1 22% (2/9) \ud83d\udfe1 67% (6/9) \ud83d\udfe1 56% (5/9) \ud83d\udfe1 67% (6/9) \ud83d\udfe1 22% (2/9) \ud83d\udfe1 22% (2/9) prometheus \ud83d\udfe1 25% (\u00bc) \ud83d\udfe1 75% (\u00be) \ud83d\udfe2 100% (4/4) \ud83d\udfe2 100% (4/4) \ud83d\udfe1 50% (2/4) \ud83d\udfe1 25% (\u00bc) question-answer \ud83d\udfe1 75% (\u00be) \ud83d\udfe2 100% (4/4) \ud83d\udfe2 100% (4/4) \ud83d\udfe2 100% (4/4) \ud83d\udfe2 100% (4/4) \ud83d\udfe1 75% (\u00be) runbooks \ud83d\udfe1 67% (4/6) \ud83d\udfe2 100% (6/6) \ud83d\udfe1 83% (\u215a) \ud83d\udfe2 100% (6/6) \ud83d\udfe2 100% (6/6) \ud83d\udfe1 67% (4/6) \u26a0\ufe0f 6 skipped slackbot \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26a0\ufe0f 6 skipped traces \ud83d\udd34 0% (0/5) \ud83d\udfe1 60% (\u2157) \ud83d\udd34 0% (0/5) \ud83d\udfe1 80% (\u2158) \ud83d\udd34 0% (0/5) \ud83d\udd34 0% (0/5) transparency \ud83d\udfe1 79% (11/14) \ud83d\udfe1 93% (13/14) \ud83d\udfe1 93% (13/14) \ud83d\udfe1 86% (12/14) \ud83d\udfe1 71% (10/14) \ud83d\udfe1 43% (6/14) \u26a0\ufe0f 6 skipped Overall \ud83d\udfe1 56% (52/93) \ud83d\udfe1 86% (82/95) \ud83d\udfe1 71% (67/94) \ud83d\udfe1 79% (74/94) \ud83d\udfe1 79% (75/95) \ud83d\udfe1 58% (55/95) \u26a0\ufe0f 64 skipped"},{"location":"development/evaluations/history/results_20251012_170303/#raw-results","title":"Raw Results","text":"<p>Status of all evaluations across models. Color coding:</p> <ul> <li>\ud83d\udfe2 Passing 100% (stable)</li> <li>\ud83d\udfe1 Passing 1-99%</li> <li>\ud83d\udd34 Passing 0% (failing)</li> <li>\ud83d\udd27 Mock data failure (missing or invalid test data)</li> <li>\u26a0\ufe0f Setup failure (environment/infrastructure issue)</li> <li>\u23f1\ufe0f Timeout or rate limit error</li> <li>\u23ed\ufe0f Test skipped (e.g., known issue or precondition not met)</li> </ul> Eval ID gpt-4o eu.anthropic.claude-sonnet-4-20250514-v1:0 gpt-4.1 gpt-5 novita/deepseek/deepseek-v3.1-terminus novita/qwen/qwen3-next-80b-a3b-instruct 01_how_many_pods \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 02_what_is_wrong_with_pod \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 03_what_is_the_command_to_port_forward \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 04_related_k8s_events \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 05_image_version \ud83d\udd17 \ud83d\udfe2 \u23f1\ufe0f \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 08_sock_shop_frontend \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 09_crashpod \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 100a_historical_logs \ud83d\udd17 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 100b_historical_logs_nonstandard_label \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 101_historical_logs_pod_deleted \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 103_logs_transparency_default_limit \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 104a_postgres_root_issue \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 104b_postgres_missing_index_pgstat \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 104c_postgres_minimal_missing_index \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 105_redis_wrong_data_structure \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 107_log_filter_http_status_code \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 108_logs_nearby_lines \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 109_logs_transparency_not_found \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 10_image_pull_backoff \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 110_k8s_events_image_pull \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 111_disabled_datadog_traces \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 111_pod_names_contain_service \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 112_find_pvcs_by_uuid \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 114_checkout_latency_tracing_rebuild[0] \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 115_checkout_errors_tracing[0] \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udd34 11_init_containers \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 121_new_relic_checkout_errors_tracing[0] \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udd34 122_new_relic_checkout_latency_tracing_rebuild[0] \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udd34 123_new_relic_checkout_errors_tracing[0] \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udd34 12_job_crashing \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \u23f1\ufe0f 13a_pending_node_selector_basic \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 13b_pending_node_selector_detailed \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 14_pending_resources \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 156_kafka_opensearch_latency \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 159_prometheus_high_cardinality_cpu[0] \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udd34 159_prometheus_high_cardinality_cpu[1] \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 159_prometheus_high_cardinality_cpu[2] \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udd34 15_failed_readiness_probe \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 16_failed_no_toolset_found \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 17_oom_kill \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 19_detect_missing_app_details \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 20_long_log_file_search \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 21_job_fail_curl_no_svc_account \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 22_high_latency_dbi_down \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 23_app_error_in_current_logs \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 24_misconfigured_pvc \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 24a_misconfigured_pvc_basic \ud83d\udd17 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 24b_misconfigured_pvc_detailed \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 25_misconfigured_ingress_class \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 26_page_render_times \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 27a_multi_container_logs \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 27b_multi_container_logs \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 28_permissions_error \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 33_cpu_metrics_discovery \ud83d\udd17 \ud83d\udfe2 \u23f1\ufe0f \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 39_failed_toolset \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udd34 41_setup_argo \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 42_dns_issues_result_new_tools_no_runbook \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 42_dns_issues_steps_new_tools \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 43_current_datetime_from_prompt \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 43_slack_deployment_logs \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 44_slack_statefulset_logs \ud83d\udd17 \ud83d\udd27 \ud83d\udd27 \ud83d\udd27 \ud83d\udd27 \ud83d\udd27 \ud83d\udd27 45_fetch_deployment_logs_simple \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 48_logs_since_thursday \ud83d\udd17 \ud83d\udd27 \ud83d\udd27 \ud83d\udd27 \ud83d\udd27 \ud83d\udd27 \ud83d\udd27 50_logs_since_specific_date \ud83d\udd17 \ud83d\udd27 \ud83d\udfe2 \ud83d\udd27 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 50a_logs_since_last_specific_month \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 51_logs_summarize_errors \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 52_logs_login_issues \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 53_logs_find_term \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 54_not_truncated_when_getting_pods \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 55_kafka_runbook \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 57_wrong_namespace \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 59_label_based_counting \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 60_count_less_than \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 61_exact_match_counting \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 62_fetch_error_logs_with_errors \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 63_fetch_error_logs_no_errors \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 64_keda_vs_hpa_confusion \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 65_health_check_followup \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 71_connection_pool_starvation \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 73a_time_window_anomaly \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 73b_time_window_anomaly \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udd34 76_service_discovery_issue \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 77_liveness_probe_misconfiguration \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 78a_missing_cpu_limits \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \u23f1\ufe0f 78b_cpu_quota_exceeded \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 79_configmap_mount_issue \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 80_pvc_storage_class_mismatch \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 81_service_account_permission_denied \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 82_pod_anti_affinity_conflict \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udd34 83_secret_not_found \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 84_network_policy_blocking_traffic \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 85_hpa_not_scaling \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 86_configmap_like_but_secret \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 89_runbook_missing_cloudwatch \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 90_runbook_basic_selection \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 91f_datadog_logs_historical_pod \ud83d\udd17 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 93_calling_datadog[0] \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 93_calling_datadog[1] \ud83d\udd17 \ud83d\udd27 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 93_calling_datadog[2] \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 93_events_since_specific_date \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd27 \ud83d\udfe2 \ud83d\udfe2 94_runbook_transparency \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 96_no_matching_runbook \ud83d\udd17 \ud83d\udd34 \ud83d\udfe2 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 97_logs_clarification_needed \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udd34 98_logs_transparency_default_time \ud83d\udd17 \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f \u23ed\ufe0f 99_logs_transparency_custom_time \ud83d\udd17 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 SUMMARY \ud83d\udfe1 56% (52/93) \ud83d\udfe1 86% (82/95) \ud83d\udfe1 71% (67/94) \ud83d\udfe1 79% (74/94) \ud83d\udfe1 79% (75/95) \ud83d\udfe1 58% (55/95)"},{"location":"development/evaluations/history/results_20251012_170303/#detailed-raw-results","title":"Detailed Raw Results","text":"Eval ID gpt-4o eu.anthropic.claude-sonnet-4-20250514-v1:0 gpt-4.1 gpt-5 novita/deepseek/deepseek-v3.1-terminus novita/qwen/qwen3-next-80b-a3b-instruct 01_how_many_pods \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 21.6s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 21.4s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 20.6s / \ud83d\udcb0 $0.05 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 26.4s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 27.3s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 15.4s 02_what_is_wrong_with_pod \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 30.4s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 35.6s / \ud83d\udcb0 $0.17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 26.4s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 63.6s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 75.8s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 31.6s 03_what_is_the_command_to_port_forward \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 26.0s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 29.0s / \ud83d\udcb0 $0.16 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 26.3s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 58.9s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 43.8s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 24.1s 04_related_k8s_events \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 18.2s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 30.9s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 22.4s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 51.7s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 44.6s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 27.4s 05_image_version \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 16.2s / \ud83d\udcb0 $0.07 \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 621.2s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 23.3s / \ud83d\udcb0 $0.07 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 20.2s / \ud83d\udcb0 $0.02 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 45.7s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 22.1s 08_sock_shop_frontend \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 09_crashpod \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 55.3s / \ud83d\udcb0 $0.20 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 43.7s / \ud83d\udcb0 $0.21 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 631.4s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 53.6s / \ud83d\udcb0 $0.19 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 74.5s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 30.1s 100a_historical_logs \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 23.7s / \ud83d\udcb0 $0.15 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 83.8s / \ud83d\udcb0 $0.35 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 24.2s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 859.1s / \ud83d\udcb0 $0.49 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 86.2s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 49.2s 100b_historical_logs_nonstandard_label \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 29.7s / \ud83d\udcb0 $0.20 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 94.3s / \ud83d\udcb0 $0.39 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 23.2s / \ud83d\udcb0 $0.11 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 171.0s / \ud83d\udcb0 $0.28 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 83.4s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 77.2s 101_historical_logs_pod_deleted \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 22.2s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 60.1s / \ud83d\udcb0 $0.32 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 27.5s / \ud83d\udcb0 $0.11 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 191.0s / \ud83d\udcb0 $0.32 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 93.8s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 164.4s 103_logs_transparency_default_limit \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 22.4s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 37.3s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 29.3s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 44.2s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 64.4s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 65.1s 104a_postgres_root_issue \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 30.5s / \ud83d\udcb0 $0.23 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 55.5s / \ud83d\udcb0 $0.39 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 48.6s / \ud83d\udcb0 $0.21 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 191.3s / \ud83d\udcb0 $0.48 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 94.5s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 62.8s 104b_postgres_missing_index_pgstat \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 104c_postgres_minimal_missing_index \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 105_redis_wrong_data_structure \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 107_log_filter_http_status_code \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 31.7s / \ud83d\udcb0 $0.20 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 70.4s / \ud83d\udcb0 $0.28 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 25.4s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 192.2s / \ud83d\udcb0 $0.35 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 123.2s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 161.0s 108_logs_nearby_lines \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 29.3s / \ud83d\udcb0 $0.22 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 50.8s / \ud83d\udcb0 $0.40 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 32.6s / \ud83d\udcb0 $0.30 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 159.7s / \ud83d\udcb0 $0.27 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 106.3s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 71.5s 109_logs_transparency_not_found \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 26.5s / \ud83d\udcb0 $0.19 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 29.1s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 24.3s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 72.9s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 71.2s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 49.0s 10_image_pull_backoff \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 30.4s / \ud83d\udcb0 $0.23 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 44.6s / \ud83d\udcb0 $0.25 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 33.1s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 93.5s / \ud83d\udcb0 $0.23 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 56.9s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 71.5s 110_k8s_events_image_pull \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 23.4s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 31.2s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 23.8s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 46.3s / \ud83d\udcb0 $0.05 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 82.9s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 31.2s 111_disabled_datadog_traces \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 14.9s / \ud83d\udcb0 $0.03 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 27.0s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 14.3s / \ud83d\udcb0 $0.02 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 128.7s / \ud83d\udcb0 $0.15 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 66.3s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 23.2s 111_pod_names_contain_service \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 25.1s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 56.4s / \ud83d\udcb0 $0.25 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 37.5s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 146.3s / \ud83d\udcb0 $0.18 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 57.3s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 34.8s 112_find_pvcs_by_uuid \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 17.3s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 41.7s / \ud83d\udcb0 $0.23 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 30.1s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 53.9s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 65.8s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 36.7s 114_checkout_latency_tracing_rebuild[0] \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 65.7s / \ud83d\udcb0 $1.00 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 66.8s / \ud83d\udcb0 $0.55 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 27.6s / \ud83d\udcb0 $0.17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 206.5s / \ud83d\udcb0 $0.51 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 221.1s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 81.1s 115_checkout_errors_tracing[0] \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 67.1s / \ud83d\udcb0 $0.77 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 76.9s / \ud83d\udcb0 $0.52 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 645.1s / \ud83d\udcb0 $0.23 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 167.7s / \ud83d\udcb0 $0.40 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 135.7s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 81.0s 11_init_containers \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 25.4s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 44.8s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 27.8s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 90.8s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 69.0s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 33.2s 121_new_relic_checkout_errors_tracing[0] \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 25.9s / \ud83d\udcb0 $0.16 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 100.3s / \ud83d\udcb0 $0.44 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 21.2s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 208.5s / \ud83d\udcb0 $0.35 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 66.4s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 240.6s 122_new_relic_checkout_latency_tracing_rebuild[0] \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 23.0s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 105.7s / \ud83d\udcb0 $0.55 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 33.1s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 153.9s / \ud83d\udcb0 $0.35 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 146.8s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 956.2s 123_new_relic_checkout_errors_tracing[0] \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 17.4s / \ud83d\udcb0 $0.07 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 124.9s / \ud83d\udcb0 $0.69 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 24.8s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 225.8s / \ud83d\udcb0 $0.58 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 38.4s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 22.8s 12_job_crashing \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 28.1s / \ud83d\udcb0 $0.18 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 49.4s / \ud83d\udcb0 $0.21 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 28.5s / \ud83d\udcb0 $0.11 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 82.8s / \ud83d\udcb0 $0.16 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 112.4s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 489.4s 13a_pending_node_selector_basic \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 25.4s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 41.3s / \ud83d\udcb0 $0.21 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 28.1s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 99.5s / \ud83d\udcb0 $0.20 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 87.1s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 404.9s 13b_pending_node_selector_detailed \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 30.8s / \ud83d\udcb0 $0.18 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 43.7s / \ud83d\udcb0 $0.20 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 33.5s / \ud83d\udcb0 $0.11 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 21.8s / \ud83d\udcb0 $0.02 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 91.1s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 18.3s 14_pending_resources \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 33.7s / \ud83d\udcb0 $0.28 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 48.2s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 24.2s / \ud83d\udcb0 $0.11 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 24.3s / \ud83d\udcb0 $0.02 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 77.0s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 74.3s 156_kafka_opensearch_latency \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 159_prometheus_high_cardinality_cpu[0] \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 60.9s / \ud83d\udcb0 $0.67 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 43.9s / \ud83d\udcb0 $0.28 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 28.9s / \ud83d\udcb0 $0.16 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 163.2s / \ud83d\udcb0 $0.22 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 63.2s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 34.7s 159_prometheus_high_cardinality_cpu[1] \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 31.9s / \ud83d\udcb0 $0.28 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 45.1s / \ud83d\udcb0 $0.20 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 25.0s / \ud83d\udcb0 $0.22 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 108.4s / \ud83d\udcb0 $0.19 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 168.3s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 41.9s 159_prometheus_high_cardinality_cpu[2] \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 30.4s / \ud83d\udcb0 $0.25 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 39.0s / \ud83d\udcb0 $0.36 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 25.0s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 81.4s / \ud83d\udcb0 $0.10 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 64.5s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 296.6s 15_failed_readiness_probe \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 28.2s / \ud83d\udcb0 $0.19 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 46.3s / \ud83d\udcb0 $0.28 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 23.8s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 71.4s / \ud83d\udcb0 $0.19 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 77.8s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 31.7s 16_failed_no_toolset_found \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 20.8s / \ud83d\udcb0 $0.07 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 19.2s / \ud83d\udcb0 $0.06 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 15.9s / \ud83d\udcb0 $0.03 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 39.8s / \ud83d\udcb0 $0.04 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 91.0s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 15.3s 17_oom_kill \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 26.0s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 43.4s / \ud83d\udcb0 $0.25 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 23.4s / \ud83d\udcb0 $0.05 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 112.1s / \ud83d\udcb0 $0.17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 68.3s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 43.7s 19_detect_missing_app_details \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 29.5s / \ud83d\udcb0 $0.18 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 69.4s / \ud83d\udcb0 $0.23 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 38.7s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 65.8s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 75.0s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 710.0s 20_long_log_file_search \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 33.7s / \ud83d\udcb0 $0.19 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 69.7s / \ud83d\udcb0 $0.25 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 29.3s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 81.6s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 111.8s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 29.0s 21_job_fail_curl_no_svc_account \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 30.3s / \ud83d\udcb0 $0.22 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 39.9s / \ud83d\udcb0 $0.20 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 26.5s / \ud83d\udcb0 $0.09 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 19.8s / \ud83d\udcb0 $0.02 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 67.5s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 35.9s 22_high_latency_dbi_down \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 55.4s / \ud83d\udcb0 $0.57 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 78.8s / \ud83d\udcb0 $0.51 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 31.4s / \ud83d\udcb0 $0.16 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 118.0s / \ud83d\udcb0 $0.24 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 87.5s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 17.2s 23_app_error_in_current_logs \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 29.1s / \ud83d\udcb0 $0.19 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 44.9s / \ud83d\udcb0 $0.26 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 36.1s / \ud83d\udcb0 $0.17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 151.8s / \ud83d\udcb0 $0.28 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 82.7s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 78.2s 24_misconfigured_pvc \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 29.1s / \ud83d\udcb0 $0.21 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 50.7s / \ud83d\udcb0 $0.24 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 32.2s / \ud83d\udcb0 $0.14 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 18.8s / \ud83d\udcb0 $0.02 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 97.4s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 31.1s 24a_misconfigured_pvc_basic \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 33.4s / \ud83d\udcb0 $0.23 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 38.2s / \ud83d\udcb0 $0.17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 27.2s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 91.2s / \ud83d\udcb0 $0.15 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 34.0s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 40.2s 24b_misconfigured_pvc_detailed \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 23.8s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 41.3s / \ud83d\udcb0 $0.13 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 31.2s / \ud83d\udcb0 $0.11 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 19.6s / \ud83d\udcb0 $0.02 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 88.1s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 32.7s 25_misconfigured_ingress_class \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 13.5s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 263.9s / \ud83d\udcb0 $0.42 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 14.5s / \ud83d\udcb0 $0.06 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 243.1s / \ud83d\udcb0 $0.21 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 112.8s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 201.1s 26_page_render_times \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 23.8s / \ud83d\udcb0 $0.18 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 40.9s / \ud83d\udcb0 $0.28 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 22.7s / \ud83d\udcb0 $0.16 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 771.7s / \ud83d\udcb0 $0.32 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 64.3s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 26.3s 27a_multi_container_logs \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 12.6s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 30.5s / \ud83d\udcb0 $0.12 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 11.8s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 61.5s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 56.4s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 38.5s 27b_multi_container_logs \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 21.4s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 31.7s / \ud83d\udcb0 $0.20 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 27.3s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 76.7s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 37.5s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 22.7s 28_permissions_error \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 15.5s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 19.7s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 18.2s / \ud83d\udcb0 $0.06 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 40.2s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 29.7s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 25.3s 33_cpu_metrics_discovery \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 20.6s / \ud83d\udcb0 $0.13 \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 622.2s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 23.7s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 69.7s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 148.6s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 17.5s 39_failed_toolset \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 17.7s / \ud83d\udcb0 $0.03 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 45.2s / \ud83d\udcb0 $0.18 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 17.2s / \ud83d\udcb0 $0.02 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 147.5s / \ud83d\udcb0 $0.34 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 78.1s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 692.3s 41_setup_argo \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 14.9s / \ud83d\udcb0 $0.03 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 19.9s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 17.0s / \ud83d\udcb0 $0.03 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 70.2s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 37.5s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 140.8s 42_dns_issues_result_new_tools_no_runbook \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 27.0s / \ud83d\udcb0 $0.23 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 80.7s / \ud83d\udcb0 $0.53 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 39.4s / \ud83d\udcb0 $0.29 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 166.8s / \ud83d\udcb0 $0.28 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 111.3s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 105.4s 42_dns_issues_steps_new_tools \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 46.1s / \ud83d\udcb0 $0.26 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 100.8s / \ud83d\udcb0 $0.33 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 51.7s / \ud83d\udcb0 $0.23 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 260.1s / \ud83d\udcb0 $0.22 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 109.7s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 105.5s 43_current_datetime_from_prompt \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 15.2s / \ud83d\udcb0 $0.03 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 14.8s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 16.5s / \ud83d\udcb0 $0.04 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 29.8s / \ud83d\udcb0 $0.02 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 26.1s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 22.3s 43_slack_deployment_logs \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 44_slack_statefulset_logs \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 45_fetch_deployment_logs_simple \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 42.0s / \ud83d\udcb0 $0.40 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 31.2s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 24.5s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 652.0s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 55.6s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 24.3s 48_logs_since_thursday \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 50_logs_since_specific_date \ud83d\udd17 \u26aa\ufe0f - \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 23.6s / \ud83d\udcb0 $0.12 \u26aa\ufe0f - \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 41.4s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 37.8s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 14.7s 50a_logs_since_last_specific_month \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 24.4s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 38.9s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 20.0s / \ud83d\udcb0 $0.05 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 90.4s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 84.0s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 17.2s 51_logs_summarize_errors \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 25.6s / \ud83d\udcb0 $0.16 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 33.8s / \ud83d\udcb0 $0.16 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 26.9s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 49.7s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 60.2s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 41.3s 52_logs_login_issues \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 27.6s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 45.2s / \ud83d\udcb0 $0.18 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 32.0s / \ud83d\udcb0 $0.14 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 26.7s / \ud83d\udcb0 $0.03 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 69.1s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 1100.6s 53_logs_find_term \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 28.1s / \ud83d\udcb0 $0.18 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 35.6s / \ud83d\udcb0 $0.19 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 25.4s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 52.1s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 60.0s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 26.3s 54_not_truncated_when_getting_pods \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 17.5s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 42.0s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 31.4s / \ud83d\udcb0 $0.13 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 770.4s / \ud83d\udcb0 $0.59 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 71.1s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 28.9s 55_kafka_runbook \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 57_wrong_namespace \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 23.2s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 33.2s / \ud83d\udcb0 $0.16 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 23.0s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 75.3s / \ud83d\udcb0 $0.16 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 52.2s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 654.0s 59_label_based_counting \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 19.7s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 21.9s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 21.2s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 27.7s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 34.7s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 22.2s 60_count_less_than \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 20.3s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 22.6s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 20.8s / \ud83d\udcb0 $0.06 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 29.4s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 60.8s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 20.2s 61_exact_match_counting \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 20.9s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 22.7s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 21.7s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 28.5s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 32.4s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 24.5s 62_fetch_error_logs_with_errors \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 25.6s / \ud83d\udcb0 $0.17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 31.8s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 24.5s / \ud83d\udcb0 $0.07 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 27.6s / \ud83d\udcb0 $0.03 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 41.8s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 38.5s 63_fetch_error_logs_no_errors \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 24.1s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 34.9s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 23.8s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 48.8s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 57.6s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 24.2s 64_keda_vs_hpa_confusion \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 15.0s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 61.9s / \ud83d\udcb0 $0.32 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 20.3s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 96.1s / \ud83d\udcb0 $0.21 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 68.2s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 21.0s 65_health_check_followup \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 26.7s / \ud83d\udcb0 $0.16 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 62.2s / \ud83d\udcb0 $0.41 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 33.9s / \ud83d\udcb0 $0.19 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 129.9s / \ud83d\udcb0 $0.31 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 89.4s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 188.2s 71_connection_pool_starvation \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 30.3s / \ud83d\udcb0 $0.20 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 47.1s / \ud83d\udcb0 $0.40 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 25.2s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 62.5s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 117.1s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 128.1s 73a_time_window_anomaly \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 29.9s / \ud83d\udcb0 $0.22 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 48.6s / \ud83d\udcb0 $0.23 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 30.9s / \ud83d\udcb0 $0.22 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 57.6s / \ud83d\udcb0 $0.16 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 62.2s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 28.9s 73b_time_window_anomaly \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 28.0s / \ud83d\udcb0 $0.17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 40.9s / \ud83d\udcb0 $0.37 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 31.9s / \ud83d\udcb0 $0.21 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 70.3s / \ud83d\udcb0 $0.16 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 59.1s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 30.3s 76_service_discovery_issue \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 42.4s / \ud83d\udcb0 $0.38 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 47.7s / \ud83d\udcb0 $0.23 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 164.0s / \ud83d\udcb0 $0.36 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 86.5s / \ud83d\udcb0 $0.17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 71.6s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 47.2s 77_liveness_probe_misconfiguration \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 20.0s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 49.1s / \ud83d\udcb0 $0.24 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 25.4s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 102.5s / \ud83d\udcb0 $0.25 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 77.9s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 34.7s 78a_missing_cpu_limits \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 22.3s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 36.6s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 27.2s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 92.4s / \ud83d\udcb0 $0.16 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 85.5s \u23f1\ufe0f 0% (0/1) / \u23f1\ufe0f 307.2s 78b_cpu_quota_exceeded \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 26.6s / \ud83d\udcb0 $0.23 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 49.4s / \ud83d\udcb0 $0.21 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 26.8s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 94.9s / \ud83d\udcb0 $0.23 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 82.9s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 39.9s 79_configmap_mount_issue \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 32.5s / \ud83d\udcb0 $0.23 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 37.6s / \ud83d\udcb0 $0.18 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 25.2s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 51.5s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 47.5s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 27.6s 80_pvc_storage_class_mismatch \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 32.3s / \ud83d\udcb0 $0.20 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 43.7s / \ud83d\udcb0 $0.20 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 30.7s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 104.7s / \ud83d\udcb0 $0.23 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 54.2s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 104.6s 81_service_account_permission_denied \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 26.0s / \ud83d\udcb0 $0.17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 53.9s / \ud83d\udcb0 $0.27 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 34.6s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 73.2s / \ud83d\udcb0 $0.26 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 103.4s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 30.6s 82_pod_anti_affinity_conflict \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 26.2s / \ud83d\udcb0 $0.18 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 60.0s / \ud83d\udcb0 $0.24 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 20.5s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 106.8s / \ud83d\udcb0 $0.19 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 103.4s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 43.4s 83_secret_not_found \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 31.3s / \ud83d\udcb0 $0.20 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 42.7s / \ud83d\udcb0 $0.20 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 22.7s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 752.3s / \ud83d\udcb0 $0.33 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 70.7s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 51.0s 84_network_policy_blocking_traffic \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 32.7s / \ud83d\udcb0 $0.24 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 60.2s / \ud83d\udcb0 $0.23 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 31.1s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 82.4s / \ud83d\udcb0 $0.17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 107.2s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 77.7s 85_hpa_not_scaling \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 22.9s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 43.4s / \ud83d\udcb0 $0.16 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 23.2s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 75.4s / \ud83d\udcb0 $0.17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 80.1s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 28.2s 86_configmap_like_but_secret \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 29.9s / \ud83d\udcb0 $0.20 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 42.6s / \ud83d\udcb0 $0.21 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 27.8s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 140.3s / \ud83d\udcb0 $0.28 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 85.7s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 46.6s 89_runbook_missing_cloudwatch \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 21.6s / \ud83d\udcb0 $0.09 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 31.3s / \ud83d\udcb0 $0.10 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 18.7s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 47.1s / \ud83d\udcb0 $0.04 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 56.7s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 101.1s 90_runbook_basic_selection \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 33.2s / \ud83d\udcb0 $0.20 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 118.3s / \ud83d\udcb0 $1.01 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 174.1s / \ud83d\udcb0 $0.66 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 247.8s / \ud83d\udcb0 $0.39 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 133.5s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 130.8s 91f_datadog_logs_historical_pod \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 14.9s / \ud83d\udcb0 $0.04 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 85.8s / \ud83d\udcb0 $0.30 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 31.8s / \ud83d\udcb0 $0.14 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 138.3s / \ud83d\udcb0 $0.21 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 74.6s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 150.4s 93_calling_datadog[0] \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 16.2s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 10.3s / \ud83d\udcb0 $0.27 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 7.1s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 29.1s / \ud83d\udcb0 $0.17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 30.9s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 17.9s 93_calling_datadog[1] \ud83d\udd17 \u26aa\ufe0f - \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 9.8s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 6.7s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 21.6s / \ud83d\udcb0 $0.12 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 21.1s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 12.1s 93_calling_datadog[2] \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 14.8s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 10.1s / \ud83d\udcb0 $0.15 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 5.5s / \ud83d\udcb0 $0.07 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 25.8s / \ud83d\udcb0 $0.19 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 22.2s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 12.0s 93_events_since_specific_date \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 10.4s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 17.0s / \ud83d\udcb0 $0.17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 8.9s / \ud83d\udcb0 $0.06 \u26aa\ufe0f - \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 23.9s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 12.6s 94_runbook_transparency \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 28.8s / \ud83d\udcb0 $0.19 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 61.2s / \ud83d\udcb0 $0.29 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 30.6s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 810.0s / \ud83d\udcb0 $0.55 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 112.1s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 85.4s 96_no_matching_runbook \ud83d\udd17 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 27.5s / \ud83d\udcb0 $0.19 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 72.9s / \ud83d\udcb0 $0.69 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 32.4s / \ud83d\udcb0 $0.13 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 126.5s / \ud83d\udcb0 $0.20 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 84.9s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 15.1s 97_logs_clarification_needed \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 8.0s / \ud83d\udcb0 $0.03 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 35.1s / \ud83d\udcb0 $0.14 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 15.3s / \ud83d\udcb0 $0.05 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 17.4s / \ud83d\udcb0 $0.02 \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 142.2s \ud83d\udd34 0% (0/1) / \u23f1\ufe0f 81.3s 98_logs_transparency_default_time \ud83d\udd17 \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - \u26aa\ufe0f - 99_logs_transparency_custom_time \ud83d\udd17 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 22.5s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 33.8s / \ud83d\udcb0 $0.11 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 21.5s / \ud83d\udcb0 $0.06 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 37.0s / \ud83d\udcb0 $0.08 \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 59.6s \ud83d\udfe2 100% (1/1) / \u23f1\ufe0f 34.2s <p>Results are automatically generated and updated weekly. View full traces and detailed analysis in Braintrust experiment: local-benchmark-20251012-151418.</p>"},{"location":"installation/cli-installation/","title":"Install CLI","text":"<p>Run HolmesGPT from your terminal as a standalone CLI tool.</p>"},{"location":"installation/cli-installation/#installation-options","title":"Installation Options","text":"Homebrew (Mac/Linux)PipxFrom Source (Poetry)Docker Container <ol> <li> <p>Add our tap:    <pre><code>brew tap robusta-dev/homebrew-holmesgpt\n</code></pre></p> </li> <li> <p>Install HolmesGPT:    <pre><code>brew install holmesgpt\n</code></pre></p> </li> <li> <p>To upgrade to the latest version:    <pre><code>brew upgrade holmesgpt\n</code></pre></p> </li> <li> <p>Verify installation:    <pre><code>holmes ask --help\n</code></pre></p> </li> </ol> <ol> <li> <p>Install pipx</p> </li> <li> <p>Install HolmesGPT:    <pre><code>pipx install holmesgpt\n</code></pre></p> </li> <li> <p>Verify installation:    <pre><code>holmes ask --help\n</code></pre></p> </li> </ol> <p>For development or custom builds:</p> <ol> <li> <p>Install Poetry</p> </li> <li> <p>Install HolmesGPT:    <pre><code>git clone https://github.com/robusta-dev/holmesgpt.git\ncd holmesgpt\npoetry install --no-root\n</code></pre></p> </li> <li> <p>Verify installation:    <pre><code>poetry run holmes ask --help\n</code></pre></p> </li> </ol> <p>Run HolmesGPT using the prebuilt Docker container:</p> <pre><code>docker run -it --net=host \\\n  -e OPENAI_API_KEY=\"your-api-key\" \\\n  -v ~/.holmes:/root/.holmes \\\n  -v ~/.aws:/root/.aws \\\n  -v ~/.config/gcloud:/root/.config/gcloud \\\n  -v $HOME/.kube/config:/root/.kube/config \\\n  us-central1-docker.pkg.dev/genuine-flight-317411/devel/holmes ask \"what pods are unhealthy and why?\"\n</code></pre> <p>Note: Use <code>-e</code> flags to pass API keys for your provider (e.g., <code>-e ANTHROPIC_API_KEY</code>, <code>-e GEMINI_API_KEY</code>). See Environment Variables Reference for the complete list.</p>"},{"location":"installation/cli-installation/#quick-start","title":"Quick Start","text":"<p>Choose your AI provider (see all providers for more options).</p> <p>Which Model to Use</p> <p>We highly recommend using Sonnet 4.0 or Sonnet 4.5 as it gives the best results by far. These models are available from Anthropic, AWS Bedrock, and Google Vertex. View Benchmarks.</p> Anthropic ClaudeOpenAIAzure OpenAIAWS BedrockGoogle GeminiGoogle Vertex AIOllama <ol> <li> <p>Set up API key:     <pre><code>export ANTHROPIC_API_KEY=\"your-api-key\"\n</code></pre></p> </li> <li> <p>Create a test pod to investigate:     <pre><code>kubectl apply -f https://raw.githubusercontent.com/robusta-dev/kubernetes-demos/main/pending_pods/pending_pod_node_selector.yaml\n</code></pre></p> </li> <li> <p>Ask your first question:     <pre><code>holmes ask \"what is wrong with the user-profile-import pod?\" --model=\"anthropic/claude-sonnet-4-5-20250929\"\n</code></pre></p> </li> </ol> <p>Note: You can use any Anthropic model by changing the model name. See Claude Models Overview for available model names.</p> <p>See Anthropic Configuration for more details.</p> <ol> <li> <p>Set up API key:     <pre><code>export OPENAI_API_KEY=\"your-api-key\"\n</code></pre></p> </li> <li> <p>Create a test pod to investigate:     <pre><code>kubectl apply -f https://raw.githubusercontent.com/robusta-dev/kubernetes-demos/main/pending_pods/pending_pod_node_selector.yaml\n</code></pre></p> </li> <li> <p>Ask your first question:     <pre><code># Uses gpt-4.1 by default (fairly fast, decent results)\nholmes ask \"what is wrong with the user-profile-import pod?\"\n\n# Or specify a different model\nholmes ask \"what is wrong with the user-profile-import pod?\" --model=\"gpt-5\"\n</code></pre></p> </li> </ol> <p>See OpenAI Configuration for more details.</p> <ol> <li> <p>Set up API key:     <pre><code>export AZURE_API_VERSION=\"2024-02-15-preview\"\nexport AZURE_API_BASE=\"https://your-resource.openai.azure.com\"\nexport AZURE_API_KEY=\"your-azure-api-key\"\n</code></pre></p> </li> <li> <p>Create a test pod to investigate:     <pre><code>kubectl apply -f https://raw.githubusercontent.com/robusta-dev/kubernetes-demos/main/pending_pods/pending_pod_node_selector.yaml\n</code></pre></p> </li> <li> <p>Ask your first question:     <pre><code>holmes ask \"what is wrong with the user-profile-import pod?\" --model=\"azure/&lt;your-model-name&gt;\"\n</code></pre></p> </li> </ol> <p>See Azure OpenAI Configuration for more details.</p> <ol> <li> <p>Set up API key:     <pre><code>export AWS_ACCESS_KEY_ID=\"your-access-key\"\nexport AWS_SECRET_ACCESS_KEY=\"your-secret-key\"\nexport AWS_DEFAULT_REGION=\"your-region\"\n</code></pre></p> </li> <li> <p>Install boto3:     <pre><code>pip install \"boto3&gt;=1.28.57\"\n</code></pre></p> </li> <li> <p>Create a test pod to investigate:     <pre><code>kubectl apply -f https://raw.githubusercontent.com/robusta-dev/kubernetes-demos/main/pending_pods/pending_pod_node_selector.yaml\n</code></pre></p> </li> <li> <p>Ask your first question:     <pre><code># Recommended: Use Sonnet 4.0 or Sonnet 4.5 for best results\nholmes ask \"what is wrong with the user-profile-import pod?\" --model=\"bedrock/anthropic.claude-sonnet-4-20250514-v1:0\"\n\n# Or use another model\nholmes ask \"what is wrong with the user-profile-import pod?\" --model=\"bedrock/&lt;your-model-name&gt;\"\n</code></pre></p> </li> </ol> <p>See AWS Bedrock Configuration for more details.</p> <ol> <li> <p>Set up API key:     <pre><code>export GEMINI_API_KEY=\"your-gemini-api-key\"\n</code></pre></p> </li> <li> <p>Create a test pod to investigate:     <pre><code>kubectl apply -f https://raw.githubusercontent.com/robusta-dev/kubernetes-demos/main/pending_pods/pending_pod_node_selector.yaml\n</code></pre></p> </li> <li> <p>Ask your first question:     <pre><code>holmes ask \"what is wrong with the user-profile-import pod?\" --model=\"gemini/&lt;your-gemini-model&gt;\"\n</code></pre></p> </li> </ol> <p>See Google Gemini Configuration for more details.</p> <ol> <li> <p>Set up credentials:     <pre><code>export VERTEXAI_PROJECT=\"your-project-id\"\nexport VERTEXAI_LOCATION=\"us-central1\"\nexport GOOGLE_APPLICATION_CREDENTIALS=\"path/to/service-account-key.json\"\n</code></pre></p> </li> <li> <p>Create a test pod to investigate:     <pre><code>kubectl apply -f https://raw.githubusercontent.com/robusta-dev/kubernetes-demos/main/pending_pods/pending_pod_node_selector.yaml\n</code></pre></p> </li> <li> <p>Ask your first question:     <pre><code>holmes ask \"what is wrong with the user-profile-import pod?\" --model=\"vertex_ai/&lt;your-vertex-model&gt;\"\n</code></pre></p> </li> </ol> <p>See Google Vertex AI Configuration for more details.</p> <ol> <li> <p>Set up API key:     No API key required for local Ollama installation.</p> </li> <li> <p>Create a test pod to investigate:     <pre><code>kubectl apply -f https://raw.githubusercontent.com/robusta-dev/kubernetes-demos/main/pending_pods/pending_pod_node_selector.yaml\n</code></pre></p> </li> <li> <p>Ask your first question:     <pre><code>holmes ask \"what is wrong with the user-profile-import pod?\" --model=\"ollama/&lt;your-model-name&gt;\"\n</code></pre></p> <p>For troubleshooting and advanced options, see Ollama Configuration.</p> </li> </ol> <p>Warning: Ollama can be tricky to configure correctly. We recommend trying HolmesGPT with a hosted model first (like Claude or OpenAI) to ensure everything works before switching to Ollama.</p>"},{"location":"installation/cli-installation/#next-steps","title":"Next Steps","text":"<ul> <li>Add Data Sources - Use built-in toolsets to connect with ArgoCD, Confluence, and monitoring tools</li> <li>Connect Remote MCP Servers - Extend capabilities with external MCP servers</li> </ul>"},{"location":"installation/cli-installation/#need-help","title":"Need Help?","text":"<ul> <li>Join our Slack - Get help from the community</li> <li>Request features on GitHub - Suggest improvements or report bugs</li> <li>Troubleshooting guide - Common issues and solutions</li> </ul>"},{"location":"installation/kubernetes-installation/","title":"Install Helm Chart","text":"<p>Deploy HolmesGPT as a service in your Kubernetes cluster with an HTTP API.</p> <p>When to use the Helm chart?</p> <p>Most users should use the CLI or UI/TUI instead. Using the Helm chart is only recommended if you're building a custom integration over an HTTP API.</p>"},{"location":"installation/kubernetes-installation/#prerequisites","title":"Prerequisites","text":"<ul> <li>Kubernetes cluster</li> <li>Helm</li> <li>kubectl configured to access your cluster</li> <li>Supported AI Provider API key.</li> </ul>"},{"location":"installation/kubernetes-installation/#installation","title":"Installation","text":"<ol> <li> <p>Add the Helm repository: <pre><code>helm repo add robusta https://robusta-charts.storage.googleapis.com\nhelm repo update\n</code></pre></p> </li> <li> <p>Create <code>values.yaml</code> file:</p> <p>Create a <code>values.yaml</code> file to configure HolmesGPT with your models using the <code>modelList</code> approach:</p> OpenAIAnthropicAzure OpenAIMultiple Providers <pre><code># values.yaml\nadditionalEnvVars:\n- name: OPENAI_API_KEY\n  value: \"your-openai-api-key\"\n# Or load from secret:\n# - name: OPENAI_API_KEY\n#   valueFrom:\n#     secretKeyRef:\n#       name: holmes-secrets\n#       key: openai-api-key\n\nmodelList:\n  gpt-4.1:\n    api_key: \"{{ env.OPENAI_API_KEY }}\"\n    model: openai/gpt-4.1\n    temperature: 0\n  gpt-5:\n    api_key: \"{{ env.OPENAI_API_KEY }}\"\n    model: openai/gpt-5\n</code></pre> <pre><code># values.yaml\nadditionalEnvVars:\n- name: ANTHROPIC_API_KEY\n  value: \"your-anthropic-api-key\"\n# Or load from secret:\n# - name: ANTHROPIC_API_KEY\n#   valueFrom:\n#     secretKeyRef:\n#       name: holmes-secrets\n#       key: anthropic-api-key\n\nmodelList:\n  claude-sonnet:\n    api_key: \"{{ env.ANTHROPIC_API_KEY }}\"\n    model: anthropic/claude-3-5-sonnet-20241022\n    temperature: 0\n</code></pre> <pre><code># values.yaml\nadditionalEnvVars:\n- name: AZURE_API_KEY\n  value: \"your-azure-api-key\"\n- name: AZURE_API_BASE\n  value: \"https://your-resource.openai.azure.com/\"\n- name: AZURE_API_VERSION\n  value: \"2024-02-15-preview\"\n# Or load from secret:\n# - name: AZURE_API_KEY\n#   valueFrom:\n#     secretKeyRef:\n#       name: holmes-secrets\n#       key: azure-api-key\n# - name: AZURE_API_BASE\n#   valueFrom:\n#     secretKeyRef:\n#       name: holmes-secrets\n#       key: azure-api-base\n\nmodelList:\n  azure-gpt4:\n    api_key: \"{{ env.AZURE_API_KEY }}\"\n    model: azure/your-deployment-name\n    api_base: \"{{ env.AZURE_API_BASE }}\"\n    api_version: \"{{ env.AZURE_API_VERSION }}\"\n    temperature: 0\n</code></pre> <pre><code># values.yaml\nadditionalEnvVars:\n- name: OPENAI_API_KEY\n  value: \"your-openai-api-key\"\n- name: ANTHROPIC_API_KEY\n  value: \"your-anthropic-api-key\"\n# Or load from secrets (recommended)\n\nmodelList:\n  gpt-4.1:\n    api_key: \"{{ env.OPENAI_API_KEY }}\"\n    model: openai/gpt-4.1\n    temperature: 0\n  claude-sonnet:\n    api_key: \"{{ env.ANTHROPIC_API_KEY }}\"\n    model: anthropic/claude-3-5-sonnet-20241022\n    temperature: 0\n  gpt-5:\n    api_key: \"{{ env.OPENAI_API_KEY }}\"\n    model: openai/gpt-5\n</code></pre> <p>Configuration Guide: Each AI provider requires different environment variables. See the AI Providers documentation for the specific environment variables needed for your chosen provider, then add them to the <code>additionalEnvVars</code> section as shown above. For a complete list of all environment variables, see the Environment Variables Reference. For advanced multiple provider setup, see Using Multiple Providers.</p> </li> <li> <p>Install HolmesGPT: <pre><code>helm install holmesgpt robusta/holmes -f values.yaml\n</code></pre></p> </li> </ol>"},{"location":"installation/kubernetes-installation/#usage","title":"Usage","text":"<p>After installation, test the service with a simple API call:</p> <pre><code># Port forward to access the service locally\n# Note: Service name is {release-name}-holmes\nkubectl port-forward svc/holmesgpt-holmes 8080:80\n\n# If you used a different release name or namespace:\n# kubectl port-forward svc/{your-release-name}-holmes 8080:80 -n {your-namespace}\n\n# Test with a basic question using modelList model name\ncurl -X POST http://localhost:8080/api/chat \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"ask\": \"list pods in namespace default?\", \"model\": \"gpt-4o-mini\"}'\n\n# Using a different model from your modelList\ncurl -X POST http://localhost:8080/api/chat \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"ask\": \"list pods in namespace default?\", \"model\": \"claude-sonnet\"}'\n</code></pre> <p>Note: Responses may take some time when HolmesGPT needs to gather large amounts of data to answer your question. Streaming APIs are coming soon to stream results.</p> <p>For complete API documentation, see the HTTP API Reference.</p>"},{"location":"installation/kubernetes-installation/#upgrading","title":"Upgrading","text":"<pre><code>helm repo update\nhelm upgrade holmesgpt robusta/holmes -f values.yaml\n</code></pre>"},{"location":"installation/kubernetes-installation/#uninstalling","title":"Uninstalling","text":"<pre><code>helm uninstall holmesgpt\n</code></pre>"},{"location":"installation/kubernetes-installation/#need-help","title":"Need Help?","text":"<ul> <li>Join our Slack - Get help from the community</li> <li>Request features on GitHub - Suggest improvements or report bugs</li> <li>Troubleshooting guide - Common issues and solutions</li> </ul>"},{"location":"installation/python-installation/","title":"Install Python SDK","text":"<p>Embed HolmesGPT in your own applications for programmatic root cause analysis, based on observability data.</p>"},{"location":"installation/python-installation/#install-holmesgpt-python-package","title":"Install HolmesGPT Python Package","text":"<pre><code>pip install holmesgpt # Installs latest stable version\n</code></pre> <p>Install unreleased version from GitHub: <pre><code>pip install \"https://github.com/robusta-dev/holmesgpt/archive/refs/heads/master.zip\"\n</code></pre></p>"},{"location":"installation/python-installation/#quick-start","title":"Quick Start","text":"<pre><code>import os\nfrom holmes.config import Config\nfrom holmes.core.prompt import build_initial_ask_messages\nfrom rich.console import Console\n\nprint(\"\ud83d\ude80 Initializing HolmesGPT...\")\n\n# Create configuration\nprint(\"Creating configuration...\")\nconfig = Config(\n    api_key=os.getenv(\"OPENAI_API_KEY\"),\n    model=\"gpt-4.1\",\n    max_steps=10\n)\nprint(f\"\u2705 Configuration created with model: {config.model}\")\n\n# Create AI instance and console\nprint(\"Creating AI instance...\")\nai = config.create_console_toolcalling_llm()\nconsole = Console()\nprint(\"\u2705 AI instance ready\")\n\n# Ask a question\nquestion = \"what pods are failing in production?\"\nprint(f\"\\n\ud83d\udd0d Asking: '{question}'\")\n\n# Build initial messages with system prompt\nmessages = build_initial_ask_messages(\n    console=console,\n    initial_user_prompt=question,\n    file_paths=None,\n    tool_executor=ai.tool_executor,\n    runbooks=config.get_runbook_catalog(),\n    system_prompt_additions=None\n)\n\nprint(\"Holmes is thinking...\")\nresponse = ai.call(messages)\nprint(f\"Holmes: {response.result}\")\n</code></pre>"},{"location":"installation/python-installation/#tool-details-example","title":"Tool Details Example","text":"<p>Here's a complete working example that shows detailed progress, available tools, toolsets, and which tools Holmes uses:</p> <pre><code>#!/usr/bin/env python3\n\"\"\"\nComplete example of using HolmesGPT Python SDK with progress tracking\n\"\"\"\n\nimport os\nfrom holmes.config import Config\nfrom holmes.core.prompt import build_initial_ask_messages\nfrom rich.console import Console\n\ndef main():\n    print(\"\ud83d\ude80 Starting HolmesGPT Python SDK Example\")\n    print(\"=\" * 60)\n\n    # Set API key (you can also set OPENAI_API_KEY environment variable)\n    api_key = os.getenv(\"OPENAI_API_KEY\", \"your-api-key-here\")\n\n    print(\"Step 1: Creating configuration...\")\n    # Create configuration\n    config = Config(\n        api_key=api_key,\n        model=\"gpt-4.1\",\n        max_steps=10\n    )\n    print(f\"\u2705 Configuration created with model: {config.model}\")\n\n    print(\"\\nStep 2: Creating AI instance...\")\n    # Create AI instance and console\n    ai = config.create_console_toolcalling_llm()\n    console = Console()\n    print(\"\u2705 AI instance created successfully\")\n\n    print(\"\\nStep 3: Listing available toolsets...\")\n    # Show available toolsets\n    toolsets = ai.tool_executor.toolsets\n    print(f\"Loaded {len(toolsets)} toolsets:\")\n    for toolset in toolsets:\n        print(f\"   \u2022 {toolset.name} ({'enabled' if toolset.enabled else 'disabled'})\")\n\n    print(\"\\nStep 4: Listing available tools from loaded toolsets...\")\n    # Show available tools\n    available_tools = list(ai.tool_executor.tools_by_name.keys())\n    print(f\"Listed {len(available_tools)} tools:\")\n    for tool in sorted(available_tools):\n        print(f\"   \u2022 {tool}\")\n\n    print(\"\\nStep 5: Asking questions...\")\n    # Ask questions\n    questions = [\n        \"what pods are failing in production?\",\n        \"show me recent kubernetes events\",\n        \"what are the resource usage patterns in my cluster?\"\n    ]\n\n    for i, question in enumerate(questions, 1):\n        print(f\"\\n\ud83d\udd0d Question {i}/{len(questions)}: {question}\")\n        print(\"=\" * 60)\n\n        try:\n            print(\"Holmes is thinking...\")\n\n            # Build initial messages\n            messages = build_initial_ask_messages(\n                console=console,\n                initial_user_prompt=question,\n                file_paths=None,\n                tool_executor=ai.tool_executor,\n                runbooks=config.get_runbook_catalog(),\n                system_prompt_additions=None\n            )\n\n            response = ai.call(messages)\n            print(f\"Holmes: {response.result}\")\n\n            # Show tools that were used\n            if response and response.tool_calls:\n                tool_names = [tool.tool_name for tool in response.tool_calls]\n                if tool_names:\n                    print(f\"\\nTools used: {tool_names}\")\n\n                    # Print contents of each tool response\n                    print(\"\\nTool responses:\")\n                    for j, tool in enumerate(response.tool_calls, 1):\n                        print(f\"\\n   {j}. {tool.tool_name}:\")\n                        print(f\"      Result: {tool.result}\")\n                        if hasattr(tool, 'error') and tool.error:\n                            print(f\"      Error: {tool.error}\")\n\n        except Exception as e:\n            print(f\"\u274c Error: {e}\")\n\n        print(\"-\" * 60)\n\n    print(\"\\n\u2705 Example completed!\")\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>Save this as <code>holmesgpt_tool_details_example.py</code> and run:</p> <pre><code># Make sure your API key is set\nexport OPENAI_API_KEY=\"your-actual-api-key\"\n\n# Run the example\npython holmesgpt_tool_details_example.py\n</code></pre> <p>This will show you:</p> <ul> <li>Configuration creation progress</li> <li>List of available tools (kubectl, prometheus, etc.)</li> <li>List of available toolsets and their status</li> <li>System prompt loading progress</li> <li>Progress for each question being asked</li> <li>Which tools Holmes used for each question</li> </ul>"},{"location":"installation/python-installation/#follow-up-questions-example","title":"Follow-up Questions Example","text":"<p>Here's how to ask follow-up questions that maintain conversation context:</p> <pre><code>#!/usr/bin/env python3\n\"\"\"\nExample showing how to ask follow-up questions with conversation context\n\"\"\"\n\nimport os\nfrom holmes.config import Config\nfrom holmes.plugins.prompts import load_and_render_prompt\nfrom holmes.core.prompt import build_initial_ask_messages\nfrom rich.console import Console\n\ndef main():\n    print(\"\ud83d\ude80 Starting HolmesGPT Follow-up Questions Example\")\n    print(\"=\" * 60)\n\n    # Create configuration\n    config = Config(\n        api_key=os.getenv(\"OPENAI_API_KEY\"),\n        model=\"gpt-4.1\",\n        max_steps=10\n    )\n\n    # Create AI instance and console\n    ai = config.create_console_toolcalling_llm()\n    console = Console()\n\n    # First question\n    print(\"\\n\ud83d\udd0d First Question:\")\n    first_question = \"what pods are failing in my cluster?\"\n    print(f\"User: {first_question}\")\n\n    # Build initial messages (includes system prompt + first user message)\n    messages = build_initial_ask_messages(\n        console=console,\n        initial_user_prompt=first_question,\n        file_paths=None,\n        tool_executor=ai.tool_executor,\n        runbooks=config.get_runbook_catalog(),\n        system_prompt_additions=None\n    )\n\n    # Call AI with initial messages\n    print(\"Holmes is thinking...\")\n    response = ai.call(messages)\n    messages = response.messages  # Update messages with full conversation\n\n    print(f\"Holmes: {response.result}\")\n\n    # Follow-up question\n    followup_question = \"Can you show me the logs for those failing pods?\"\n\n    print(f\"\\n\ud83d\udd0d Follow-up Question:\")\n    print(f\"User: {followup_question}\")\n\n    # Add the follow-up question to the conversation\n    messages.append({\"role\": \"user\", \"content\": followup_question})\n\n    # Call AI with updated message history\n    print(\"Holmes is thinking...\")\n    response = ai.call(messages)\n    messages = response.messages  # Update messages with latest response\n\n    print(f\"Holmes: {response.result}\")\n\n    # Show tools used\n    if response.tool_calls:\n        tool_names = [tool.tool_name for tool in response.tool_calls]\n        print(f\"Tools used: {tool_names}\")\n\n    print(\"\\n\u2705 Conversation completed!\")\n    print(f\"Total messages in conversation: {len(messages)}\")\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>Key Points for Follow-up Questions:</p> <ol> <li>Use <code>build_initial_ask_messages()</code> for the first question</li> <li>Use <code>ai.call(messages)</code> instead of <code>ai.prompt_call()</code></li> <li>Update messages after each response: <code>messages = response.messages</code></li> <li>Append new questions: <code>messages.append({\"role\": \"user\", \"content\": question})</code></li> <li>Messages contain full conversation history for context</li> </ol>"},{"location":"installation/python-installation/#configuration-options","title":"Configuration Options","text":""},{"location":"installation/python-installation/#basic-configuration","title":"Basic Configuration","text":"<pre><code>from holmes.config import Config\n\n# Basic configuration example\nconfig = Config(\n    api_key=\"your-api-key\",\n    model=\"gpt-4.1\",  # or \"anthropic/claude-sonnet-4-20250514\", etc.\n    max_steps=10\n)\n\n# Minimal configuration (API key only)\nconfig = Config(api_key=\"your-api-key\")\n\n# Environment-based configuration\nconfig = Config()  # Will auto-detect API key from OPENAI_API_KEY\n</code></pre>"},{"location":"installation/python-installation/#advanced-configuration","title":"Advanced Configuration","text":"<pre><code>from holmes.config import Config\n\n# Complete configuration with custom toolsets and runbooks\nconfig = Config(\n    # LLM settings\n    api_key=\"your-api-key\",\n    model=\"gpt-4.1\",\n    max_steps=10,\n\n    # Custom toolsets and runbooks\n    custom_toolsets=[\"/path/to/custom/toolset.yaml\"],\n    custom_runbooks=[\"/path/to/custom/runbook.yaml\"],\n)\n</code></pre>"},{"location":"installation/python-installation/#api-reference","title":"API Reference","text":""},{"location":"installation/python-installation/#config","title":"Config","text":"<p>Main configuration class for HolmesGPT.</p> <p>Constructor Parameters:</p> <ul> <li><code>api_key</code> (str, optional) - LLM API key (can also use environment variables)</li> <li><code>model</code> (str, optional) - Model to use (default: \"gpt-4.1\")</li> <li><code>max_steps</code> (int, optional) - Maximum investigation steps (default: 10)</li> <li><code>custom_toolsets</code> (list, optional) - Custom toolset file paths</li> <li><code>custom_runbooks</code> (list, optional) - Custom runbook file paths</li> </ul> <p>Class Methods:</p> <ul> <li><code>Config.load_from_file(path)</code> - Load configuration from YAML file</li> <li><code>Config.load_from_env()</code> - Load configuration from environment variables</li> </ul> <p>Instance Methods:</p> <ul> <li><code>create_console_toolcalling_llm()</code> - Create AI instance for investigations</li> </ul>"},{"location":"installation/python-installation/#toolcallingllm","title":"ToolCallingLLM","text":"<p>Main AI instance for running investigations.</p> <p>Methods:</p> <ul> <li><code>prompt_call(system_prompt, user_prompt)</code> - Ask a question and get response</li> <li><code>call(messages)</code> - Call with full message history</li> </ul>"},{"location":"installation/python-installation/#environment-variables","title":"Environment Variables","text":"<p>Instead of passing <code>api_key</code> to the Config constructor, you can set these environment variables and use <code>Config()</code> without parameters:</p> <pre><code># AI Provider (choose one)\nexport OPENAI_API_KEY=\"your-openai-key\"\nexport ANTHROPIC_API_KEY=\"your-anthropic-key\"\nexport GOOGLE_API_KEY=\"your-google-key\"\n\n# Optional: Custom configuration\nexport HOLMES_CONFIG_PATH=\"/path/to/config.yaml\"\nexport HOLMES_LOG_LEVEL=\"INFO\"\n</code></pre> <p>\ud83d\udcda See Also: Check the Environment Variables Reference for complete documentation of all available environment variables.</p> <p>Usage with environment variables: <pre><code>import os\nos.environ[\"OPENAI_API_KEY\"] = \"your-api-key\"\n\nconfig = Config()  # Will auto-detect API key from environment\n</code></pre></p>"},{"location":"installation/python-installation/#need-help","title":"Need Help?","text":"<ul> <li>Join our Slack - Get help from the community</li> <li>Request features on GitHub - Suggest improvements or report bugs</li> <li>Troubleshooting guide - Common issues and solutions</li> </ul>"},{"location":"installation/ui-installation/","title":"Install UI/Slack/K9s","text":"<p>Use HolmesGPT through graphical and terminal interfaces via third-party integrations.</p>"},{"location":"installation/ui-installation/#k9s-plugin","title":"K9s Plugin","text":"<p>Integrate HolmesGPT into your K9s Kubernetes terminal for instant analysis.</p> <p></p>"},{"location":"installation/ui-installation/#prerequisites","title":"Prerequisites","text":"<ul> <li>K9s must be installed - See the K9s installation guide</li> <li>HolmesGPT CLI and API key - Follow the CLI Installation Guide to install Holmes and configure your AI provider</li> </ul>"},{"location":"installation/ui-installation/#plugin-options","title":"Plugin Options","text":"Basic Plugin (Shift + H) - Quick investigation with predefined question <p>Add to your K9s plugins configuration file:</p> <ul> <li>Linux: <code>~/.config/k9s/plugins.yaml</code> or <code>~/.k9s/plugins.yaml</code></li> <li>macOS: <code>~/Library/Application Support/k9s/plugins.yaml</code> or <code>~/.k9s/plugins.yaml</code></li> <li>Windows: <code>%APPDATA%/k9s/plugins.yaml</code></li> </ul> <p>Read more about K9s plugins here and check your plugin path here.</p> <pre><code>plugins:\n  holmesgpt:\n    shortCut: Shift-H\n    description: Ask HolmesGPT\n    scopes:\n      - all\n    command: bash\n    background: false\n    confirm: false\n    args:\n      - -c\n      - |\n        # Check if we're already using the correct context\n        CURRENT_CONTEXT=$(kubectl config current-context 2&gt;/dev/null || echo \"\")\n        if [ \"$CURRENT_CONTEXT\" = \"$CONTEXT\" ]; then\n          # Already using the correct context, run HolmesGPT directly\n          holmes ask \"why is $NAME of $RESOURCE_NAME in -n $NAMESPACE not working as expected\"\n        else\n          # Create temporary kubeconfig to avoid changing user's system context\n          # K9s passes $CONTEXT but we need to ensure HolmesGPT uses the same context\n          # without permanently switching the user's kubectl context\n          TEMP_KUBECONFIG=$(mktemp)\n          kubectl config view --raw &gt; $TEMP_KUBECONFIG\n          KUBECONFIG=$TEMP_KUBECONFIG kubectl config use-context $CONTEXT\n          # KUBECONFIG environment variable is passed to holmes and all its child processes\n          KUBECONFIG=$TEMP_KUBECONFIG holmes ask \"why is $NAME of $RESOURCE_NAME in -n $NAMESPACE not working as expected\"\n          rm -f $TEMP_KUBECONFIG\n        fi\n        echo \"Press 'q' to exit\"\n        while : ; do\n        read -n 1 k &lt;&amp;1\n        if [[ $k = q ]] ; then\n        break\n        fi\n        done\n</code></pre> Advanced Plugin (Shift + Q) - Interactive plugin with custom questions <p>Add to your K9s plugins configuration file:</p> <ul> <li>Linux: <code>~/.config/k9s/plugins.yaml</code> or <code>~/.k9s/plugins.yaml</code></li> <li>macOS: <code>~/Library/Application Support/k9s/plugins.yaml</code> or <code>~/.k9s/plugins.yaml</code></li> <li>Windows: <code>%APPDATA%/k9s/plugins.yaml</code></li> </ul> <p>Read more about K9s plugins here and check your plugin path here.</p> <pre><code>plugins:\n  custom-holmesgpt:\n    shortCut: Shift-Q\n    description: Custom HolmesGPT Ask\n    scopes:\n      - all\n    command: bash\n    background: false\n    confirm: false\n    args:\n      - -c\n      - |\n        INSTRUCTIONS=\"# Edit the line below. Lines starting with '#' will be ignored.\"\n        DEFAULT_ASK_COMMAND=\"why is $NAME of $RESOURCE_NAME in -n $NAMESPACE not working as expected\"\n        QUESTION_FILE=$(mktemp)\n\n        echo \"$INSTRUCTIONS\" &gt; \"$QUESTION_FILE\"\n        echo \"$DEFAULT_ASK_COMMAND\" &gt;&gt; \"$QUESTION_FILE\"\n\n        # Open the line in the default text editor\n        ${EDITOR:-nano} \"$QUESTION_FILE\"\n\n        # Read the modified line, ignoring lines starting with '#'\n        user_input=$(grep -v '^#' \"$QUESTION_FILE\")\n\n        echo \"Running: holmes ask '$user_input'\"\n        # Check if we're already using the correct context\n        CURRENT_CONTEXT=$(kubectl config current-context 2&gt;/dev/null || echo \"\")\n        if [ \"$CURRENT_CONTEXT\" = \"$CONTEXT\" ]; then\n          # Already using the correct context, run HolmesGPT directly\n          holmes ask \"$user_input\"\n        else\n          # Create temporary kubeconfig to avoid changing user's system context\n          # K9s passes $CONTEXT but we need to ensure HolmesGPT uses the same context\n          # without permanently switching the user's kubectl context\n          TEMP_KUBECONFIG=$(mktemp)\n          kubectl config view --raw &gt; $TEMP_KUBECONFIG\n          KUBECONFIG=$TEMP_KUBECONFIG kubectl config use-context $CONTEXT\n          # KUBECONFIG environment variable is passed to holmes and all its child processes\n          KUBECONFIG=$TEMP_KUBECONFIG holmes ask \"$user_input\"\n          rm -f $TEMP_KUBECONFIG\n        fi\n        echo \"Press 'q' to exit\"\n        while : ; do\n        read -n 1 k &lt;&amp;1\n        if [[ $k = q ]] ; then\n        break\n        fi\n        done\n</code></pre>"},{"location":"installation/ui-installation/#usage","title":"Usage","text":"<ol> <li>Run K9s and select any Kubernetes resource</li> <li>Press Shift + H for quick analysis or Shift + Q for custom questions</li> </ol>"},{"location":"installation/ui-installation/#web-ui-robusta","title":"Web UI (Robusta)","text":"<p>The fastest way to use HolmesGPT is via the managed Robusta SaaS platform.</p> AWS TroubleshootingCPU Spike InvestigationTempo Tracing Integration <p> </p> <p> </p> <p></p>"},{"location":"installation/ui-installation/#get-started","title":"Get Started","text":"<ol> <li>Sign up: platform.robusta.dev</li> <li>Connect your cluster: Follow the in-app wizard</li> <li>Ask Holmes: Analyze alerts or troubleshoot issues</li> </ol> <p>Multiple AI Providers</p> <p>You can configure multiple AI models for users to choose from in the UI. See Using Multiple Providers for configuration details.</p>"},{"location":"installation/ui-installation/#slack-bot-robusta","title":"Slack Bot (Robusta)","text":"<p>First install Robusta SaaS, then tag HolmesGPT in any Slack message for instant analysis.</p> <p></p>"},{"location":"installation/ui-installation/#setup-slack-bot","title":"Setup Slack Bot","text":""},{"location":"installation/ui-installation/#need-help","title":"Need Help?","text":"<ul> <li>Join our Slack - Get help from the community</li> <li>Request features on GitHub - Suggest improvements or report bugs</li> <li>Troubleshooting guide - Common issues and solutions</li> </ul>"},{"location":"reference/environment-variables/","title":"Environment Variables","text":"<p>This page documents all environment variables that can be used to configure HolmesGPT behavior.</p>"},{"location":"reference/environment-variables/#ai-provider-configuration","title":"AI Provider Configuration","text":""},{"location":"reference/environment-variables/#openai","title":"OpenAI","text":"<ul> <li><code>OPENAI_API_KEY</code> - API key for OpenAI models</li> </ul>"},{"location":"reference/environment-variables/#anthropic","title":"Anthropic","text":"<ul> <li><code>ANTHROPIC_API_KEY</code> - API key for Anthropic Claude models</li> </ul>"},{"location":"reference/environment-variables/#google","title":"Google","text":"<ul> <li><code>GEMINI_API_KEY</code> - API key for Google Gemini models</li> <li><code>GOOGLE_API_KEY</code> - Alternative API key for Google services</li> </ul>"},{"location":"reference/environment-variables/#azure-openai","title":"Azure OpenAI","text":"<ul> <li><code>AZURE_API_KEY</code> - API key for Azure OpenAI service</li> <li><code>AZURE_API_BASE</code> - Base URL for Azure OpenAI endpoint</li> <li><code>AZURE_API_VERSION</code> - API version to use (e.g., \"2024-02-15-preview\")</li> </ul>"},{"location":"reference/environment-variables/#aws-bedrock","title":"AWS Bedrock","text":"<ul> <li><code>AWS_ACCESS_KEY_ID</code> - AWS access key ID</li> <li><code>AWS_SECRET_ACCESS_KEY</code> - AWS secret access key</li> <li><code>AWS_DEFAULT_REGION</code> - AWS region for Bedrock</li> </ul>"},{"location":"reference/environment-variables/#google-vertex-ai","title":"Google Vertex AI","text":"<ul> <li><code>VERTEXAI_PROJECT</code> - Google Cloud project ID</li> <li><code>VERTEXAI_LOCATION</code> - Vertex AI location (e.g., \"us-central1\")</li> <li><code>GOOGLE_APPLICATION_CREDENTIALS</code> - Path to service account key JSON file</li> </ul>"},{"location":"reference/environment-variables/#llm-tool-calling-configuration","title":"LLM Tool Calling Configuration","text":""},{"location":"reference/environment-variables/#llms_with_strict_tool_calls","title":"LLMS_WITH_STRICT_TOOL_CALLS","text":"<p>Default: <code>\"azure/gpt-4.1, openai/*\"</code></p> <p>Comma-separated list of model patterns that support strict tool calling. When a model matches one of these patterns, HolmesGPT will: - Enable the <code>strict</code> flag for function definitions - Set <code>additionalProperties: false</code> in tool parameter schemas - Enforce stricter schema validation for tool calls</p> <p>This improves reliability of tool calling for supported models by ensuring the LLM adheres more strictly to the defined tool schemas.</p> <p>Example: <pre><code>export LLMS_WITH_STRICT_TOOL_CALLS=\"azure/gpt-4.1,openai/*,anthropic/claude-sonnet-4*\"\n</code></pre></p>"},{"location":"reference/environment-variables/#tool_schema_no_param_object_if_no_params","title":"TOOL_SCHEMA_NO_PARAM_OBJECT_IF_NO_PARAMS","text":"<p>Default: <code>false</code></p> <p>When set to <code>true</code>, removes the <code>parameters</code> object from tool schemas when a tool has no parameters. This is specifically required for Google Gemini models which don't expect a parameters object for parameterless functions.</p> <p>Example: <pre><code>export TOOL_SCHEMA_NO_PARAM_OBJECT_IF_NO_PARAMS=true\n</code></pre></p> <p>Note: This setting is typically only needed when using Gemini models. Other providers handle empty parameter objects correctly.</p>"},{"location":"reference/environment-variables/#holmesgpt-configuration","title":"HolmesGPT Configuration","text":""},{"location":"reference/environment-variables/#holmes_config_path","title":"HOLMES_CONFIG_PATH","text":"<p>Path to a custom HolmesGPT configuration file. If not set, defaults to <code>~/.holmes/config.yaml</code>.</p> <p>Example: <pre><code>export HOLMES_CONFIG_PATH=\"/path/to/custom/config.yaml\"\n</code></pre></p>"},{"location":"reference/environment-variables/#holmes_log_level","title":"HOLMES_LOG_LEVEL","text":"<p>Controls the logging verbosity of HolmesGPT.</p> <p>Values: <code>DEBUG</code>, <code>INFO</code>, <code>WARNING</code>, <code>ERROR</code>, <code>CRITICAL</code> Default: <code>INFO</code></p> <p>Example: <pre><code>export HOLMES_LOG_LEVEL=\"DEBUG\"\n</code></pre></p>"},{"location":"reference/environment-variables/#holmes_cache_dir","title":"HOLMES_CACHE_DIR","text":"<p>Directory for caching HolmesGPT data and temporary files.</p>"},{"location":"reference/environment-variables/#holmes_post_processing_prompt","title":"HOLMES_POST_PROCESSING_PROMPT","text":"<p>Custom prompt template for post-processing LLM responses.</p>"},{"location":"reference/environment-variables/#data-source-configuration","title":"Data Source Configuration","text":""},{"location":"reference/environment-variables/#prometheus","title":"Prometheus","text":"<ul> <li><code>PROMETHEUS_URL</code> - URL of the Prometheus server</li> </ul>"},{"location":"reference/environment-variables/#confluence","title":"Confluence","text":"<ul> <li><code>CONFLUENCE_BASE_URL</code> - Base URL of Confluence instance</li> <li><code>CONFLUENCE_EMAIL</code> - Email for Confluence authentication</li> <li><code>CONFLUENCE_API_KEY</code> - API key for Confluence</li> </ul>"},{"location":"reference/environment-variables/#github","title":"GitHub","text":"<ul> <li><code>GITHUB_TOKEN</code> - Personal access token for GitHub API</li> </ul>"},{"location":"reference/environment-variables/#datadog","title":"Datadog","text":"<ul> <li><code>DATADOG_APP_KEY</code> - Datadog application key</li> <li><code>DATADOG_API_KEY</code> - Datadog API key</li> </ul>"},{"location":"reference/environment-variables/#aws","title":"AWS","text":"<ul> <li><code>AWS_ACCESS_KEY_ID</code> - AWS access key (also used for AWS toolset)</li> <li><code>AWS_SECRET_ACCESS_KEY</code> - AWS secret key (also used for AWS toolset)</li> <li><code>AWS_DEFAULT_REGION</code> - Default AWS region</li> </ul>"},{"location":"reference/environment-variables/#mongodb-atlas","title":"MongoDB Atlas","text":"<ul> <li><code>MONGODB_ATLAS_PUBLIC_KEY</code> - Public key for MongoDB Atlas API</li> <li><code>MONGODB_ATLAS_PRIVATE_KEY</code> - Private key for MongoDB Atlas API</li> </ul>"},{"location":"reference/environment-variables/#slab","title":"Slab","text":"<ul> <li><code>SLAB_API_KEY</code> - API key for Slab integration</li> </ul>"},{"location":"reference/environment-variables/#testing-and-development","title":"Testing and Development","text":""},{"location":"reference/environment-variables/#run_live","title":"RUN_LIVE","text":"<p>When set to <code>true</code>, enables live execution of commands in tests instead of using mocked responses. Strongly recommended for accurate test results.</p> <p>Example: <pre><code>export RUN_LIVE=true\n</code></pre></p>"},{"location":"reference/environment-variables/#model","title":"MODEL","text":"<p>Override the default LLM model for testing.</p> <p>Example: <pre><code>export MODEL=\"anthropic/claude-sonnet-4-20250514\"\n</code></pre></p>"},{"location":"reference/environment-variables/#classifier_model","title":"CLASSIFIER_MODEL","text":"<p>Model to use for scoring test answers (defaults to MODEL if not set). Required when using Anthropic models as the primary model since Anthropic models cannot be used as classifiers.</p> <p>Example: <pre><code>export CLASSIFIER_MODEL=\"gpt-4.1\"\n</code></pre></p>"},{"location":"reference/environment-variables/#iterations","title":"ITERATIONS","text":"<p>Number of times to run each test for reliability testing.</p> <p>Example: <pre><code>export ITERATIONS=10\n</code></pre></p>"},{"location":"reference/environment-variables/#braintrust_api_key","title":"BRAINTRUST_API_KEY","text":"<p>API key for Braintrust integration to track test results.</p>"},{"location":"reference/environment-variables/#braintrust_org","title":"BRAINTRUST_ORG","text":"<p>Braintrust organization name (default: \"robustadev\").</p>"},{"location":"reference/environment-variables/#experiment_id","title":"EXPERIMENT_ID","text":"<p>Custom experiment name for tracking test runs in Braintrust.</p>"},{"location":"reference/environment-variables/#ask_holmes_test_type","title":"ASK_HOLMES_TEST_TYPE","text":"<p>Controls message building flow in ask_holmes tests: - <code>cli</code> (default) - Uses CLI-style message building - <code>server</code> - Uses server-style message building with ChatRequest</p>"},{"location":"reference/environment-variables/#usage-examples","title":"Usage Examples","text":""},{"location":"reference/environment-variables/#basic-setup","title":"Basic Setup","text":"<pre><code># Set up OpenAI\nexport OPENAI_API_KEY=\"sk-...\"\nexport HOLMES_LOG_LEVEL=\"INFO\"\n\n# Run HolmesGPT\nholmes ask \"what pods are failing?\"\n</code></pre>"},{"location":"reference/environment-variables/#gemini-configuration","title":"Gemini Configuration","text":"<pre><code># Configure for Gemini models\nexport GEMINI_API_KEY=\"your-key\"\nexport TOOL_SCHEMA_NO_PARAM_OBJECT_IF_NO_PARAMS=true\n\nholmes ask \"analyze cluster health\" --model=\"gemini/gemini-1.5-pro\"\n</code></pre>"},{"location":"reference/environment-variables/#testing-with-strict-tool-calling","title":"Testing with Strict Tool Calling","text":"<pre><code># Enable strict tool calling for additional models\nexport LLMS_WITH_STRICT_TOOL_CALLS=\"azure/gpt-4.1,openai/*,custom/model-*\"\nexport RUN_LIVE=true\nexport MODEL=\"custom/model-v2\"\n\npoetry run pytest tests/llm/ -n 6\n</code></pre>"},{"location":"reference/environment-variables/#see-also","title":"See Also","text":"<ul> <li>AI Providers - Detailed configuration for each AI provider</li> <li>CLI Installation - Setting up the CLI with environment variables</li> <li>Helm Configuration - Kubernetes deployment configuration</li> </ul>"},{"location":"reference/helm-configuration/","title":"Helm Configuration","text":"<p>Configuration reference for HolmesGPT Helm chart.</p> <p>Quick Links:</p> <ul> <li>Installation Tutorial - Step-by-step setup guide</li> <li>values.yaml - Complete configuration reference</li> <li>HTTP API Reference - Test your deployment</li> </ul>"},{"location":"reference/helm-configuration/#basic-configuration","title":"Basic Configuration","text":"<pre><code># values.yaml\n# Image settings\nimage: holmes:0.0.0\nregistry: robustadev\n\n# Logging level\nlogLevel: INFO\n\n# send exceptions to sentry\nenableTelemetry: true\n\n# Resource limits\nresources:\n  requests:\n    cpu: 100m\n    memory: 1024Mi\n  limits:\n    memory: 1024Mi\n\n# Enabled/disable/customize specific toolsets\ntoolsets:\n  kubernetes/core:\n    enabled: true\n  kubernetes/logs:\n    enabled: true\n  robusta:\n    enabled: true\n  internet:\n    enabled: true\n  prometheus/metrics:\n    enabled: true\n  ...\n</code></pre>"},{"location":"reference/helm-configuration/#configuration-options","title":"Configuration Options","text":""},{"location":"reference/helm-configuration/#essential-settings","title":"Essential Settings","text":"Parameter Description Default <code>additionalEnvVars</code> Environment variables (API keys, etc.) <code>[]</code> <code>toolsets</code> Enable/disable specific toolsets (see values.yaml) <code>modelList</code> Configure multiple AI models for UI selection. See Using Multiple Providers <code>{}</code> <code>openshift</code> Enable OpenShift compatibility mode <code>false</code> <code>image</code> HolmesGPT image name <code>holmes:0.0.0</code> <code>registry</code> Container registry <code>robustadev</code> <code>logLevel</code> Log level (DEBUG, INFO, WARN, ERROR) <code>INFO</code> <code>enableTelemetry</code> Send exception reports to sentry <code>true</code> <code>certificate</code> Base64 encoded custom CA certificate for outbound HTTPS requests (e.g., LLM API via proxy) <code>\"\"</code> <code>sentryDSN</code> Sentry DSN for telemetry (see values.yaml)"},{"location":"reference/helm-configuration/#api-key-configuration","title":"API Key Configuration","text":"<p>The most important configuration is setting up API keys for your chosen AI provider:</p> <pre><code>additionalEnvVars:\n- name: OPENAI_API_KEY\n  value: \"your-api-key\"\n# Or load from secret:\n# - name: OPENAI_API_KEY\n#   valueFrom:\n#     secretKeyRef:\n#       name: holmes-secrets\n#       key: openai-api-key\n</code></pre>"},{"location":"reference/helm-configuration/#toolset-configuration","title":"Toolset Configuration","text":"<p>Control which capabilities HolmesGPT has access to:</p> <pre><code>toolsets:\n  kubernetes/core:\n    enabled: true      # Core Kubernetes functionality\n  kubernetes/logs:\n    enabled: true      # Kubernetes logs access\n  robusta:\n    enabled: true      # Robusta platform integration\n  internet:\n    enabled: true      # Internet access for documentation\n  prometheus/metrics:\n    enabled: true      # Prometheus metrics access\n</code></pre>"},{"location":"reference/helm-configuration/#service-account-configuration","title":"Service Account Configuration","text":"<pre><code># Create service account (default: true)\ncreateServiceAccount: true\n\n# Use custom service account name\ncustomServiceAccountName: \"\"\n\n# Service account settings\nserviceAccount:\n  imagePullSecrets: []\n  annotations: {}\n\n# Custom RBAC rules\ncustomClusterRoleRules: []\n</code></pre>"},{"location":"reference/helm-configuration/#resource-configuration","title":"Resource Configuration","text":"<pre><code>resources:\n  requests:\n    cpu: 100m\n    memory: 1024Mi\n  limits:\n    cpu: 100m        # Optional CPU limit\n    memory: 1024Mi\n</code></pre>"},{"location":"reference/helm-configuration/#toolset-configuration_1","title":"Toolset Configuration","text":"<p>Enable or disable specific toolsets:</p> <pre><code>toolsets:\n  kubernetes/core:\n    enabled: true      # Core Kubernetes functionality\n  kubernetes/logs:\n    enabled: true      # Kubernetes logs access\n  robusta:\n    enabled: true      # Robusta platform integration\n  internet:\n    enabled: true      # Internet access for documentation\n  prometheus/metrics:\n    enabled: true      # Prometheus metrics access\n</code></pre>"},{"location":"reference/helm-configuration/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"reference/helm-configuration/#scheduling","title":"Scheduling","text":"<pre><code># Node selection\n# nodeSelector:\n#   kubernetes.io/os: linux\n\n# Pod affinity/anti-affinity\naffinity: {}\n\n# Tolerations\ntolerations: []\n\n# Priority class\npriorityClassName: \"\"\n</code></pre>"},{"location":"reference/helm-configuration/#additional-configuration","title":"Additional Configuration","text":"<pre><code># Additional environment variables\nadditionalEnvVars: []\nadditional_env_vars: []  # Legacy, use additionalEnvVars instead\n\n# Image pull secrets\nimagePullSecrets: []\n\n# Additional volumes\nadditionalVolumes: []\n\n# Additional volume mounts\nadditionalVolumeMounts: []\n\n# OpenShift compatibility mode\nopenshift: false\n\n# Post-processing configuration\nenablePostProcessing: false\npostProcessingPrompt: \"builtin://generic_post_processing.jinja2\"\n\n# Account creation\nenableAccountsCreate: true\n\n# MCP servers configuration\nmcp_servers: {}\n\n# Model list configuration for multiple AI providers (UI only)\n# See: https://holmesgpt.dev/ai-providers/using-multiple-providers/\nmodelList: {}\n</code></pre>"},{"location":"reference/helm-configuration/#example-configurations","title":"Example Configurations","text":""},{"location":"reference/helm-configuration/#minimal-setup","title":"Minimal Setup","text":"<pre><code># values.yaml\nimage: holmes:0.0.0\nregistry: robustadev\nlogLevel: INFO\nenableTelemetry: false\n\nresources:\n  requests:\n    cpu: 100m\n    memory: 512Mi\n  limits:\n    memory: 512Mi\n\ntoolsets:\n  kubernetes/core:\n    enabled: true\n  kubernetes/logs:\n    enabled: true\n  robusta:\n    enabled: false\n  internet:\n    enabled: false\n  prometheus/metrics:\n    enabled: false\n</code></pre>"},{"location":"reference/helm-configuration/#multiple-ai-providers-setup","title":"Multiple AI Providers Setup","text":"<pre><code># values.yaml\nadditionalEnvVars:\n  - name: OPENAI_API_KEY\n    valueFrom:\n      secretKeyRef:\n        name: holmes-secrets\n        key: openai-api-key\n  - name: ANTHROPIC_API_KEY\n    valueFrom:\n      secretKeyRef:\n        name: holmes-secrets\n        key: anthropic-api-key\n  - name: AWS_ACCESS_KEY_ID\n    valueFrom:\n      secretKeyRef:\n        name: holmes-secrets\n        key: aws-access-key-id\n  - name: AWS_SECRET_ACCESS_KEY\n    valueFrom:\n      secretKeyRef:\n        name: holmes-secrets\n        key: aws-secret-access-key\n\nmodelList:\n  gpt-4.1:\n    api_key: \"{{ env.OPENAI_API_KEY }}\"\n    model: openai/gpt-4.1\n    temperature: 0\n  claude-sonnet-4:\n    api_key: \"{{ env.ANTHROPIC_API_KEY }}\"\n    model: anthropic/claude-sonnet-4-20250514\n    temperature: 1\n    thinking:\n      budget_tokens: 10000\n      type: enabled\n  bedrock-sonnet-4:\n    aws_access_key_id: \"{{ env.AWS_ACCESS_KEY_ID }}\"\n    aws_region_name: us-east-1\n    aws_secret_access_key: \"{{ env.AWS_SECRET_ACCESS_KEY }}\"\n    model: bedrock/anthropic.claude-sonnet-4-20250514-v1:0\n    temperature: 1\n    thinking:\n      budget_tokens: 10000\n      type: enabled\n</code></pre>"},{"location":"reference/helm-configuration/#openshift-setup","title":"OpenShift Setup","text":"<pre><code># values.yaml\nopenshift: true\ncreateServiceAccount: true\n\nresources:\n  requests:\n    cpu: 100m\n    memory: 1024Mi\n  limits:\n    memory: 1024Mi\n\ntoolsets:\n  kubernetes/core:\n    enabled: true\n  kubernetes/logs:\n    enabled: true\n</code></pre>"},{"location":"reference/helm-configuration/#configuration-validation","title":"Configuration Validation","text":"<pre><code># Validate configuration\nhelm template holmesgpt robusta/holmes -f values.yaml\n\n# Dry run installation\nhelm install holmesgpt robusta/holmes -f values.yaml --dry-run\n\n# Check syntax\nyamllint values.yaml\n</code></pre>"},{"location":"reference/helm-configuration/#complete-reference","title":"Complete Reference","text":"<p>For the complete and up-to-date configuration reference, see the actual <code>values.yaml</code> file in the repository.</p>"},{"location":"reference/http-api/","title":"HolmesGPT API Reference","text":""},{"location":"reference/http-api/#overview","title":"Overview","text":"<p>The HolmesGPT API provides endpoints for automated investigations, workload health checks, and conversational troubleshooting. This document describes each endpoint, its purpose, request fields, and example usage.</p>"},{"location":"reference/http-api/#model-parameter-behavior","title":"Model Parameter Behavior","text":"<p>When using the API with a Helm deployment, the <code>model</code> parameter must reference a model name from your <code>modelList</code> configuration in your Helm values, not the direct model identifier.</p> <p>Example Configuration: <pre><code># In your values.yaml\nmodelList:\n  fast-model:\n    api_key: \"{{ env.OPENAI_API_KEY }}\"\n    model: openai/gpt-4.1\n    temperature: 0\n  accurate-model:\n    api_key: \"{{ env.ANTHROPIC_API_KEY }}\"\n    model: anthropic/claude-sonnet-4-20250514\n    temperature: 0\n</code></pre></p> <p>Correct API Usage: <pre><code># Use the modelList key name, not the actual model identifier\ncurl -X POST http://localhost:8080/api/chat \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"ask\": \"list pods\", \"model\": \"fast-model\"}'\n</code></pre></p> <p>Incorrect Usage: <pre><code># This will fail - don't use the direct model identifier\ncurl -X POST http://localhost:8080/api/chat \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"ask\": \"list pods\", \"model\": \"openai/gpt-4.1\"}'\n</code></pre></p> <p>For complete setup instructions with <code>modelList</code> configuration, see the Kubernetes Installation Guide.</p>"},{"location":"reference/http-api/#endpoints","title":"Endpoints","text":""},{"location":"reference/http-api/#apichat-post","title":"<code>/api/chat</code> (POST)","text":"<p>Description: General-purpose chat endpoint for interacting with the AI assistant. Supports open-ended questions and troubleshooting.</p>"},{"location":"reference/http-api/#request-fields","title":"Request Fields","text":"Field Required Default Type Description ask Yes string User's question conversation_history No list Conversation history (first message must be system) model No string Model name from your <code>modelList</code> configuration <p>Example <pre><code>curl -X POST http://&lt;HOLMES-URL&gt;/api/chat \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"ask\": \"What is the status of my cluster?\",\n    \"conversation_history\": [\n      {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}\n    ]\n  }'\n</code></pre></p> <p>Example Response <pre><code>{\n  \"analysis\": \"Your cluster is healthy. All nodes are ready and workloads are running as expected.\",\n  \"conversation_history\": [\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": \"What is the status of my cluster?\"},\n    {\"role\": \"assistant\", \"content\": \"Your cluster is healthy. All nodes are ready and workloads are running as expected.\"}\n  ],\n  \"tool_calls\": [...],\n  \"follow_up_actions\": [...]\n}\n</code></pre></p>"},{"location":"reference/http-api/#apiinvestigate-post","title":"<code>/api/investigate</code> (POST)","text":"<p>Description: Initiate an automated investigation of an issue or incident.</p>"},{"location":"reference/http-api/#request-fields_1","title":"Request Fields","text":"Field Required Default Type Description source Yes string Source of the issue (e.g., \"prometheus\") title Yes string Title of the investigation description Yes string Description of the issue subject Yes object Subject details (e.g., resource info) context Yes object Additional context source_instance_id No \"ApiRequest\" string Source instance identifier include_tool_calls No false boolean Include tool calls in response include_tool_call_results No false boolean Include tool call results in response prompt_template No \"builtin://generic_investigation.jinja2\" string Prompt template to use sections No object Structured output sections model No string Model name from your <code>modelList</code> configuration <p>Example <pre><code>curl -X POST http://&lt;HOLMES-URL&gt;/api/investigate \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"source\": \"prometheus\",\n    \"title\": \"Pod CrashLoopBackOff\",\n    \"description\": \"Pod is crashing repeatedly\",\n    \"subject\": {\"namespace\": \"default\", \"pod\": \"my-pod\"},\n    \"context\": {},\n    \"include_tool_calls\": true,\n    \"model\": \"gpt-4.1\"\n  }'\n</code></pre></p> <p>Example Response <pre><code>{\n  \"analysis\": \"The pod 'my-pod' in namespace 'default' is crashing due to an OOMKilled event. Consider increasing memory limits.\",\n  \"sections\": {\n    \"Alert Explanation\": \"...\",\n    \"Key Findings\": \"...\",\n    \"Conclusions and Possible Root Causes\": \"...\",\n    \"Next Steps\": \"...\",\n    \"App or Infra?\": \"...\",\n    \"External links\": \"...\"\n  },\n  \"tool_calls\": [\n    {\n      \"tool_call_id\": \"1\",\n      \"tool_name\": \"kubectl_logs\",\n      \"description\": \"Fetch pod logs\",\n      \"result\": {\"logs\": \"...\"}\n    }\n  ],\n  \"instructions\": [...]\n}\n</code></pre></p>"},{"location":"reference/http-api/#apistreaminvestigate-post","title":"<code>/api/stream/investigate</code> (POST)","text":"<p>Description: Same as <code>/api/investigate</code>, but returns results as a stream for real-time updates.</p>"},{"location":"reference/http-api/#request-fields_2","title":"Request Fields","text":"<p>Same as <code>/api/investigate</code>.</p> <p>Example <pre><code>curl -N -X POST http://&lt;HOLMES-URL&gt;/api/stream/investigate \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"source\": \"prometheus\",\n    \"title\": \"Pod CrashLoopBackOff\",\n    \"description\": \"Pod is crashing repeatedly\",\n    \"subject\": {\"namespace\": \"default\", \"pod\": \"my-pod\"},\n    \"context\": {},\n    \"include_tool_calls\": true,\n    \"model\": \"gpt-4.1\"\n  }'\n</code></pre></p> <p>Example Response (streamed) <pre><code>event: start_tool_calling\ndata: {\"tool_name\": \"kubectl_describe\", \"id\": \"call_0\"}\n\nevent: start_tool_calling\ndata: {\"tool_name\": \"kubectl_logs\", \"id\": \"call_1\"}\n\nevent: start_tool_calling\ndata: {\"tool_name\": \"kubectl_previous_logs\", \"id\": \"call_2\"}\n\nevent: start_tool_calling\ndata: {\"tool_name\": \"kubectl_memory_requests_namespace\", \"id\": \"call_3\"}\n\nevent: tool_calling_result\ndata: {\"tool_call_id\": \"call_3\", \"role\": \"tool\", \"description\": \"kubectl get pods -n default -o ...\", \"name\": \"kubectl_memory_requests_namespace\", \"result\": {...}}\n\nevent: tool_calling_result\ndata: {\"tool_call_id\": \"call_0\", \"role\": \"tool\", \"description\": \"kubectl describe pod my-pod -n default\", \"name\": \"kubectl_describe\", \"result\": {...}}\n\nevent: tool_calling_result\ndata: {\"tool_call_id\": \"call_2\", \"role\": \"tool\", \"description\": \"kubectl logs my-pod -n default --previous\", \"name\": \"kubectl_previous_logs\", \"result\": {...}}\n\nevent: tool_calling_result\ndata: {\"tool_call_id\": \"call_1\", \"role\": \"tool\", \"description\": \"kubectl logs my-pod -n default\", \"name\": \"kubectl_logs\", \"result\": {...}}\n\nevent: ai_answer_end\ndata: {\"sections\": {\"Alert Explanation\": ...}}\n</code></pre></p>"},{"location":"reference/http-api/#apiissue_chat-post","title":"<code>/api/issue_chat</code> (POST)","text":"<p>Description: Conversational interface for discussing a specific issue or incident, with context from a previous investigation.</p>"},{"location":"reference/http-api/#request-fields_3","title":"Request Fields","text":"Field Required Default Type Description ask Yes string User's question investigation_result Yes object Previous investigation result (see below) issue_type Yes string Type of issue conversation_history No list Conversation history (first message must be system) model No string Model name from your <code>modelList</code> configuration <p>investigation_result object: - <code>result</code> (string, optional): Previous analysis - <code>tools</code> (list, optional): Tools used/results</p> <p>Example <pre><code>curl -X POST http://&lt;HOLMES-URL&gt;/api/issue_chat \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"ask\": \"How do I fix this issue?\",\n    \"investigation_result\": {\n      \"result\": \"Pod crashed due to OOM.\",\n      \"tools\": []\n    },\n    \"issue_type\": \"CrashLoopBackOff\",\n    \"conversation_history\": [\n      {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}\n    ]\n  }'\n</code></pre></p> <p>Example Response <pre><code>{\n  \"analysis\": \"To fix the CrashLoopBackOff, increase the memory limit for the pod and check for memory leaks in the application.\",\n  \"conversation_history\": [\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": \"How do I fix this issue?\"},\n    {\"role\": \"assistant\", \"content\": \"To fix the CrashLoopBackOff, increase the memory limit for the pod and check for memory leaks in the application.\"}\n  ],\n  \"tool_calls\": [...],\n  \"follow_up_actions\": [...]\n}\n</code></pre></p>"},{"location":"reference/http-api/#apiworkload_health_check-post","title":"<code>/api/workload_health_check</code> (POST)","text":"<p>Description: Performs a health check on a specified workload (e.g., a Kubernetes deployment).</p>"},{"location":"reference/http-api/#request-fields_4","title":"Request Fields","text":"Field Required Default Type Description ask Yes string User's question resource Yes object Resource details (e.g., name, kind) alert_history_since_hours No 24 float How many hours back to check alerts alert_history No true boolean Whether to include alert history stored_instructions No true boolean Use stored instructions instructions No [] list Additional instructions include_tool_calls No false boolean Include tool calls in response include_tool_call_results No false boolean Include tool call results in response prompt_template No \"builtin://kubernetes_workload_ask.jinja2\" string Prompt template to use model No string Model name from your <code>modelList</code> configuration <p>Example <pre><code>curl -X POST http://&lt;HOLMES-URL&gt;/api/workload_health_check \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"ask\": \"Why is my deployment unhealthy?\",\n    \"resource\": {\"name\": \"my-deployment\", \"kind\": \"Deployment\"},\n    \"alert_history_since_hours\": 12\n  }'\n</code></pre></p> <p>Example Response <pre><code>{\n  \"analysis\": \"Deployment 'my-deployment' is unhealthy due to repeated CrashLoopBackOff events.\",\n  \"sections\": null,\n  \"tool_calls\": [\n    {\n      \"tool_call_id\": \"2\",\n      \"tool_name\": \"kubectl_get_events\",\n      \"description\": \"Fetch recent events\",\n      \"result\": {\"events\": \"...\"}\n    }\n  ],\n  \"instructions\": [...]\n}\n</code></pre></p>"},{"location":"reference/http-api/#apiworkload_health_chat-post","title":"<code>/api/workload_health_chat</code> (POST)","text":"<p>Description: Conversational interface for discussing the health of a workload.</p>"},{"location":"reference/http-api/#request-fields_5","title":"Request Fields","text":"Field Required Default Type Description ask Yes string User's question workload_health_result Yes object Previous health check result (see below) resource Yes object Resource details conversation_history No list Conversation history (first message must be system) model No string Model name from your <code>modelList</code> configuration <p>workload_health_result object: - <code>analysis</code> (string, optional): Previous analysis - <code>tools</code> (list, optional): Tools used/results</p> <p>Example <pre><code>curl -X POST http://&lt;HOLMES-URL&gt;/api/workload_health_chat \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"ask\": \"Check the workload health.\",\n    \"workload_health_result\": {\n      \"analysis\": \"Previous health check: all good.\",\n      \"tools\": []\n    },\n    \"resource\": {\"name\": \"my-deployment\", \"kind\": \"Deployment\"},\n    \"conversation_history\": [\n      {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}\n    ]\n  }'\n</code></pre></p> <p>Example Response <pre><code>{\n  \"analysis\": \"The deployment 'my-deployment' is healthy. No recent issues detected.\",\n  \"conversation_history\": [\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": \"Check the workload health.\"},\n    {\"role\": \"assistant\", \"content\": \"The deployment 'my-deployment' is healthy. No recent issues detected.\"}\n  ],\n  \"tool_calls\": [...]\n}\n</code></pre></p>"},{"location":"reference/http-api/#apimodel-get","title":"<code>/api/model</code> (GET)","text":"<p>Description: Returns a list of available AI models that can be used for investigations and chat.</p> <p>Example <pre><code>curl http://&lt;HOLMES-URL&gt;/api/model\n</code></pre></p> <p>Example Response <pre><code>{\n  \"model_name\": [\"gpt-4.1\", \"azure/gpt-4.1\", \"robusta\"]\n}\n</code></pre></p>"},{"location":"reference/http-api/#server-sent-events-sse-reference","title":"Server-Sent Events (SSE) Reference","text":"<p>All streaming endpoints (<code>/api/stream/investigate</code>, <code>/api/stream/chat</code>, <code>/api/stream/issue_chat</code>, etc.) emit Server-Sent Events (SSE) to provide real-time updates during the investigation or chat process.</p>"},{"location":"reference/http-api/#metadata-object-reference","title":"Metadata Object Reference","text":"<p>Many events include a <code>metadata</code> object that provides detailed information about token usage, context window limits, and message truncation. This section describes the complete structure of the metadata object.</p>"},{"location":"reference/http-api/#token-usage-information","title":"Token Usage Information","text":"<p>Structure: <pre><code>{\n  \"metadata\": {\n    \"usage\": {\n      \"prompt_tokens\": 2500,\n      \"completion_tokens\": 150,\n      \"total_tokens\": 2650\n    },\n    \"tokens\": {\n      \"total_tokens\": 2650,\n      \"tools_tokens\": 100,\n      \"system_tokens\": 500,\n      \"user_tokens\": 300,\n      \"tools_to_call_tokens\": 50,\n      \"assistant_tokens\": 1600,\n      \"other_tokens\": 100\n    },\n    \"max_tokens\": 128000,\n    \"max_output_tokens\": 16384\n  }\n}\n</code></pre></p> <p>Fields:</p> <ul> <li><code>usage</code> (object): Token usage from the LLM provider (raw response from the model)</li> <li><code>prompt_tokens</code> (integer): Tokens in the prompt (input)</li> <li><code>completion_tokens</code> (integer): Tokens in the completion (output)</li> <li> <p><code>total_tokens</code> (integer): Total tokens used (prompt + completion)</p> </li> <li> <p><code>tokens</code> (object): HolmesGPT's detailed token count breakdown by message role</p> </li> <li><code>total_tokens</code> (integer): Total tokens in the conversation</li> <li><code>tools_tokens</code> (integer): Tokens used by tool definitions</li> <li><code>system_tokens</code> (integer): Tokens in system messages</li> <li><code>user_tokens</code> (integer): Tokens in user messages</li> <li><code>tools_to_call_tokens</code> (integer): Tokens used for tool call requests from the assistant</li> <li><code>assistant_tokens</code> (integer): Tokens in assistant messages (excluding tool calls)</li> <li> <p><code>other_tokens</code> (integer): Tokens from other message types</p> </li> <li> <p><code>max_tokens</code> (integer): Maximum context window size for the model</p> </li> <li><code>max_output_tokens</code> (integer): Maximum tokens reserved for model output</li> </ul>"},{"location":"reference/http-api/#truncation-information","title":"Truncation Information","text":"<p>When messages are truncated to fit within context limits, the metadata includes truncation details:</p> <p>Structure: <pre><code>{\n  \"metadata\": {\n    \"truncations\": [\n      {\n        \"tool_call_id\": \"call_abc123\",\n        \"start_index\": 0,\n        \"end_index\": 5000,\n        \"tool_name\": \"kubectl_logs\",\n        \"original_token_count\": 15000\n      }\n    ]\n  }\n}\n</code></pre></p> <p>Fields:</p> <ul> <li><code>truncations</code> (array): List of truncated tool results</li> <li><code>tool_call_id</code> (string): ID of the truncated tool call</li> <li><code>start_index</code> (integer): Character index where truncation starts (always 0)</li> <li><code>end_index</code> (integer): Character index where content was cut off</li> <li><code>tool_name</code> (string): Name of the tool whose output was truncated</li> <li><code>original_token_count</code> (integer): Original token count before truncation</li> </ul> <p>Truncated content will include a <code>[TRUNCATED]</code> marker at the end.</p>"},{"location":"reference/http-api/#event-types","title":"Event Types","text":""},{"location":"reference/http-api/#start_tool_calling","title":"<code>start_tool_calling</code>","text":"<p>Emitted when the AI begins executing a tool. This event is sent before the tool runs.</p> <p>Payload: <pre><code>{\n  \"tool_name\": \"kubectl_describe\",\n  \"id\": \"call_abc123\"\n}\n</code></pre></p> <p>Fields:</p> <ul> <li><code>tool_name</code> (string): The name of the tool being called</li> <li><code>id</code> (string): Unique identifier for this tool call</li> </ul>"},{"location":"reference/http-api/#tool_calling_result","title":"<code>tool_calling_result</code>","text":"<p>Emitted when a tool execution completes. Contains the tool's output and metadata.</p> <p>Payload: <pre><code>{\n  \"tool_call_id\": \"call_abc123\",\n  \"role\": \"tool\",\n  \"description\": \"kubectl describe pod my-pod -n default\",\n  \"name\": \"kubectl_describe\",\n  \"result\": {\n    \"status\": \"success\",\n    \"data\": \"...\",\n    \"error\": null,\n    \"params\": {\"pod\": \"my-pod\", \"namespace\": \"default\"}\n  }\n}\n</code></pre></p> <p>Fields:</p> <ul> <li><code>tool_call_id</code> (string): Unique identifier matching the <code>start_tool_calling</code> event</li> <li><code>role</code> (string): Always \"tool\"</li> <li><code>description</code> (string): Human-readable description of what the tool did</li> <li><code>name</code> (string): The name of the tool that was called</li> <li><code>result</code> (object): Tool execution result</li> <li><code>status</code> (string): One of \"success\", \"error\", \"approval_required\"</li> <li><code>data</code> (string|object): The tool's output data (stringified if complex)</li> <li><code>error</code> (string|null): Error message if the tool failed</li> <li><code>params</code> (object): Parameters that were passed to the tool</li> </ul>"},{"location":"reference/http-api/#ai_message","title":"<code>ai_message</code>","text":"<p>Emitted when the AI has a text message or reasoning to share (typically before tool calls).</p> <p>Payload: <pre><code>{\n  \"content\": \"I need to check the pod logs to understand the issue.\",\n  \"reasoning\": \"The pod is crashing, so examining logs will reveal the root cause.\",\n  \"metadata\": {...}\n}\n</code></pre></p> <p>Fields:</p> <ul> <li><code>content</code> (string|null): The AI's message content</li> <li><code>reasoning</code> (string|null): The AI's internal reasoning (only present for models that support reasoning like o1)</li> <li><code>metadata</code> (object): See Metadata Object Reference for complete structure</li> </ul>"},{"location":"reference/http-api/#ai_answer_end","title":"<code>ai_answer_end</code>","text":"<p>Emitted when the investigation or chat is complete. This is the final event in the stream.</p> <p>For RCA/Investigation (<code>/api/stream/investigate</code>): <pre><code>{\n  \"sections\": {\n    \"Alert Explanation\": \"...\",\n    \"Key Findings\": \"...\",\n    \"Conclusions and Possible Root Causes\": \"...\",\n    \"Next Steps\": \"...\",\n    \"App or Infra?\": \"...\",\n    \"External links\": \"...\"\n  },\n  \"analysis\": \"Full analysis text...\",\n  \"instructions\": [\"runbook1\", \"runbook2\"],\n  \"metadata\": {...}\n}\n</code></pre></p> <p>For Chat (<code>/api/stream/chat</code>, <code>/api/stream/issue_chat</code>): <pre><code>{\n  \"analysis\": \"The issue can be resolved by...\",\n  \"conversation_history\": [\n    {\"role\": \"system\", \"content\": \"...\"},\n    {\"role\": \"user\", \"content\": \"...\"},\n    {\"role\": \"assistant\", \"content\": \"...\"}\n  ],\n  \"follow_up_actions\": [\n    {\n      \"id\": \"action1\",\n      \"action_label\": \"Run diagnostics\",\n      \"pre_action_notification_text\": \"Running diagnostics...\",\n      \"prompt\": \"Run diagnostic checks\"\n    }\n  ],\n  \"metadata\": {...}\n}\n</code></pre></p> <p>Common Fields:</p> <ul> <li><code>metadata</code> (object): See Metadata Object Reference for complete structure including token usage, truncations, and compaction info</li> </ul> <p>RCA-Specific Fields:</p> <ul> <li><code>sections</code> (object): Structured investigation output with predefined sections (customizable via request)</li> <li><code>analysis</code> (string): Full analysis text (markdown format)</li> <li><code>instructions</code> (array): List of runbooks that were used during investigation</li> </ul> <p>Chat-Specific Fields:</p> <ul> <li><code>analysis</code> (string): The AI's response (markdown format)</li> <li><code>conversation_history</code> (array): Complete conversation history including the latest response</li> <li><code>follow_up_actions</code> (array|null): Optional follow-up actions the user can take</li> <li><code>id</code> (string): Unique identifier for the action</li> <li><code>action_label</code> (string): Display label for the action</li> <li><code>pre_action_notification_text</code> (string): Text to show before executing the action</li> <li><code>prompt</code> (string): The prompt to send when the action is triggered</li> </ul>"},{"location":"reference/http-api/#approval_required","title":"<code>approval_required</code>","text":"<p>Emitted when tool execution requires user approval (e.g., potentially destructive operations). The stream pauses until the user provides approval decisions via a subsequent request.</p> <p>Payload: <pre><code>{\n  \"content\": null,\n  \"conversation_history\": [...],\n  \"follow_up_actions\": [...],\n  \"requires_approval\": true,\n  \"pending_approvals\": [\n    {\n      \"tool_call_id\": \"call_xyz789\",\n      \"tool_name\": \"kubectl_delete\",\n      \"description\": \"kubectl delete pod failed-pod -n default\",\n      \"params\": {\"pod\": \"failed-pod\", \"namespace\": \"default\"}\n    }\n  ]\n}\n</code></pre></p> <p>Fields:</p> <ul> <li><code>content</code> (null): No AI content when approval is required</li> <li><code>conversation_history</code> (array): Current conversation state</li> <li><code>follow_up_actions</code> (array|null): Optional follow-up actions</li> <li><code>requires_approval</code> (boolean): Always true for this event</li> <li><code>pending_approvals</code> (array): List of tools awaiting approval</li> <li><code>tool_call_id</code> (string): Unique identifier for the tool call</li> <li><code>tool_name</code> (string): Name of the tool requiring approval</li> <li><code>description</code> (string): Human-readable description</li> <li><code>params</code> (object): Parameters for the tool call</li> </ul> <p>To continue after approval, send a new request with <code>tool_decisions</code>: <pre><code>{\n  \"conversation_history\": [...],\n  \"tool_decisions\": [\n    {\"tool_call_id\": \"call_xyz789\", \"approved\": true}\n  ]\n}\n</code></pre></p>"},{"location":"reference/http-api/#token_count","title":"<code>token_count</code>","text":"<p>Emitted periodically to provide token usage updates during the investigation. This event is sent after each LLM iteration to help track resource consumption in real-time.</p> <p>Payload: <pre><code>{\n  \"metadata\": {...}\n}\n</code></pre></p> <p>Fields:</p> <ul> <li><code>metadata</code> (object): See Metadata Object Reference for complete token usage structure. This event provides the same metadata structure as other events, allowing you to monitor token consumption throughout the investigation</li> </ul>"},{"location":"reference/http-api/#conversation_history_compacted","title":"<code>conversation_history_compacted</code>","text":"<p>Emitted when the conversation history has been compacted to fit within the context window. This happens automatically when the conversation grows too large.</p> <p>Payload: <pre><code>{\n  \"content\": \"Conversation history was compacted to fit within context limits.\",\n  \"messages\": [...],\n  \"metadata\": {\n    \"initial_tokens\": 150000,\n    \"compacted_tokens\": 80000\n  }\n}\n</code></pre></p> <p>Fields:</p> <ul> <li><code>content</code> (string): Human-readable description of the compaction</li> <li><code>messages</code> (array): The compacted conversation history</li> <li><code>metadata</code> (object): Token information about the compaction</li> <li><code>initial_tokens</code> (integer): Token count before compaction</li> <li><code>compacted_tokens</code> (integer): Token count after compaction</li> </ul>"},{"location":"reference/http-api/#error","title":"<code>error</code>","text":"<p>Emitted when an error occurs during processing.</p> <p>Payload: <pre><code>{\n  \"description\": \"Rate limit exceeded\",\n  \"error_code\": 5204,\n  \"msg\": \"Rate limit exceeded\",\n  \"success\": false\n}\n</code></pre></p> <p>Fields:</p> <ul> <li><code>description</code> (string): Detailed error description</li> <li><code>error_code</code> (integer): Numeric error code</li> <li><code>msg</code> (string): Error message</li> <li><code>success</code> (boolean): Always false</li> </ul> <p>Common Error Codes:</p> <ul> <li><code>5204</code>: Rate limit exceeded</li> <li><code>1</code>: Generic error</li> </ul>"},{"location":"reference/http-api/#event-flow-examples","title":"Event Flow Examples","text":""},{"location":"reference/http-api/#typical-rca-investigation-flow","title":"Typical RCA Investigation Flow","text":"<pre><code>1. start_tool_calling (tool 1)\n2. start_tool_calling (tool 2)\n3. tool_calling_result (tool 1)\n4. tool_calling_result (tool 2)\n5. token_count\n6. start_tool_calling (tool 3)\n7. tool_calling_result (tool 3)\n8. token_count\n9. ai_answer_end\n</code></pre>"},{"location":"reference/http-api/#chat-with-approval-flow","title":"Chat with Approval Flow","text":"<pre><code>1. ai_message\n2. start_tool_calling (safe tool)\n3. start_tool_calling (requires approval)\n4. tool_calling_result (safe tool)\n5. tool_calling_result (approval required with status: \"approval_required\")\n6. approval_required\n[Client sends approval decisions]\n1. tool_calling_result (approved tool executed)\n[investigation resumes]\n</code></pre>"},{"location":"reference/http-api/#chat-with-history-compaction","title":"Chat with History Compaction","text":"<pre><code>1. conversation_history_compacted\n2. start_tool_calling (tool 1)\n3. tool_calling_result (tool 1)\n4. token_count\n5. ai_answer_end\n</code></pre>"},{"location":"reference/slash-commands/","title":"Slash Commands","text":"<p>Slash commands provide special actions in HolmesGPT's interactive mode. Type any command with a leading <code>/</code> to execute it.</p>"},{"location":"reference/slash-commands/#built-in-commands","title":"Built-in Commands","text":"Command Description <code>/help</code> Show all available commands and their descriptions <code>/exit</code> Exit interactive mode and return to shell <code>/clear</code> Clear conversation history and start fresh <code>/tools</code> Show available toolsets and their status <code>/context</code> Display token usage and context size information <code>/auto</code> Toggle automatic display of tool outputs <code>/last</code> Show tool outputs from the most recent AI response <code>/show [number\\|name]</code> View specific tool output in scrollable modal <code>/run &lt;command&gt;</code> Execute shell command and optionally share with AI <code>/shell</code> Start interactive shell session"},{"location":"reference/slash-commands/#command-details","title":"Command Details","text":""},{"location":"reference/slash-commands/#help","title":"<code>/help</code>","text":"<p>Displays all available slash commands and their descriptions.</p> <pre><code>&gt; /help\n</code></pre>"},{"location":"reference/slash-commands/#exit","title":"<code>/exit</code>","text":"<p>Exits the interactive session and returns to your shell. Alternative: press <code>Ctrl+C</code> twice.</p> <pre><code>&gt; /exit\n</code></pre>"},{"location":"reference/slash-commands/#clear","title":"<code>/clear</code>","text":"<p>Clears all conversation history and starts fresh. Useful when switching topics or when context becomes too large.</p> <pre><code>&gt; /clear\n</code></pre>"},{"location":"reference/slash-commands/#tools","title":"<code>/tools</code>","text":"<p>Lists all configured toolsets and their current status (enabled/disabled).</p> <pre><code>&gt; /tools\nAvailable toolsets:\n\u2713 kubernetes (enabled)\n\u2713 prometheus (enabled)\n\u2717 grafana (disabled - no URL configured)\n</code></pre>"},{"location":"reference/slash-commands/#context","title":"<code>/context</code>","text":"<p>Displays detailed information about token usage and context size.</p> <pre><code>&gt; /context\nContext Usage:\n- System: 1,250 tokens\n- User: 3,421 tokens\n- Assistant: 2,156 tokens\n- Tools: 5,234 tokens\nTotal: 12,061 / 128,000 tokens (9.4%)\n\nTop tools by token usage:\n1. kubernetes_get_pod_logs: 2,341 tokens\n2. kubernetes_describe_pod: 1,893 tokens\n</code></pre>"},{"location":"reference/slash-commands/#auto","title":"<code>/auto</code>","text":"<p>Controls whether tool outputs are automatically shown after each AI response. When disabled, use <code>/last</code> to view outputs.</p> <pre><code>&gt; /auto\nAuto-display tool outputs: ON\n</code></pre>"},{"location":"reference/slash-commands/#last","title":"<code>/last</code>","text":"<p>Displays all tool outputs from the most recent AI response. Useful when auto-display is off or to review outputs again.</p> <pre><code>&gt; /last\n</code></pre>"},{"location":"reference/slash-commands/#show-numbername","title":"<code>/show [number|name]</code>","text":"<p>Opens a scrollable modal to view full tool output. You can specify outputs by: - Number: <code>/show 3</code> (shows 3<sup>rd</sup> tool output) - Name: <code>/show kubernetes_get_pod_logs</code> (shows specific tool output)</p> <pre><code>&gt; /show 1\n&gt; /show kubernetes_get_pod_logs\n</code></pre>"},{"location":"reference/slash-commands/#modal-navigation","title":"Modal Navigation","text":"<ul> <li><code>j</code>/<code>k</code> or \u2191/\u2193 - Move up/down</li> <li><code>g</code>/<code>G</code> - Go to top/bottom</li> <li><code>d</code>/<code>u</code> - Half page down/up</li> <li><code>f</code>/<code>b</code> or PgDn/PgUp - Full page down/up</li> <li><code>w</code> - Toggle word wrap</li> <li><code>q</code> or Esc - Close modal</li> </ul>"},{"location":"reference/slash-commands/#run-command","title":"<code>/run &lt;command&gt;</code>","text":"<p>Runs a shell command and optionally shares the output with the AI.</p> <pre><code>&gt; /run kubectl get pods -n production\n# Output displayed...\nShare output with AI? (Y/n): y\nAdd a comment or question (optional): why are some pods in CrashLoopBackOff?\n</code></pre>"},{"location":"reference/slash-commands/#shell","title":"<code>/shell</code>","text":"<p>Starts an interactive shell session. When you exit, you can share the entire session with the AI.</p> <pre><code>&gt; /shell\n$ kubectl logs failing-pod-xyz\n$ kubectl describe pod failing-pod-xyz\n$ exit\nShare shell session with AI? (Y/n): y\nAdd a comment or question (optional): The pod keeps failing with OOM errors\n</code></pre>"},{"location":"reference/troubleshooting/","title":"HolmesGPT Not Finding Any Issues? Here's Why.","text":""},{"location":"reference/troubleshooting/#1-truncation-too-much-data","title":"1. Truncation: Too Much Data","text":"<p>Data overflow causes important information to be truncated. See #437 for summarization improvements.</p> <p>Solution:</p> <ul> <li>Use specific namespaces and time ranges</li> <li>Target individual components instead of cluster-wide queries</li> </ul>"},{"location":"reference/troubleshooting/#2-missing-data-access","title":"2. Missing Data Access","text":"<p>HolmesGPT can't access logs, metrics, or traces from your observability stack.</p> <p>Solution:</p> <ul> <li>Verify toolset configuration connects to Prometheus/Grafana/logs</li> <li>Test connectivity: <code>kubectl exec -it &lt;holmes-pod&gt; -- curl http://prometheus:9090/api/v1/query?query=up</code></li> </ul>"},{"location":"reference/troubleshooting/#3-rbac-permissions","title":"3. RBAC Permissions","text":"<p>Service account lacks Kubernetes API permissions.</p> <p>Error Example: <pre><code>pods is forbidden: User \"system:serviceaccount:default:holmesgpt\" cannot get resource \"pods\"\n</code></pre></p> <p>Solution: <pre><code>rbac:\n  create: true\nrbacRules:\n  - apiGroups: [\"\"]\n    resources: [\"pods\", \"services\", \"events\", \"nodes\"]\n    verbs: [\"get\", \"list\", \"watch\"]\n</code></pre></p>"},{"location":"reference/troubleshooting/#4-unclear-prompts","title":"4. Unclear Prompts","text":"<p>Vague questions produce poor results.</p> <p>Bad:</p> <ul> <li>\"Why is my pod not working?\"</li> <li>\"Check if anything is wrong with my cluster\"</li> <li>\"Something is broken in production and users are complaining\"</li> <li>\"My deployment keeps failing but I don't know why\"</li> <li>\"Can you debug this issue I'm having with my application?\"</li> </ul> <p>Good:</p> <ul> <li>\"Why is payment-service pod restarting in production namespace?\"</li> <li>\"What caused memory spike in web-frontend deployment last hour?\"</li> </ul>"},{"location":"reference/troubleshooting/#5-model-issues","title":"5. Model Issues","text":"<p>Older LLM models lack reasoning capability for complex problems.</p> <p>Solution: <pre><code>config:\n  model: \"gpt-4.1\"  # or anthropic/claude-sonnet-4-20250514\n  temperature: 0.1\n  maxTokens: 2000\n</code></pre></p> <p>Recommended Models:</p> <ul> <li><code>anthropic/claude-opus-4-1-20250805</code> - Most powerful for complex investigations (recommended)</li> <li><code>anthropic/claude-sonnet-4-20250514</code> - Superior reasoning with faster performance</li> <li><code>gpt-4.1</code> - Good balance of speed/capability</li> </ul> <p>See benchmark results for detailed model performance comparisons.</p>"},{"location":"reference/troubleshooting/#still-stuck","title":"Still stuck?","text":"<p>Join our Slack community or open a GitHub issue for help.</p>"},{"location":"walkthrough/","title":"Walkthrough","text":"<p>Get started with HolmesGPT by running your first investigation.</p>"},{"location":"walkthrough/#prerequisites","title":"Prerequisites","text":"<p>Before starting, ensure you have:</p> <ul> <li>\u2705 HolmesGPT CLI installed - See CLI Installation Guide</li> <li>\u2705 AI provider API key configured - See AI Provider Setup</li> <li>\u2705 kubectl access to a Kubernetes cluster - Any cluster will work</li> </ul>"},{"location":"walkthrough/#run-your-first-investigation","title":"Run Your First Investigation","text":"<p>Let's investigate a pod with HolmesGPT to see the value it provides:</p> <ol> <li> <p>Create a test pod with an issue: <pre><code>kubectl apply -f https://raw.githubusercontent.com/robusta-dev/kubernetes-demos/main/pending_pods/pending_pod_node_selector.yaml\n</code></pre></p> </li> <li> <p>Ask Holmes to investigate:</p> OpenAI (Default)Azure OpenAIAnthropic ClaudeGoogle GeminiAWS BedrockOllama <pre><code>holmes ask \"describe the user-profile-import pod and explain any issues\"\n</code></pre> <pre><code>holmes ask \"describe the user-profile-import pod and explain any issues\" --model=\"azure/&lt;your-model-name&gt;\"\n</code></pre> <pre><code>holmes ask \"describe the user-profile-import pod and explain any issues\" --model=\"anthropic/&lt;your-model-name&gt;\"\n</code></pre> <pre><code>holmes ask \"describe the user-profile-import pod and explain any issues\" --model=\"google/&lt;your-model-name&gt;\"\n</code></pre> <pre><code>holmes ask \"describe the user-profile-import pod and explain any issues\" --model=\"bedrock/&lt;your-model-name&gt;\"\n</code></pre> <pre><code>holmes ask \"describe the user-profile-import pod and explain any issues\" --model=\"ollama/&lt;your-model-name&gt;\"\n</code></pre> </li> <li> <p>See the value:</p> <p>Holmes will analyze the pod, identify that it's stuck in \"Pending\" state due to an invalid node selector, and suggest specific remediation steps - all without you needing to manually run <code>kubectl describe</code>, check events, or dig through logs.</p> </li> </ol>"},{"location":"walkthrough/#what-you-just-experienced","title":"What You Just Experienced","text":"<p>HolmesGPT automatically:</p> <ul> <li>\u2705 Gathered context - Retrieved pod status, events, and related information</li> <li>\u2705 Identified the root cause - Invalid node selector preventing scheduling</li> <li>\u2705 Provided actionable solutions - Specific commands to fix the issue</li> <li>\u2705 Saved investigation time - No manual troubleshooting steps required</li> </ul>"},{"location":"walkthrough/#clean-up","title":"Clean Up","text":"<p>Remove the test pod:</p> <pre><code>kubectl delete pod user-profile-import\n</code></pre>"},{"location":"walkthrough/#next-steps","title":"Next Steps","text":"<ul> <li>Add integrations - Connect monitoring tools like Prometheus, Grafana, and DataDog</li> <li>Troubleshooting guide - Common issues and solutions</li> <li>Join our Slack - Get help from the community</li> <li>Request features on GitHub - Suggest improvements or report bugs</li> </ul>"},{"location":"walkthrough/cicd-troubleshooting/","title":"CI/CD Pipeline Troubleshooting","text":"<p>HolmesGPT can be integrated into CI/CD pipelines to automatically troubleshoot deployment failures, providing instant insights when deployments fail. Optionally, you can get the AI investigation results sent directly to your Slack channel.</p> <p></p>"},{"location":"walkthrough/cicd-troubleshooting/#automated-deployment-troubleshooting","title":"Automated Deployment Troubleshooting","text":"<p>Example of using HolmesGPT in a CI/CD pipeline to automatically troubleshoot deployment failures and send results to Slack:</p> <pre><code># .github/workflows/deploy.yml or gitlab-ci.yml\n- name: Install HolmesGPT\n  run: |\n    # Clone the branch of holmes you want to install\n    git clone -b slack-markdown-fix https://github.com/robusta-dev/holmesgpt.git /tmp/holmesgpt\n    cd /tmp/holmesgpt\n\n    # Install Poetry\n    curl -sSL https://install.python-poetry.org | python3 - --version 1.4.0\n    export PATH=\"$HOME/.local/bin:$PATH\"\n\n    # Install dependencies using Poetry\n    poetry install\n\n- name: Deploy to EKS\n  env:\n    OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}\n  run: |\n    # Apply Kubernetes manifests\n    kubectl apply -f https://raw.githubusercontent.com/robusta-dev/kubernetes-demos/refs/heads/main/image_pull_backoff/no_such_image.yaml\n    # Wait for rollout\n    if ! kubectl rollout status deployment/customer-relations-webapp --timeout=150s; then\n      echo \"Deployment failed - starting HolmesGPT investigation\"\n      # Run HolmesGPT investigation and send directly to Slack\n      cd /tmp/holmesgpt\n      poetry run holmes ask \\\n        \"\ud83d\udea8 EKS Deployment Failed in ${{ github.repository }}\n\n        Environment: EKS Cluster ${{ vars.EKS_CLUSTER_NAME }} in ${{ vars.AWS_REGION }}\n        Commit: ${{ github.sha }}\n        Pipeline: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}\n\n        The deployment failed. Analyze why the pods are not becoming ready. Focus on: image pulls, resource limits, probes, and configuration issues\" \\\n        --no-interactive \\\n        --destination slack \\\n        --slack-token \"${{ secrets.SLACK_TOKEN }}\" \\\n        --slack-channel \"#YOUR_CHANNEL_NAME\"\n      exit 1\n    fi\n</code></pre> Complete Example GitHub Actions Workflow <pre><code>name: Deploy to Production\n\non:\n  push:\n    branches:\n      - main\n  workflow_dispatch:\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n\n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v4\n\n    - name: Configure AWS credentials\n      uses: aws-actions/configure-aws-credentials@v4\n      with:\n        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}\n        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n        aws-region: ${{ vars.AWS_REGION }}\n\n    - name: Set up kubectl\n      uses: azure/setup-kubectl@v3\n      with:\n        version: v1.28.0\n\n    - name: Configure kubectl for EKS\n      run: |\n        aws eks update-kubeconfig --region ${{ vars.AWS_REGION }} --name ${{ vars.EKS_CLUSTER_NAME }}\n        # Get current user ARN and add to cluster access\n        USER_ARN=$(aws sts get-caller-identity --query Arn --output text)\n        aws eks create-access-entry --cluster-name ${{ vars.EKS_CLUSTER_NAME }} --principal-arn $USER_ARN --region ${{ vars.AWS_REGION }} || true\n        aws eks associate-access-policy --cluster-name ${{ vars.EKS_CLUSTER_NAME }} --principal-arn $USER_ARN --policy-arn arn:aws:eks::aws:cluster-access-policy/AmazonEKSClusterAdminPolicy --access-scope type=cluster --region ${{ vars.AWS_REGION }} || true\n\n    - name: Debug kubeconfig\n      run: |\n        echo \"Testing kubectl connection...\"\n        kubectl config current-context &gt; /dev/null\n        kubectl cluster-info &gt; /dev/null\n        kubectl auth can-i get pods --namespace=default &gt; /dev/null\n        echo \"kubectl connection verified\"\n\n    - name: Install HolmesGPT\n      run: |\n        # Clone the branch of holmes you want to install\n        git clone -b slack-markdown-fix https://github.com/robusta-dev/holmesgpt.git /tmp/holmesgpt\n        cd /tmp/holmesgpt\n\n        # Install Poetry\n        curl -sSL https://install.python-poetry.org | python3 - --version 1.4.0\n        export PATH=\"$HOME/.local/bin:$PATH\"\n\n        # Install dependencies using Poetry\n        poetry install\n\n    - name: Deploy to EKS\n      env:\n        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}\n      run: |\n        # Apply Kubernetes manifests\n        kubectl apply -f https://raw.githubusercontent.com/robusta-dev/kubernetes-demos/refs/heads/main/image_pull_backoff/no_such_image.yaml\n        # Wait for rollout\n        if ! kubectl rollout status deployment/customer-relations-webapp --timeout=150s; then\n          echo \"Deployment failed - starting HolmesGPT investigation\"\n          # Run HolmesGPT investigation and send directly to Slack\n          cd /tmp/holmesgpt\n          poetry run holmes ask \\\n            \"\ud83d\udea8 EKS Deployment Failed in ${{ github.repository }}\n\n            Environment: EKS Cluster ${{ vars.EKS_CLUSTER_NAME }} in ${{ vars.AWS_REGION }}\n            Commit: ${{ github.sha }}\n            Pipeline: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}\n\n            The deployment failed. Analyze why the pods are not becoming ready. Focus on: image pulls, resource limits, probes, and configuration issues\" \\\n            --no-interactive \\\n            --destination slack \\\n            --slack-token \"${{ secrets.SLACK_TOKEN }}\" \\\n            --slack-channel \"#YOUR_CHANNEL_NAME\"\n          exit 1\n        fi\n</code></pre>"},{"location":"walkthrough/cicd-troubleshooting/#simplified-approaches","title":"Simplified Approaches","text":"<p>The built-in Slack integration will automatically format and send the analysis to your specified channel. You can also use a simpler approach for basic deployments:</p> <pre><code># Simple deployment check with Slack notification\nkubectl rollout status deployment/app -n prod --timeout=300s || \\\n  holmes ask \"deployment/app in prod namespace failed to roll out\" \\\n    --destination slack \\\n    --slack-token \"$SLACK_TOKEN\" \\\n    --slack-channel \"#alerts\"\n</code></pre>"},{"location":"walkthrough/interactive-mode/","title":"Interactive Mode","text":"<p>HolmesGPT's interactive mode provides a powerful chat-like interface for iterative troubleshooting and investigation of cloud-native issues using LLMs.</p>"},{"location":"walkthrough/interactive-mode/#getting-started","title":"Getting Started","text":""},{"location":"walkthrough/interactive-mode/#launching-interactive-mode","title":"Launching Interactive Mode","text":"<p>Interactive mode is the default when running <code>holmes ask</code>:</p> <pre><code>holmes ask\n</code></pre> <p>You can also provide an initial question:</p> <pre><code>holmes ask \"what pods are failing?\"\n</code></pre>"},{"location":"walkthrough/interactive-mode/#example-workflows","title":"Example Workflows","text":""},{"location":"walkthrough/interactive-mode/#autonomous-ai-investigation","title":"Autonomous AI Investigation","text":"<p>In this example, the AI independently investigates and diagnoses an issue using its available tools:</p> <pre><code>holmes ask\n\n&gt; why is the payment-service in production namespace not responding to requests?\n\nRunning tool #1 kubectl_find_resource: kubectl get -A --show-labels -o wide deployment | grep payment\n  Finished #1 in 1.32s, output length: 894 characters - /show 1 to view contents\n\nRunning tool #2 kubectl_describe: kubectl describe deployment payment-service -n production\n  Finished #2 in 1.45s, output length: 2,341 characters - /show 2 to view contents\n\nRunning tool #3 kubectl_get_by_kind_in_namespace: kubectl get pod -n production -o wide --show-labels | grep -E 'NAME|payment'\n  Finished #3 in 1.28s, output length: 456 characters - /show 3 to view contents\n\nRunning tool #4 fetch_pod_logs: Fetching logs for pod payment-service-7b9c5d4-xyz in namespace production\n  Finished #4 in 2.87s, output length: 8,234 characters - /show 4 to view contents\n\nRunning tool #5 kubectl_events: kubectl get events -n production --field-selector involvedObject.name=payment-service-7b9c5d4-xyz\n  Finished #5 in 1.19s, output length: 1,203 characters - /show 5 to view contents\n\nBased on my investigation, the payment-service is not responding due to:\n\n1. **Database Connection Failures**: The logs show repeated \"connection refused\" errors to `payment-db:5432`\n2. **StatefulSet Down**: The payment-db StatefulSet has 0/1 replicas running\n3. **PVC Pending**: The database's PersistentVolumeClaim is stuck in Pending status\n\nRoot cause appears to be storage-related. Let me check the PVC status.\n\n&gt; can you check why the PVC is pending?\n\nRunning tool #1 kubectl_describe: kubectl describe pvc payment-db-pvc-0 -n production\n  Finished #1 in 1.38s, output length: 1,567 characters - /show 1 to view contents\n\nRunning tool #2 kubectl_get: kubectl get storageclass fast-ssd -o yaml\n  Finished #2 in 1.14s, output length: 134 characters - /show 2 to view contents\n\nRunning tool #3 kubectl_get_by_kind_in_namespace: kubectl get storageclass\n  Finished #3 in 1.23s, output length: 456 characters - /show 3 to view contents\n\nThe PVC is pending because the requested StorageClass doesn't exist:\n\n\n  Error from server (NotFound): storageclasses.storage.k8s.io \"fast-ssd\" not found\n\nAvailable StorageClasses in the cluster:\n- **gp2** (default) - EBS General Purpose SSD\n- **gp3** - EBS General Purpose SSD (newer generation)\n- **io1** - EBS Provisioned IOPS SSD\n- **standard** - EBS Magnetic volumes\n</code></pre>"},{"location":"walkthrough/interactive-mode/#human-in-the-loop-investigation","title":"Human-in-the-Loop Investigation","text":"<p>In this example, the human provides additional context and runs commands the AI couldn't access:</p> <pre><code>holmes ask \"users are reporting intermittent 502 errors on the checkout page but I don't see any pod failures\"\n\nRunning tool #1 kubectl_get_by_kind_in_namespace: kubectl get pod -n production -o wide --show-labels\n  Finished #1 in 1.41s, output length: 3,234 characters - /show 1 to view contents\n\nRunning tool #2 kubectl_top_pods: kubectl top pods -n production --containers\n  Finished #2 in 2.18s, output length: 1,876 characters - /show 2 to view contents\n\nRunning tool #3 fetch_pod_logs: Fetching logs for pod frontend-6d4cf56-abc in namespace production. filter=502|error\n  Finished #3 in 3.21s, output length: 456 characters - /show 3 to view contents\n\nRunning tool #4 prometheus_query: query='rate(http_requests_total{status=\"502\"}[5m])'\n  Finished #4 in 1.92s, output length: 234 characters - /show 4 to view contents\n\nAll pods are healthy with normal resource usage. The 502 errors in the logs show \"upstream connect error\". The errors spike every 10 minutes. I need access to:\n- Load balancer/ingress controller logs\n- Corporate proxy or WAF logs if you use one\n- Database connection pool metrics from inside the app\n- Any recent network or firewall changes\n\n&gt; /run aws elbv2 describe-target-health --target-group-arn arn:aws:elasticloadbalancing:us-east-1:123456:targetgroup/prod-tg/abc123\nRunning command: aws elbv2 describe-target-health --target-group-arn arn:aws:elasticloadbalancing:us-east-1:123456:targetgroup/prod-tg/abc123\n\n{\n  \"TargetHealthDescriptions\": [\n    {\n      \"Target\": {\"Id\": \"i-0abc123\", \"Port\": 80},\n      \"HealthCheckPort\": \"80\",\n      \"TargetHealth\": {\n        \"State\": \"unhealthy\",\n        \"Reason\": \"Target.Timeout\",\n        \"Description\": \"Request timed out\"\n      }\n    }\n  ]\n}\n\nShare output with AI? (Y/n): y\nAdd a comment or question (optional): This is our ALB target group\n\nThe issue is clearer now. The ALB target `i-0abc123` is failing health checks with timeouts. This EC2 instance appears to be outside your Kubernetes cluster.\n\n&gt; /run ssh admin@10.0.1.50 \"sudo tail -100 /var/log/nginx/error.log | grep -i 'too many' | head -5\"\nRunning command: ssh admin@10.0.1.50 \"sudo tail -100 /var/log/nginx/error.log | grep -i 'too many' | head -5\"\n\n2024/11/20 10:00:01 [error] 1234#1234: *456789 limiting connections by zone \"perip\", client: 10.0.2.100\n2024/11/20 10:10:02 [error] 1234#1234: *456790 limiting connections by zone \"perip\", client: 10.0.2.100\n2024/11/20 10:20:01 [error] 1234#1234: *456791 limiting connections by zone \"perip\", client: 10.0.2.100\n2024/11/20 10:30:03 [error] 1234#1234: *456792 limiting connections by zone \"perip\", client: 10.0.2.100\n2024/11/20 10:40:02 [error] 1234#1234: *456793 limiting connections by zone \"perip\", client: 10.0.2.100\n\nShare output with AI? (Y/n): y\nAdd a comment or question (optional): This is the nginx rate limiting on the EC2 instance. 10.0.2.100 is our k8s cluster NAT gateway\n\n**Root Cause Found**: The 502 errors are caused by Nginx rate limiting on the EC2 instance:\n\n1. **Every 10 minutes** your Kubernetes pods hit the rate limit\n2. **Source IP problem**: All K8s traffic appears as one IP (10.0.2.100 - NAT Gateway)\n3. **Nginx configuration**: `limit_req_zone $binary_remote_addr zone=perip` treats all K8s traffic as one client\n\n**Solution**:\n```nginx\n# Update nginx config to use X-Forwarded-For for K8s traffic\nmap $remote_addr $limit_key {\n    \"10.0.2.100\" $http_x_forwarded_for;  # K8s NAT Gateway\n    default      $binary_remote_addr;\n}\nlimit_req_zone $limit_key zone=perip:10m rate=100r/s;\n</code></pre>"},{"location":"walkthrough/interactive-mode/#scenarios-to-consider-using-run-or-shell","title":"Scenarios to Consider Using /run or /shell","text":"<ol> <li>Access to Data HolmesGPT Can't Access on It's Own</li> <li>ssh'ing into a machine</li> <li>run commands with escalated permisssions (sudo)</li> <li> <p>accessing data sources HolmesGPT can't access on it's own</p> </li> <li> <p>Adding Business Context</p> </li> <li>Pulling in marketing data with recent campaign launch times</li> <li> <p>Fetcing planned maintenance windows from a source HolmesGPT does not know about</p> </li> <li> <p>Sharing Development/Testing Insights</p> </li> <li>Point HolmesGPT at recent code deployments or git commits</li> </ol>"},{"location":"walkthrough/interactive-mode/#tips-and-best-practices","title":"Tips and Best Practices","text":"<ol> <li>Use <code>/reset</code> when switching topics - This gives you a fresh context and prevents confusion</li> <li>Use <code>/run</code> if the AI is missing something important - Guide the investigation by showing it what it is missing</li> <li>Check <code>/context</code> periodically - Especially during long investigations</li> <li>View evidence with <code>/show</code> - Full outputs often contain important details</li> <li>Add comments when sharing shell output - Helps the AI understand what you're looking for</li> </ol>"},{"location":"walkthrough/interactive-mode/#beyond-interactive-mode","title":"Beyond Interactive Mode","text":"<p>For additional HolmesGPT usage patterns, see:</p> <ul> <li>CI/CD Troubleshooting - Integrate HolmesGPT into deployment pipelines</li> </ul>"},{"location":"walkthrough/investigating-prometheus-alerts/","title":"Investigating Prometheus Alerts","text":"<p>You can investigate Prometheus/AlertManager alerts using HolmesGPT by connecting it to your AlertManager instance. This allows you to run investigations on all active alerts or a specific alert.</p> <p></p>"},{"location":"walkthrough/investigating-prometheus-alerts/#prerequisites","title":"Prerequisites","text":"<ul> <li>HolmesGPT CLI installed (installation guide)</li> <li>An AI provider API key configured (setup guide)</li> <li>Access to your AlertManager instance</li> </ul>"},{"location":"walkthrough/investigating-prometheus-alerts/#investigating-a-prometheus-alert-using-holmesgpt","title":"Investigating a Prometheus Alert Using HolmesGPT","text":""},{"location":"walkthrough/investigating-prometheus-alerts/#step-1-forward-alertmanager","title":"Step 1: Forward AlertManager","text":"<p>First, you need to forward the AlertManager service to your local machine so HolmesGPT can connect to it. Run the following command in your terminal:</p> <pre><code>kubectl port-forward svc/&lt;Your-Alertmanager-Service&gt; 9093:9093\n</code></pre>"},{"location":"walkthrough/investigating-prometheus-alerts/#step-2-create-a-test-alert","title":"Step 2: Create a Test Alert","text":"<p>Now we'll deploy a crashing workload and simulate an alert from AlertManager.</p> <p><pre><code>kubectl apply -f https://raw.githubusercontent.com/robusta-dev/kubernetes-demos/main/crashpod/broken.yaml\n</code></pre> Since it takes some time for the alert to be generated, we will manually send a <code>KubePodCrashLooping</code> alert to AlertManager for testing purposes. To do this run: <pre><code># Send a KubePodCrashLooping alert directly to AlertManager\ncurl -X POST http://localhost:9093/api/v1/alerts \\\n  -H \"Content-Type: application/json\" \\\n  -d '[\n    {\n      \"labels\": {\n        \"alertname\": \"KubePodCrashLooping\",\n        \"severity\": \"warning\",\n        \"namespace\": \"default\",\n        \"pod\": \"payment-processing-worker\",\n        \"container\": \"worker\",\n        \"job\": \"kubernetes-pods\"\n      },\n      \"annotations\": {\n        \"description\": \"Pod default/payment-processing-worker is crash looping\",\n        \"summary\": \"Pod is in CrashLoopBackOff state\"\n      },\n      \"generatorURL\": \"http://prometheus:9090/graph?g0.expr=increase%28kube_pod_container_status_restarts_total%5B1h%5D%29%20%3E%205\",\n      \"startsAt\": \"'$(date -u +%Y-%m-%dT%H:%M:%SZ)'\"\n    }\n  ]'\n</code></pre> You should now see the <code>KubePodCrashLooping</code> alert in your AlertManager UI at <code>http://localhost:9093</code>.</p>"},{"location":"walkthrough/investigating-prometheus-alerts/#step-3-investigate-alerts","title":"Step 3: Investigate Alerts","text":"<p>Finally let's use the HolmesGPT <code>investigate</code> subcommand to investigate the alerts. Run the following command:</p> <p><pre><code>holmes investigate alertmanager --alertmanager-url http://localhost:9093\n</code></pre> </p> <p>By default, HolmesGPT will fetch all active alerts from AlertManager and investigate them.</p> <p>For our investigation, we will use the <code>--alertmanager-alertname</code> flag to focus on the specific <code>KubePodCrashLooping</code> alert we created earlier. <pre><code>holmes investigate alertmanager --alertmanager-url http://localhost:9093 --alertmanager-alertname \"KubePodCrashLooping\"\n</code></pre> Once the investigation is complete, HolmesGPT will provide the potential Root Cause, next steps, and more.</p>"},{"location":"walkthrough/investigating-prometheus-alerts/#filtering-alerts","title":"Filtering Alerts","text":"<p>The <code>holmes investigate alertmanager</code> command supports many flags. For example, to investigate only critical alerts or alerts in a specific namespace, you can use the <code>--alertmanager-label</code> flag:</p> <pre><code># Critical alerts only\nholmes investigate alertmanager \\\n  --alertmanager-url http://localhost:9093 \\\n  --alertmanager-label \"severity=critical\"\n\n# Production namespace issues\nholmes investigate alertmanager \\\n  --alertmanager-url http://localhost:9093 \\\n  --alertmanager-label \"namespace=production\"\n</code></pre>"},{"location":"walkthrough/investigating-prometheus-alerts/#whats-next","title":"What's Next?","text":"<ul> <li>Add new data sources - Connect HolmesGPT to your databases, APM tools, and custom APIs for deeper investigations.</li> <li>Set up remote MCP - Add data sources as remote Model Context Protocol (MCP) servers.</li> </ul>"},{"location":"walkthrough/investigating-using-aks-mcp-server/","title":"Investigating using AKS MCP Server","text":"<p>You can investigate Azure Kubernetes Service issues using HolmesGPT with the AKS MCP (Model Context Protocol) server.</p> <p></p>"},{"location":"walkthrough/investigating-using-aks-mcp-server/#prerequisites","title":"Prerequisites","text":"<ul> <li>HolmesGPT CLI installed (installation guide)</li> <li>An AI provider API key configured (setup guide)</li> <li>Azure CLI installed and authenticated</li> <li>Access to Azure Kubernetes Service clusters</li> <li>Azure Kubernetes Service VS Code extension installed</li> </ul>"},{"location":"walkthrough/investigating-using-aks-mcp-server/#setting-up-aks-mcp-server","title":"Setting Up AKS MCP Server","text":""},{"location":"walkthrough/investigating-using-aks-mcp-server/#step-1-setup-the-mcp-server","title":"Step 1: Setup the MCP Server","text":"<ul> <li>Open VS Code Command Palette (<code>Ctrl+Shift+P</code> or <code>Cmd+Shift+P</code>)</li> <li>Run: \"AKS: Setup AKS MCP Server\"</li> <li>Follow the setup wizard to configure your Azure credentials and cluster access</li> </ul>"},{"location":"walkthrough/investigating-using-aks-mcp-server/#step-2-update-configuration-for-sse","title":"Step 2: Update Configuration for SSE","text":"<p>After installation, update your VS Code MCP configuration (<code>.vscode/mcp.json</code>) to use SSE transport and start the server    <pre><code>{\n  \"servers\": {\n    \"AKS MCP\": {\n      \"command\": \"/Users/yourname/.vs-kubernetes/tools/aks-mcp/v0.0.3/aks-mcp\",\n      \"args\": [\n        \"--transport\",\n        \"sse\"\n      ]\n    }\n  }\n}\n</code></pre> Note: Change <code>\"stdio\"</code> to <code>\"sse\"</code> in the transport argument.</p>"},{"location":"walkthrough/investigating-using-aks-mcp-server/#step-3-configure-holmesgpt","title":"Step 3: Configure HolmesGPT","text":"<p>Add this configuration to your HolmesGPT config file (<code>~/.holmes/config.yaml</code>):</p> <pre><code>mcp_servers:\n  aks-mcp:\n    description: \"Azure Kubernetes Service(AKS) Model Context Protocol(MCP) server\"\n    url: \"http://localhost:8000/sse\"\n    llm_instructions: \"MCP server to get AKS cluster information, retrieve cluster resources and workloads, analyze network policies and VNet configurations, query control plane logs, fetch cluster metrics and health status. Investigate networking issues with NSGs and load balancers, perform kubectl operations, real-time monitoring of DNS, services across Azure Kubernetes environments\"\n</code></pre>"},{"location":"walkthrough/investigating-using-aks-mcp-server/#investigation-examples","title":"Investigation Examples","text":"<p>Once configured, you can investigate AKS issues using natural language queries:</p>"},{"location":"walkthrough/investigating-using-aks-mcp-server/#cluster-health-issues","title":"Cluster Health Issues","text":"<pre><code>holmes ask \"What issues do I have in my AKS cluster?\"\n</code></pre>"},{"location":"walkthrough/investigating-using-aks-mcp-server/#network-connectivity-problems","title":"Network Connectivity Problems","text":"<pre><code>holmes ask \"My payment deployment can't reach external services investigate why\"\n</code></pre>"},{"location":"walkthrough/investigating-using-aks-mcp-server/#whats-next","title":"What's Next?","text":"<ul> <li>Add more data sources - Combine AKS MCP with other observability tools</li> <li>Set up additional MCP servers - Integrate multiple specialized MCP servers</li> <li>Configure custom toolsets - Create specialized investigation workflows</li> </ul>"}]}