apiVersion: v1
kind: Namespace
metadata:
  name: ask-holmes-slack-statefulset-logs

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: alertmanager-config
  namespace: ask-holmes-slack-statefulset-logs
data:
  config.yml: |
    global:
      resolve_timeout: 5m
      # Optional: SMTP, Slack, PagerDuty, OpsGenie, etc. global settings
      # slack_api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK_URL' # Example if using Slack globally

    route:
      group_by: ['alertname', 'job']
      group_wait: 30s
      group_interval: 5m
      repeat_interval: 12h
      receiver: 'default-receiver' # Default receiver for all alerts

      # You can define more specific routes here if needed
      # routes:
      #   - receiver: 'critical-alerts'
      #     match_re:
      #       severity: 'critical'
      #     continue: true # If true, subsequent sibling routes are also processed

    receivers:
    - name: 'default-receiver'
      # This is a placeholder. You MUST configure actual notification channels.
      # Example for a webhook:
      # webhook_configs:
      # - url: 'http://your-webhook-endpoint:port/path'
      #   send_resolved: true

      # Example for Slack (ensure you have global.slack_api_url or define api_url here):
      # slack_configs:
      # - channel: '#alerts-channel'
      #   send_resolved: true
      #   text: "summary: {{ .CommonAnnotations.summary }}\ndescription: {{ .CommonAnnotations.description }}"

      # For testing, you can use a receiver that does nothing or logs to a file,
      # but for actual alerting, configure something like Slack, PagerDuty, email, etc.
      # A "do-nothing" receiver (useful for initial setup):
      webhook_configs:
      - url: 'http://localhost:9099/' # This will likely fail but won't stop Alertmanager from running
        send_resolved: false

    # Inhibit rules can be defined here to suppress notifications for certain alerts
    # if other alerts are already firing.
    # inhibit_rules:
    #   - source_match:
    #       severity: 'critical'
    #     target_match:
    #       severity: 'warning'
    #     # Alertname, cluster, etc. must be equal.
    #     equal: ['alertname', 'namespace', 'job']

---
# Headless service for StatefulSet (DNS discovery for pods if scaled)
apiVersion: v1
kind: Service
metadata:
  name: alertmanager # Must match StatefulSet.spec.serviceName
  namespace: ask-holmes-slack-statefulset-logs
  labels:
    app.kubernetes.io/name: alertmanager
spec:
  clusterIP: None # Headless service
  selector:
    app.kubernetes.io/name: alertmanager
  ports:
  - name: web
    port: 9093
    targetPort: web
  # - name: mesh # Port for Alertmanager clustering if replicas > 1
  #   port: 9094
  #   targetPort: mesh

---
# ClusterIP service to access Alertmanager UI/API
apiVersion: v1
kind: Service
metadata:
  name: alertmanager-ui
  namespace: ask-holmes-slack-statefulset-logs
  labels:
    app.kubernetes.io/name: alertmanager
spec:
  type: ClusterIP
  selector:
    app.kubernetes.io/name: alertmanager
  ports:
  - name: web
    port: 9093 # Service port
    targetPort: web # Pod port name (or number 9093)
    protocol: TCP

---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: alertmanager
  namespace: ask-holmes-slack-statefulset-logs
  labels:
    app.kubernetes.io/name: alertmanager
spec:
  replicas: 1 # For a single Alertmanager instance. Increase for HA.
  selector:
    matchLabels:
      app.kubernetes.io/name: alertmanager
  serviceName: "alertmanager" # Must match the headless Service name
  template:
    metadata:
      labels:
        app.kubernetes.io/name: alertmanager
    spec:
      # Run pods as non-root user for security
      securityContext:
        fsGroup: 2000
        runAsNonRoot: true
        runAsUser: 1000
      containers:
      - name: alertmanager
        image: prom/alertmanager:v0.27.0 # Using a specific stable version
        args:
          - "--config.file=/etc/alertmanager/config.yml"
          - "--storage.path=/alertmanager"
          - "--web.listen-address=:9093"
        ports:
        - name: web
          containerPort: 9093
          protocol: TCP
        volumeMounts:
        - name: config-volume
          mountPath: /etc/alertmanager
        - name: storage-volume # Mount the persistent storage
          mountPath: /alertmanager
        resources: # Optional: Adjust based on your needs
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 500m
            memory: 256Mi
        readinessProbe:
          httpGet:
            path: /-/ready
            port: web
          initialDelaySeconds: 10
          timeoutSeconds: 5
        livenessProbe:
          httpGet:
            path: /-/healthy
            port: web
          initialDelaySeconds: 30
          timeoutSeconds: 5
          failureThreshold: 10
      volumes:
      - name: config-volume
        configMap:
          name: alertmanager-config
  volumeClaimTemplates:
  - metadata:
      name: storage-volume
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 2Gi

---
# ServiceAccount for alertmanager-operator
apiVersion: v1
kind: ServiceAccount
metadata:
  name: alertmanager-operator
  namespace: ask-holmes-slack-statefulset-logs

---
# Role for alertmanager-operator (namespace-scoped)
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: alertmanager-operator
  namespace: ask-holmes-slack-statefulset-logs
rules:
- apiGroups: [""]
  resources: ["pods", "services", "endpoints", "configmaps", "secrets"]
  verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
- apiGroups: ["apps"]
  resources: ["statefulsets", "deployments"]
  verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
- apiGroups: ["monitoring.coreos.com"]
  resources: ["alertmanagers", "alertmanagerconfigs", "prometheuses", "prometheusrules", "servicemonitors", "podmonitors", "thanosrulers", "probes"]
  verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
- apiGroups: ["monitoring.coreos.com"]
  resources: ["alertmanagers/status", "prometheuses/status", "thanosrulers/status"]
  verbs: ["update"]

---
# RoleBinding for alertmanager-operator (namespace-scoped)
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: alertmanager-operator
  namespace: ask-holmes-slack-statefulset-logs
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: alertmanager-operator
subjects:
- kind: ServiceAccount
  name: alertmanager-operator
  namespace: ask-holmes-slack-statefulset-logs

---
# Headless service for alertmanager-operator StatefulSet
apiVersion: v1
kind: Service
metadata:
  name: alertmanager-operator
  namespace: ask-holmes-slack-statefulset-logs
  labels:
    app.kubernetes.io/name: alertmanager-operator
spec:
  clusterIP: None # Headless service
  selector:
    app.kubernetes.io/name: alertmanager-operator
  ports:
  - name: metrics
    port: 8080
    targetPort: metrics

---
# ClusterIP service to access alertmanager-operator metrics
apiVersion: v1
kind: Service
metadata:
  name: alertmanager-operator-metrics
  namespace: ask-holmes-slack-statefulset-logs
  labels:
    app.kubernetes.io/name: alertmanager-operator
spec:
  type: ClusterIP
  selector:
    app.kubernetes.io/name: alertmanager-operator
  ports:
  - name: metrics
    port: 8080
    targetPort: metrics
    protocol: TCP

---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: alertmanager-operator
  namespace: ask-holmes-slack-statefulset-logs
  labels:
    app.kubernetes.io/name: alertmanager-operator
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: alertmanager-operator
  serviceName: "alertmanager-operator"
  template:
    metadata:
      labels:
        app.kubernetes.io/name: alertmanager-operator
    spec:
      serviceAccountName: alertmanager-operator
      securityContext:
        fsGroup: 2000
        runAsNonRoot: true
        runAsUser: 1000
      containers:
      - name: alertmanager-operator
        image: quay.io/prometheus-operator/prometheus-operator:v0.68.0
        args:
          - "--kubelet-service=kube-system/kubelet"
          - "--log-level=info"
          - "--prometheus-config-reloader=quay.io/prometheus-operator/prometheus-config-reloader:v0.68.0"
          - "--namespaces=ask-holmes-slack-statefulset-logs"
        env:
        - name: GOGC
          value: "30"
        - name: GOMEMLIMIT
          value: "200MiB"
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 500m
            memory: 256Mi
        ports:
        - name: metrics
          containerPort: 8080
          protocol: TCP
        readinessProbe:
          httpGet:
            path: /metrics
            port: 8080
          initialDelaySeconds: 10
          timeoutSeconds: 5
        livenessProbe:
          httpGet:
            path: /metrics
            port: 8080
          initialDelaySeconds: 30
          timeoutSeconds: 5
          failureThreshold: 10

---
# Alertmanager Custom Resource
apiVersion: monitoring.coreos.com/v1
kind: Alertmanager
metadata:
  name: alertmanager
  namespace: ask-holmes-slack-statefulset-logs
spec:
  replicas: 1
  configSecret: alertmanager-config-secret
  storage:
    volumeClaimTemplate:
      spec:
        accessModes: ["ReadWriteOnce"]
        resources:
          requests:
            storage: 2Gi
  securityContext:
    fsGroup: 2000
    runAsNonRoot: true
    runAsUser: 1000
  logLevel: warn

---
# Secret for Alertmanager configuration
apiVersion: v1
kind: Secret
metadata:
  name: alertmanager-config-secret
  namespace: ask-holmes-slack-statefulset-logs
type: Opaque
stringData:
  alertmanager.yaml: |
    global:
      resolve_timeout: 5m
    route:
      group_by: ['alertname', 'job']
      group_wait: 30s
      group_interval: 5m
      repeat_interval: 12h
      receiver: 'default-receiver'
    receivers:
    - name: 'default-receiver'
      webhook_configs:
      - url: 'http://localhost:9099/'
        send_resolved: false
