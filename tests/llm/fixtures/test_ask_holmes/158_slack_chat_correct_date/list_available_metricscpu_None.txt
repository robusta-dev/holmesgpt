{"toolset_name":"prometheus/metrics","tool_name":"list_available_metrics","match_params":{"type_filter":null,"name_filter":"cpu"}}
{"schema_version": "robusta:v1.0.0", "status": "success", "error": null, "return_code": null, "url": null, "invocation": null, "params": {"type_filter": null, "name_filter": "cpu"}, "icon_url": null}
Metric | Description | Type | Labels
----------------------------------------------------------------------------------------------------
container_cpu_cfs_periods_total | Number of elapsed enforcement period intervals. | counter | container, endpoint, id, image, instance, job, metrics_path, name, namespace, node, pod, service
container_cpu_cfs_throttled_periods_total | Number of throttled period intervals. | counter | container, endpoint, id, image, instance, job, metrics_path, name, namespace, node, pod, service
container_cpu_cfs_throttled_seconds_total | Total time duration the container has been throttled. | counter | none
container_cpu_load_average_10s | Value of container cpu load average over the last 10 seconds. | gauge | none
container_cpu_load_d_average_10s | Value of container cpu load.d average over the last 10 seconds. | gauge | container, endpoint, id, image, instance, job, metrics_path, name, namespace, node, pod, service
container_cpu_system_seconds_total | Cumulative system cpu time consumed in seconds. | counter | none
container_cpu_usage_seconds_total | Cumulative cpu time consumed in seconds. | counter | container, cpu, endpoint, id, image, instance, job, metrics_path, name, namespace, node, pod, service
container_cpu_user_seconds_total | Cumulative user cpu time consumed in seconds. | counter | none
container_spec_cpu_period | CPU period of the container. | gauge | none
container_spec_cpu_quota | CPU quota of the container. | gauge | none
container_spec_cpu_shares | CPU share of the container. | gauge | none
go_cpu_classes_gc_mark_assist_cpu_seconds_total | Estimated total CPU time goroutines spent performing GC tasks to assist the GC and prevent it from falling behind the application. This metric is an overestimate, and not directly comparable to system CPU time measurements. Compare only with other /cpu/classes metrics. | counter | endpoint, instance, job, metrics_path, namespace, node, service
go_cpu_classes_gc_mark_dedicated_cpu_seconds_total | Estimated total CPU time spent performing GC tasks on processors (as defined by GOMAXPROCS) dedicated to those tasks. This metric is an overestimate, and not directly comparable to system CPU time measurements. Compare only with other /cpu/classes metrics. | counter | endpoint, instance, job, metrics_path, namespace, node, service
go_cpu_classes_gc_mark_idle_cpu_seconds_total | Estimated total CPU time spent performing GC tasks on spare CPU resources that the Go scheduler could not otherwise find a use for. This should be subtracted from the total GC CPU time to obtain a measure of compulsory GC CPU time. This metric is an overestimate, and not directly comparable to system CPU time measurements. Compare only with other /cpu/classes metrics. | counter | endpoint, instance, job, metrics_path, namespace, node, service
go_cpu_classes_gc_pause_cpu_seconds_total | Estimated total CPU time spent with the application paused by the GC. Even if only one thread is running during the pause, this is computed as GOMAXPROCS times the pause latency because nothing else can be executing. This is the exact sum of samples in /sched/pauses/total/gc:seconds if each sample is multiplied by GOMAXPROCS at the time it is taken. This metric is an overestimate, and not directly comparable to system CPU time measurements. Compare only with other /cpu/classes metrics. | counter | endpoint, instance, job, metrics_path, namespace, node, service
go_cpu_classes_gc_total_cpu_seconds_total | Estimated total CPU time spent performing GC tasks. This metric is an overestimate, and not directly comparable to system CPU time measurements. Compare only with other /cpu/classes metrics. Sum of all metrics in /cpu/classes/gc. | counter | endpoint, instance, job, metrics_path, namespace, node, service
go_cpu_classes_idle_cpu_seconds_total | Estimated total available CPU time not spent executing any Go or Go runtime code. In other words, the part of /cpu/classes/total:cpu-seconds that was unused. This metric is an overestimate, and not directly comparable to system CPU time measurements. Compare only with other /cpu/classes metrics. | counter | endpoint, instance, job, metrics_path, namespace, node, service
go_cpu_classes_scavenge_assist_cpu_seconds_total | Estimated total CPU time spent returning unused memory to the underlying platform in response eagerly in response to memory pressure. This metric is an overestimate, and not directly comparable to system CPU time measurements. Compare only with other /cpu/classes metrics. | counter | endpoint, instance, job, metrics_path, namespace, node, service
go_cpu_classes_scavenge_background_cpu_seconds_total | Estimated total CPU time spent performing background tasks to return unused memory to the underlying platform. This metric is an overestimate, and not directly comparable to system CPU time measurements. Compare only with other /cpu/classes metrics. | counter | endpoint, instance, job, metrics_path, namespace, node, service
go_cpu_classes_scavenge_total_cpu_seconds_total | Estimated total CPU time spent performing tasks that return unused memory to the underlying platform. This metric is an overestimate, and not directly comparable to system CPU time measurements. Compare only with other /cpu/classes metrics. Sum of all metrics in /cpu/classes/scavenge. | counter | endpoint, instance, job, metrics_path, namespace, node, service
go_cpu_classes_total_cpu_seconds_total | Estimated total available CPU time for user Go code or the Go runtime, as defined by GOMAXPROCS. In other words, GOMAXPROCS integrated over the wall-clock duration this process has been executing for. This metric is an overestimate, and not directly comparable to system CPU time measurements. Compare only with other /cpu/classes metrics. Sum of all metrics in /cpu/classes. | counter | endpoint, instance, job, metrics_path, namespace, node, service
go_cpu_classes_user_cpu_seconds_total | Estimated total CPU time spent running user Go code. This may also include some small amount of time spent in the Go runtime. This metric is an overestimate, and not directly comparable to system CPU time measurements. Compare only with other /cpu/classes metrics. | counter | endpoint, instance, job, metrics_path, namespace, node, service
kube_pod_overhead_cpu_cores | The pod overhead in regards to cpu cores associated with running a pod. | gauge | none
kubelet_cpu_manager_exclusive_cpu_allocation_count | [ALPHA] The total number of CPUs exclusively allocated to containers running on this node | gauge | endpoint, instance, job, metrics_path, namespace, node, service
kubelet_cpu_manager_pinning_errors_total | [ALPHA] The number of cpu core allocations which required pinning failed. | counter | endpoint, instance, job, metrics_path, namespace, node, service
kubelet_cpu_manager_pinning_requests_total | [ALPHA] The number of cpu core allocations which required pinning. | counter | endpoint, instance, job, metrics_path, namespace, node, service
kubelet_cpu_manager_shared_pool_size_millicores | [ALPHA] The size of the shared CPU pool for non-guaranteed QoS pods, in millicores. | gauge | endpoint, instance, job, metrics_path, namespace, node, service
machine_cpu_cores | Number of logical CPU cores. | gauge | boot_id, endpoint, instance, job, machine_id, metrics_path, namespace, node, service, system_uuid
machine_cpu_physical_cores | Number of physical CPU cores. | gauge | boot_id, endpoint, instance, job, machine_id, metrics_path, namespace, node, service, system_uuid
machine_cpu_sockets | Number of CPU sockets. | gauge | boot_id, endpoint, instance, job, machine_id, metrics_path, namespace, node, service, system_uuid
node_cpu_frequency_max_hertz | Maximum CPU thread frequency in hertz. | gauge | container, cpu, endpoint, instance, job, namespace, pod, service
node_cpu_frequency_min_hertz | Minimum CPU thread frequency in hertz. | gauge | container, cpu, endpoint, instance, job, namespace, pod, service
node_cpu_guest_seconds_total | Seconds the CPUs spent in guests (VMs) for each mode. | counter | container, cpu, endpoint, instance, job, mode, namespace, pod, service
node_cpu_scaling_frequency_hertz | Current scaled CPU thread frequency in hertz. | gauge | container, cpu, endpoint, instance, job, namespace, pod, service
node_cpu_scaling_frequency_max_hertz | Maximum scaled CPU thread frequency in hertz. | gauge | container, cpu, endpoint, instance, job, namespace, pod, service
node_cpu_scaling_frequency_min_hertz | Minimum scaled CPU thread frequency in hertz. | gauge | container, cpu, endpoint, instance, job, namespace, pod, service
node_cpu_scaling_governor | Current enabled CPU frequency governor. | gauge | container, cpu, endpoint, governor, instance, job, namespace, pod, service
node_cpu_seconds_total | Seconds the CPUs spent in each mode. | counter | container, cpu, endpoint, instance, job, mode, namespace, pod, service
node_memory_Percpu_bytes | Memory information field Percpu_bytes. | gauge | container, endpoint, instance, job, namespace, pod, service
node_pressure_cpu_waiting_seconds_total | Total time in seconds that processes have waited for CPU time | counter | container, endpoint, instance, job, namespace, pod, service
node_softnet_cpu_collision_total | Number of collision occur while obtaining device lock while transmitting | counter | container, cpu, endpoint, instance, job, namespace, pod, service
process_cpu_seconds | Total user and system CPU time spent in seconds. | counter | none
process_cpu_seconds_total | Total user and system CPU time spent in seconds. | counter | container, endpoint, instance, job, metrics_path, namespace, node, pod, service, target
