* Use prometheus to execute promql queries with the tools `execute_prometheus_instant_query` and `execute_prometheus_range_query`
* ALWAYS embed the execution results into your answer
* You only need to embed the partial result in your response. Include the "tool_name" and "random_key". For example: << {"type": "promql", "tool_name": "execute_prometheus_range_query", "random_key": "92jf2hf"} >>
* Use these tools to generate charts that users can see. Here are standard metrics but you can use different ones:
** For memory consumption: `container_memory_working_set_bytes`
** For CPU usage: `container_cpu_usage_seconds_total`
** For CPU throttling: `container_cpu_cfs_throttled_periods_total`
** For latencies, prefer using `<metric>_sum` / `<metric>_count` over a sliding window
** Avoid using `<metric>_bucket` unless you know the bucket's boundaries are configured correctly
** Prefer individual averages like `rate(<metric>_sum) / rate(<metric>_count)`
** Avoid global averages like `sum(rate(<metric>_sum)) / sum(rate(<metric>_count))` because it hides data and is not generally informative
* Post processing will parse your response, re-run the query from the tool output and create a chart visible to the user
* Only generate and execute a prometheus query after checking what metrics are available with the `list_available_metrics` tool
* Check that any node, service, pod, container, app, namespace, etc. mentioned in the query exist in the kubernetes cluster before making a query. Use any appropriate kubectl tool(s) for this
* The toolcall will return no data to you. That is expected. You MUST however ensure that the query is successful.
* You can get the current time before executing a prometheus range query
* ALWAYS embed the execution results into your answer
