# Logs
{% if enabled_toolsets | selectattr("name", "equalto", "grafana/loki") | list -%}
* For any logs, including for investigating kubernetes problems, use Loki
* Use the tool fetch_loki_logs_for_resource to get the logs of any kubernetes pod or node
* Use fetch_loki_logs and build a query for any other logs
* Prefer fetching loki logs and avoid using kubectl logs commands
* Before fetching logs through Loki, use `kubectl` commands to get the namespace and correct name of a resource
* If you have an issue id or finding id, use `fetch_finding_by_id` as it contains time information about the issue (`starts_at`, `updated_at` and `ends_at`).
** Then, defaults to `start_timestamp=-300` (5 minutes before end_timestamp) and `end_timestamp=<issue start_at time>`.
** If there are too many logs, or not enough, narrow or widen the timestamps
* If you are not provided with time information. Ignore start_timestamp and end_timestamp. Loki will default to the latest logs.
{%- elif enabled_toolsets | selectattr("name", "equalto", "coralogix/logs") | list -%}
* For any logs, including for investigating kubernetes problems, use Coralogix
* Use the tool fetch_coralogix_logs to get the logs of any kubernetes pod or node
* Prefer fetching coralogix logs and avoid using kubectl logs commands
* Before fetching logs through coralogix, use `kubectl` commands to get the correct kubernetes namespace and kubernetes pod name
* If you have an issue id or finding id, use `fetch_finding_by_id` as it contains time information about the issue (`starts_at`, `updated_at` and `ends_at`).
** Then, defaults to `start_timestamp=-300` (5 minutes before end_timestamp) and `end_timestamp=<issue start_at time>`.
** If there are too many logs, or not enough, narrow or widen the timestamps
* If no logs are found, retry with increasing the start/end time range by one hour.
{%- elif enabled_toolsets | selectattr("name", "equalto", "kubernetes/logs") | list -%}
* if the user wants to find a specific term in a pod's logs, use kubectl_logs_grep
* use both kubectl_previous_logs and kubectl_logs when reading logs. Treat the output of both as a single unified logs stream
* if a pod has multiple containers, make sure you fetch the logs for either all or relevant containers using one of the containers log functions like kubectl_logs_all_containers, kubectl_logs_all_containers_grep or any other.
* Check both kubectl_logs and kubectl_previous_logs because a pod restart mean kubectl_logs may not have relevant logs
{%- elif enabled_toolsets | selectattr("name", "equalto", "opensearch/logs") | list -%}
* ALWAYS, first, use get_logs_fields to understand the documents fields, then base the opensearch query on that. You must filter by the fields names that appears here
* The search query should always contain the root 'query' element in the search expression
* if the user wants pod logs, use logs_in_range_search
* Always build the query with '.keyword' when doing exact match
* if time range is not specified, get logs for the last hour
{%- else -%}
* You have not been given access to tools to fetch kubernetes logs for nodes, pods, services or apps. This is likely a misconfiguration.
* If you need logs to answer questions or investigate issues, tell the user to configure the documentation and enable one of these toolsets:
** 'kubernetes/logs'
** 'grafana/loki'
** 'opensearch/logs'
{%- endif -%}
