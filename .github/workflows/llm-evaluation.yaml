name: Evaluate LLM test cases

on:
  pull_request:
    branches: ["*"]
  push:
    branches: [master]

permissions:
  pull-requests: write
  contents: read

jobs:
  llm_evals:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: 3.12

      - name: Install Python dependencies and build
        # if you change something here, you must also change it in .github/workflows/build-binaries-and-brew.yaml
        run: |
          python -m pip install --upgrade pip setuptools pyinstaller

          curl -sSL https://install.python-poetry.org | python3 - --version 1.4.0
          poetry config virtualenvs.create false
          poetry install --no-root

      - name: Install kubectl
        run: |
          curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/
          kubectl version --client

      - name: Install KIND
        run: |
          curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.20.0/kind-linux-amd64
          chmod +x ./kind
          sudo mv ./kind /usr/local/bin/kind
          kind version

      - name: Create KIND cluster
        run: |
          cat <<EOF > kind-config.yaml
          kind: Cluster
          apiVersion: kind.x-k8s.io/v1alpha4
          nodes:
          - role: control-plane
            extraPortMappings:
            - containerPort: 30000
              hostPort: 30000
              protocol: TCP
            - containerPort: 30001
              hostPort: 30001
              protocol: TCP
            kubeadmConfigPatches:
            - |
              kind: InitConfiguration
              nodeRegistration:
                kubeletExtraArgs:
                  max-pods: "200"
            - |
              kind: KubeProxyConfiguration
              metricsBindAddress: "0.0.0.0:10249"
            - |
              kind: KubeletConfiguration
              maxPods: 200
          - role: worker
            kubeadmConfigPatches:
            - |
              kind: JoinConfiguration
              nodeRegistration:
                kubeletExtraArgs:
                  max-pods: "200"
            - |
              kind: KubeletConfiguration
              maxPods: 200
          EOF

          # Create cluster with resource limits appropriate for GitHub Actions (7GB RAM, 2 CPU)
          kind create cluster --config kind-config.yaml --wait 5m

          # Configure kubectl
          kubectl cluster-info --context kind-kind

          # Wait for all nodes to be ready
          echo "Waiting for nodes to be ready..."
          kubectl wait --for=condition=Ready nodes --all --timeout=300s
          kubectl get nodes

          # Wait for all system pods to be ready
          echo "Waiting for system pods to be ready..."
          kubectl wait --for=condition=Ready pods --all -n kube-system --timeout=300s

          # Verify cluster is working by creating a test pod
          echo "Creating test pod to verify cluster..."
          kubectl run test-pod --image=busybox:1.35 --restart=Never -- echo "Cluster is ready"
          kubectl wait --for=condition=Ready pod/test-pod --timeout=120s
          kubectl logs test-pod
          kubectl delete pod test-pod

          # Show cluster info for debugging
          echo "=== Cluster nodes ==="
          kubectl get nodes -o wide
          echo "=== System pods ==="
          kubectl get pods -n kube-system
          echo "=== Cluster is ready for tests ==="

      - name: Run tests
        id: evals
        continue-on-error: true
        shell: bash
        env:
          RUN_LIVE: "true"
          AZURE_API_BASE: ${{ secrets.AZURE_API_BASE }}
          AZURE_API_KEY: ${{ secrets.AZURE_API_KEY }}
          AZURE_API_VERSION: ${{ secrets.AZURE_API_VERSION }}
          MODEL: ${{ secrets.MODEL }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          BRAINTRUST_API_KEY: ${{ secrets.BRAINTRUST_API_KEY }}
          UPLOAD_DATASET: "true"
          EXPERIMENT_ID: github-${{ github.run_id }}.${{ github.run_number }}.${{ github.run_attempt }}
          GENERATE_REGRESSIONS_FILE: "true"
        run: |
          poetry run pytest --no-cov tests/llm/test_ask_holmes.py tests/llm/test_investigate.py -s -n10 -m 'llm and easy'
      - uses: actions/github-script@v7
        if: always()
        with:
          retries: 3
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            try {
              if(!context.issue || !context.issue.number) {
                // Only comment on PR if the workflow is run as part of a PR
                return
              }
              const reportContent = fs.readFileSync('evals_report.md', 'utf8');

              const comments = await github.rest.issues.listComments({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number
              });

              const botComment = comments.data.find(comment =>
                comment.user.type === 'Bot' &&
                comment.body.includes('## Results of HolmesGPT evals')
              );

              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: reportContent
              });

              if (botComment) {
                await github.rest.issues.deleteComment({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  comment_id: botComment.id
                });
              }
            } catch(e) {
              console.log(e)
            }
      - name: Check test results
        if: always()
        run: |
          if [[ -f "regressions.txt" ]]; then
            echo "There are regressions in the evals. Please check the evals file for details."
            cat regressions.txt
            exit 1
          else
            echo "All tests passed without regressions."
          fi
