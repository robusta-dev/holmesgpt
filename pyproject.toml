[tool.poetry]
name = "holmesgpt"
version = "0.0.0"
description = ""
authors = ["Natan Yellin <natan@robusta.dev>"]
readme = "README.md"
packages = [{ include = "holmes" }]

[tool.poetry.scripts]
holmes = "holmes.main:run"

[tool.poetry.dependencies]
python = "^3.10"
openai = ">=1.6.1,<1.100.0"
jinja2 = "^3.1.2"
typer = "^0.15.4"
python-benedict = "^0.33.1"
humanize = "^4.9.0"
rich = "^13.7.1"
fastapi = "^0.116"
uvicorn = "^0.30"
pydantic = "^2.7"
supabase = "^2.5"
colorlog = "^6.8.2"
strenum = "^0.4.15"
markdown = "^3.6"
certifi = "^2024.7.4"
boto3 = "^1.34.145"
cachetools = "^5.5.0"
bs4 = "^0.0.2"
markdownify = "^1.1.0"
opensearch-py = "^2.8.0"
backoff = "^2.2.1"
litellm = "1.77.1"
sentry-sdk = {extras = ["fastapi"], version = "^2.20.0"}
confluent-kafka = "^2.6.1"
kubernetes = "^32.0.1"
mcp = "v1.12.2"
prompt-toolkit = "^3.0.51"
pygments = "^2.18.0"
azure-identity = "^1.23.0"
azure-core = "^1.34.0"
requests = "^2.32.4"
azure-mgmt-sql = "^4.0.0b21"
pyodbc = "^5.0.1"
azure-monitor-query = "^1.2.0"
azure-mgmt-monitor = "^7.0.0b1"
azure-mgmt-alertsmanagement = "^1.0.0"
azure-mgmt-resource = "^23.3.0"
tenacity = "^9.1.2"
# Due to a bug in the postgrest package, we need to pin the version to 0.16.8 until we will upgrade selfhost supabase versions.
postgrest = "0.16.8"
requests-aws4auth = "^1.3.1"
prometrix = "0.2.5"
httpx = {version = "<0.28", extras = ["socks"]}

[tool.poetry.group.dev]
optional = true

[tool.poetry.group.dev.dependencies]
mkdocs-material = "^9.5.39"
mkdocs-glightbox = "^0.4.0"
pytest = "^8.3.3"
pytest-xdist = "^3.6.1"
pytest-json-report = "^1.5.0"
ruff = "^0.7.3"
braintrust = "^0.1.2"
autoevals = "^0.0.129"
pre-commit = "^4.0.1"
responses = "^0.23.1"
freezegun = "^1.5.1"
tomli = {version = "^2.0.1", python = "<3.11"}
mypy = "^1.16.0"
pytest-cov = "^6.2.1"
types-python-dateutil = "^2.9.0.20250708"
pytest-dotenv = "^0.5.2"
pytest-sugar = "^1.1.1"
pytest-shared-session-scope = "^0.4.0"
mkdocs-awesome-nav = "^3.2.0"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"

[tool.mypy]
ignore_missing_imports = true
scripts_are_modules = true
exclude = [
    "tests/llm/fixtures/.*",
    "dist/.*",
    "site/.*",
]

[tool.pytest.ini_options]
markers = [
    "llm: Evaluate LLM behaviour (prompt, tools, etc.)",
    "datetime: Tests involving datetime functionality",
    "logs: Tests involving log processing",
    "metrics: Tests involving metrics processing",
    "context_window: Tests involving context window handling",
    "network: Tests requiring network connectivity",
    "runbooks: Tests involving runbook functionality",
    "chain-of-causation: Tests involving chain-of-causation analysis",
    "slackbot: Tests involving Slack bot functionality",
    "numerical: Tests involving numerical calculations or data",
    "counting: Ask holmes to count kubernetes/cloud resources",
    "kubernetes: Tests for Kubernetes-specific troubleshooting scenarios",
    "easy: Tests that are supposed to pass - if these fail, it indicates a regression. Only add evals here if they pass at least 20/20 runs.",
    "medium: Tests that we want to focus on in the near future and get holmes to pass them",
    "hard: Tests that are hard and holmes does not pass today and might not pass in the near future",
    "transparency: Holmes communicates to the user when it encounters problems fulfilling the user's request",
    "kafka: Tests involving Kafka functionality",
    "leaked-information: cases where the eval is accidentally leaking information that should not be available to the LLM - e.g. if the names of environment variables or the docker image gives away part of the test",
    "port-forward: Tests requiring port forwarding to local services (automatically added to tests with port_forwards in test_case.yaml)",
    "toolset-limitation: Tests that cannot be solved no matter how smart the model, unless we improve the underlying toolsets themselves",
    "database: Tests involving database interactions",
    "traces: Tests where the ai is expected to find the solution using the traces",
    "datadog: DataDog toolset",
    "storage: Disk related, like I/O or disk space",
    "question-answer: Simple question-answer tests where Holmes answers straightforward questions about the system",
    "prometheus: Tests involving Prometheus metrics",
    "loki: Tests involving Loki logs",
    "newrelic: New Relic toolset",
    "embeds: Ability of holmes to include embeds like << { promql... } >> in its answers",
    "no-cicd: Tests to skip in the GitHub action because we're missing prerequisites in the KIND cluster like a Prometheus instance",
]

addopts = [
    "--cov-config=pyproject.toml",
    "--cov=holmes",
    "-rs",  # Show skip reasons by default
    "--tb=short",  # Show shorter tracebacks by default
    "--durations=10",  # Show 5 slowest tests after each run
]

# Logging configuration for pytest
log_cli = true
log_cli_level = "INFO"
log_cli_format = "%(asctime)s [%(levelname)8s] [%(name)s] %(message)s"
log_cli_date_format = "%Y-%m-%d %H:%M:%S"

# File logging
log_file = "tests.log"
log_file_level = "INFO"  # Changed from DEBUG to reduce noise in HTML report
log_file_format = "%(asctime)s [%(levelname)8s] [%(name)s] %(message)s"
log_file_date_format = "%Y-%m-%d %H:%M:%S"

[tool.coverage.run]
branch = true
omit = [
    "tests/*",
]

[tool.coverage.report]
fail_under = 46
